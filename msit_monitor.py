import os
import re    
import json
import time
import logging
import asyncio
from datetime import datetime, timedelta
from pathlib import Path
import pandas as pd

from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException

from bs4 import BeautifulSoup
import telegram
import gspread
from oauth2client.service_account import ServiceAccountCredentials

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('msit_monitor')

class MSITMonitor:
    def __init__(self):
        # Telegram ì„¤ì •
        self.telegram_token = os.environ.get('TELCO_NEWS_TOKEN')
        self.chat_id = os.environ.get('TELCO_NEWS_TESTER')
        if not self.telegram_token or not self.chat_id:
            raise ValueError("í™˜ê²½ ë³€ìˆ˜ TELCO_NEWS_TOKENê³¼ TELCO_NEWS_TESTERê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        # Google Sheets ì„¤ì •
        self.gspread_creds = os.environ.get('MSIT_GSPREAD_ref')
        self.spreadsheet_id = os.environ.get('MSIT_SPREADSHEET_ID')
        self.spreadsheet_name = os.environ.get('SPREADSHEET_NAME', 'MSIT í†µì‹  í†µê³„')
    
        if not self.gspread_creds:
            logger.warning("í™˜ê²½ ë³€ìˆ˜ MSIT_GSPREAD_refê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Google Sheets ì—…ë°ì´íŠ¸ëŠ” ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
        
        # MSIT URL
        self.url = "https://www.msit.go.kr/bbs/list.do?sCode=user&mPid=74&mId=99"
        
        # Telegram ë´‡ ì´ˆê¸°í™”
        self.bot = telegram.Bot(token=self.telegram_token)
        
        # ì¶”ì í•  ë³´ê³ ì„œ ìœ í˜•
        self.report_types = [
            "ì´ë™ì „í™” ë° íŠ¸ë˜í”½ í†µê³„",
            "ì´ë™ì „í™” ë° ì‹œë‚´ì „í™” ë²ˆí˜¸ì´ë™ í˜„í™©",
            "ìœ ì„ í†µì‹ ì„œë¹„ìŠ¤ ê°€ì… í˜„í™©",
            "ë¬´ì„ í†µì‹ ì„œë¹„ìŠ¤ ê°€ì… í˜„í™©", 
            "íŠ¹ìˆ˜ë¶€ê°€í†µì‹ ì‚¬ì—…ìí˜„í™©",
            "ë¬´ì„ ë°ì´í„° íŠ¸ë˜í”½ í†µê³„",
            "ìœ Â·ë¬´ì„ í†µì‹ ì„œë¹„ìŠ¤ ê°€ì… í˜„í™© ë° ë¬´ì„ ë°ì´í„° íŠ¸ë˜í”½ í†µê³„"
        ]
        
        # ì„ì‹œ ë””ë ‰í† ë¦¬
        self.temp_dir = Path("./downloads")
        self.temp_dir.mkdir(exist_ok=True)

    def setup_driver(self):
        """Selenium WebDriver ì„¤ì •"""
        options = Options()
        options.add_argument('--headless')
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--disable-gpu')
        options.add_argument('--window-size=1920,1080')
        
        # ì„±ëŠ¥ ìµœì í™” ì„¤ì •
        prefs = {
            "profile.default_content_setting_values.images": 2  # ì´ë¯¸ì§€ ë¡œë”© ë¹„í™œì„±í™”
        }
        options.add_experimental_option("prefs", prefs)
        
        # ë¶ˆí•„ìš”í•œ ë¡œê·¸ ë¹„í™œì„±í™”
        options.add_experimental_option('excludeSwitches', ['enable-logging'])
        
        # ì„œë¹„ìŠ¤ ì„¤ì •
        if os.path.exists('/usr/bin/chromium-browser'):
            options.binary_location = '/usr/bin/chromium-browser'
            service = Service('/usr/bin/chromedriver')
        else:
            try:
                from webdriver_manager.chrome import ChromeDriverManager
                service = Service(ChromeDriverManager().install())
            except ImportError:
                service = Service('/usr/bin/chromedriver')
        
        driver = webdriver.Chrome(service=service, options=options)
        driver.set_page_load_timeout(60)
        return driver

    def setup_gspread_client(self):
        """Google Sheets í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        if not self.gspread_creds:
            return None
        
        try:
            # í™˜ê²½ ë³€ìˆ˜ì—ì„œ ìê²© ì¦ëª… íŒŒì‹±
            creds_dict = json.loads(self.gspread_creds)
            
            # ì„ì‹œ íŒŒì¼ì— ìê²© ì¦ëª… ì €ì¥
            temp_creds_path = self.temp_dir / "temp_creds.json"
            with open(temp_creds_path, 'w') as f:
                json.dump(creds_dict, f)
            
            # gspread í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
            scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
            credentials = ServiceAccountCredentials.from_json_keyfile_name(str(temp_creds_path), scope)
            client = gspread.authorize(credentials)
            
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            os.unlink(temp_creds_path)
            
            return client
        except Exception as e:
            logger.error(f"Google Sheets í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return None

    def is_telecom_stats_post(self, title):
        """ê²Œì‹œë¬¼ì´ í†µì‹  í†µê³„ ë³´ê³ ì„œì¸ì§€ í™•ì¸"""
        # "(YYYYë…„ MMì›”ë§ ê¸°ì¤€)" í˜•ì‹ì˜ ë‚ ì§œ íŒ¨í„´ í™•ì¸
        date_pattern = r'\((\d{4})ë…„\s+(\d{1,2})ì›”ë§\s+ê¸°ì¤€\)'
        has_date_pattern = re.search(date_pattern, title) is not None
        
        # ì œëª©ì— ë³´ê³ ì„œ ìœ í˜•ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        contains_report_type = any(report_type in title for report_type in self.report_types)
        
        return has_date_pattern and contains_report_type

    def extract_post_id(self, item):
        """BeautifulSoup í•­ëª©ì—ì„œ ê²Œì‹œë¬¼ ID ì¶”ì¶œ"""
        try:
            link_elem = item.find('a')
            if not link_elem:
                return None
                
            onclick_attr = link_elem.get('onclick', '')
            match = re.search(r"fn_detail\((\d+)\)", onclick_attr)
            if match:
                return match.group(1)
            return None
        except Exception as e:
            logger.error(f"ê²Œì‹œë¬¼ ID ì¶”ì¶œ ì¤‘ ì—ëŸ¬: {str(e)}")
            return None

    def get_post_url(self, post_id):
        """ê²Œì‹œë¬¼ IDë¡œë¶€í„° URL ìƒì„±"""
        if not post_id:
            return None
        return f"https://www.msit.go.kr/bbs/view.do?sCode=user&mId=99&mPid=74&nttSeqNo={post_id}"

    def is_in_date_range(self, date_str, days=4):
        """ê²Œì‹œë¬¼ ë‚ ì§œê°€ ì§€ì •ëœ ë²”ìœ„ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸"""
        try:
            # ë‚ ì§œ ë¬¸ìì—´ ì •ê·œí™”
            date_str = date_str.replace(',', ' ').strip()
            
            # ë‹¤ì–‘í•œ ë‚ ì§œ í˜•ì‹ ì‹œë„
            try:
                # "YYYY. MM. DD" í˜•ì‹
                post_date = datetime.strptime(date_str, '%Y. %m. %d').date()
            except ValueError:
                try:
                    # "MMM DD YYYY" í˜•ì‹
                    post_date = datetime.strptime(date_str, '%b %d %Y').date()
                except ValueError:
                    try:
                        # "YYYY-MM-DD" í˜•ì‹
                        post_date = datetime.strptime(date_str, '%Y-%m-%d').date()
                    except ValueError:
                        # ì •ê·œì‹ìœ¼ë¡œ ì‹œë„
                        match = re.search(r'(\d{4})[.\-\s]+(\d{1,2})[.\-\s]+(\d{1,2})', date_str)
                        if match:
                            year, month, day = map(int, match.groups())
                            post_date = datetime(year, month, day).date()
                        else:
                            logger.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” ë‚ ì§œ í˜•ì‹: {date_str}")
                            return True  # ì•Œ ìˆ˜ ì—†ëŠ” ê²½ìš° í¬í•¨
            
            # ë‚ ì§œ ë²”ìœ„ ê³„ì‚° (í•œêµ­ ì‹œê°„ëŒ€)
            korea_tz = datetime.now() + timedelta(hours=9)  # UTCì—ì„œ KSTë¡œ
            days_ago = (korea_tz - timedelta(days=days)).date()
            
            logger.info(f"ê²Œì‹œë¬¼ ë‚ ì§œ í™•ì¸: {post_date} vs {days_ago} ({days}ì¼ ì „, í•œêµ­ ì‹œê°„ ê¸°ì¤€)")
            return post_date >= days_ago
            
        except Exception as e:
            logger.error(f"ë‚ ì§œ íŒŒì‹± ì—ëŸ¬: {str(e)}")
            return True  # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ì ìœ¼ë¡œ í¬í•¨

    def has_next_page(self, driver):
        """ë‹¤ìŒ í˜ì´ì§€ê°€ ìˆëŠ”ì§€ í™•ì¸"""
        try:
            current_page = int(driver.find_element(By.CSS_SELECTOR, "a.page-link[aria-current='page']").text)
            next_page_link = driver.find_elements(By.CSS_SELECTOR, f"a.page-link[href*='pageIndex={current_page + 1}']")
            return len(next_page_link) > 0
        except Exception as e:
            logger.error(f"ë‹¤ìŒ í˜ì´ì§€ í™•ì¸ ì¤‘ ì—ëŸ¬: {str(e)}")
            return False

    def go_to_next_page(self, driver):
        """ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™"""
        try:
            current_page = int(driver.find_element(By.CSS_SELECTOR, "a.page-link[aria-current='page']").text)
            next_page = driver.find_element(By.CSS_SELECTOR, f"a.page-link[href*='pageIndex={current_page + 1}']")
            next_page.click()
            WebDriverWait(driver, 10).until(
                EC.staleness_of(driver.find_element(By.CSS_SELECTOR, "div.board_list"))
            )
            return True
        except Exception as e:
            logger.error(f"ë‹¤ìŒ í˜ì´ì§€ ì´ë™ ì¤‘ ì—ëŸ¬: {str(e)}")
            return False

    def parse_page(self, driver, days_range=4):
        """í˜„ì¬ í˜ì´ì§€ì—ì„œ ê´€ë ¨ ê²Œì‹œë¬¼ íŒŒì‹±"""
        all_posts = []
        telecom_stats_posts = []
        continue_search = True
        
        try:
            WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.CLASS_NAME, "board_list"))
            )
            
            soup = BeautifulSoup(driver.page_source, 'html.parser')
            posts = soup.find_all('div', {'class': 'toggle'})
            
            for item in posts:
                # í—¤ë” í–‰ ê±´ë„ˆë›°ê¸°
                if 'thead' in item.get('class', []):
                    continue

                try:
                    # ë‚ ì§œ ì •ë³´ ì¶”ì¶œ
                    date_elem = item.find('div', {'class': 'date', 'aria-label': 'ë“±ë¡ì¼'})
                    if not date_elem:
                        date_elem = item.find('div', {'class': 'date'})
                    if not date_elem:
                        continue
                        
                    date_str = date_elem.text.strip()
                    if not date_str or date_str == 'ë“±ë¡ì¼':
                        continue
                    
                    logger.info(f"ë‚ ì§œ ë¬¸ìì—´ ë°œê²¬: {date_str}")
                    
                    # ê²Œì‹œë¬¼ì´ ë‚ ì§œ ë²”ìœ„ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸
                    if not self.is_in_date_range(date_str, days=days_range):
                        continue_search = False
                        break
                    
                    # ì œëª© ë° ê²Œì‹œë¬¼ ID ì¶”ì¶œ
                    title_elem = item.find('p', {'class': 'title'})
                    if not title_elem:
                        continue
                        
                    title = title_elem.text.strip()
                    post_id = self.extract_post_id(item)
                    post_url = self.get_post_url(post_id)
                    
                    # ë¶€ì„œ ì •ë³´ ì¶”ì¶œ
                    dept_elem = item.find('dd', {'id': lambda x: x and 'td_CHRG_DEPT_NM' in x})
                    dept_text = dept_elem.text.strip() if dept_elem else "ë¶€ì„œ ì •ë³´ ì—†ìŒ"
                    
                    # ê²Œì‹œë¬¼ ì •ë³´ ë”•ì…”ë„ˆë¦¬ ìƒì„±
                    post_info = {
                        'title': title,
                        'date': date_str,
                        'department': dept_text,
                        'url': post_url,
                        'post_id': post_id
                    }
                    
                    # ëª¨ë“  ê²Œì‹œë¬¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                    all_posts.append(post_info)
                    
                    # í†µì‹  í†µê³„ ê²Œì‹œë¬¼ì¸ì§€ í™•ì¸
                    if self.is_telecom_stats_post(title):
                        logger.info(f"í†µì‹  í†µê³„ ê²Œì‹œë¬¼ ë°œê²¬: {title}")
                        telecom_stats_posts.append(post_info)
                        
                except Exception as e:
                    logger.error(f"ê²Œì‹œë¬¼ íŒŒì‹± ì¤‘ ì—ëŸ¬: {str(e)}")
                    continue
            
            return all_posts, telecom_stats_posts, continue_search
            
        except Exception as e:
            logger.error(f"í˜ì´ì§€ íŒŒì‹± ì¤‘ ì—ëŸ¬: {str(e)}")
            return [], [], False

    def find_view_link_params(self, driver, post):
        """ê²Œì‹œë¬¼ì—ì„œ ë°”ë¡œë³´ê¸° ë§í¬ íŒŒë¼ë¯¸í„° ì°¾ê¸°"""
        if not post.get('post_id'):
            logger.error(f"ê²Œì‹œë¬¼ ì ‘ê·¼ ë¶ˆê°€ {post['title']} - post_id ëˆ„ë½")
            return None
        
        logger.info(f"ê²Œì‹œë¬¼ ì—´ê¸°: {post['title']}")
        
        # ìµœëŒ€ 3ë²ˆê¹Œì§€ ì¬ì‹œë„
        max_retries = 3
        for attempt in range(max_retries):
            try:
                # ê²Œì‹œë¬¼ ìƒì„¸ í˜ì´ì§€ë¡œ ì´ë™
                detail_url = f"https://www.msit.go.kr/bbs/view.do?sCode=user&mId=99&mPid=74&nttSeqNo={post['post_id']}"
                driver.get(detail_url)
                
                # ëª…ì‹œì ì¸ ëŒ€ê¸° ì‹œê°„ ì¶”ê°€
                time.sleep(3)
                
                # ë‹¤ì–‘í•œ ìš”ì†Œ ì¤‘ í•˜ë‚˜ë¼ë„ ë¡œë“œë˜ë©´ ì„±ê³µìœ¼ë¡œ ê°„ì£¼
                WebDriverWait(driver, 20).until(
                    lambda x: len(x.find_elements(By.CLASS_NAME, "view_head")) > 0 or 
                             len(x.find_elements(By.CLASS_NAME, "view_file")) > 0
                )
                break  # ì„±ê³µí•˜ë©´ ë£¨í”„ ì¢…ë£Œ
            except TimeoutException:
                if attempt < max_retries - 1:
                    logger.warning(f"í˜ì´ì§€ ë¡œë“œ íƒ€ì„ì•„ì›ƒ, ì¬ì‹œë„ {attempt+1}/{max_retries}")
                    time.sleep(3)  # ì¬ì‹œë„ ì „ 3ì´ˆ ëŒ€ê¸°
                else:
                    logger.error(f"{max_retries}ë²ˆ ì‹œë„ í›„ í˜ì´ì§€ ë¡œë“œ ì‹¤íŒ¨")
                    
                    # ì‹œìŠ¤í…œ ì ê²€ í˜ì´ì§€ í™•ì¸
                    if "ì‹œìŠ¤í…œ ì ê²€ ì•ˆë‚´" in driver.page_source:
                        logger.warning("ì‹œìŠ¤í…œ ì ê²€ ì¤‘ì…ë‹ˆë‹¤.")
                        return None
                    
                    return None
            except Exception as e:
                logger.error(f"ê²Œì‹œë¬¼ ìƒì„¸ ì •ë³´ ì ‘ê·¼ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                return None
        
        # ë°”ë¡œë³´ê¸° ë§í¬ ì°¾ê¸°
        try:
            # ì—¬ëŸ¬ ì„ íƒìë¡œ ë°”ë¡œë³´ê¸° ë§í¬ ì°¾ê¸°
            view_links = driver.find_elements(By.CSS_SELECTOR, "a.view[title='ìƒˆì°½ ì—´ë¦¼']")
            
            if not view_links:
                # onclick ì†ì„±ìœ¼ë¡œ ì°¾ê¸°
                all_links = driver.find_elements(By.TAG_NAME, "a")
                view_links = [link for link in all_links if 'getExtension_path' in (link.get_attribute('onclick') or '')]
            
            if not view_links:
                # í…ìŠ¤íŠ¸ë¡œ ì°¾ê¸°
                all_links = driver.find_elements(By.TAG_NAME, "a")
                view_links = [link for link in all_links if 'ë°”ë¡œë³´ê¸°' in (link.text or '')]
            
            if view_links:
                view_link = view_links[0]
                onclick_attr = view_link.get_attribute('onclick')
                logger.info(f"ë°”ë¡œë³´ê¸° ë§í¬ ë°œê²¬, onclick: {onclick_attr}")
                
                # getExtension_path('49234', '1') í˜•ì‹ì—ì„œ ë§¤ê°œë³€ìˆ˜ ì¶”ì¶œ
                match = re.search(r"getExtension_path\s*\(\s*['\"]([\d]+)['\"]?\s*,\s*['\"]([\d]+)['\"]", onclick_attr)
                if match:
                    atch_file_no = match.group(1)
                    file_ord = match.group(2)
                    
                    # ë‚ ì§œ ì •ë³´ ì¶”ì¶œ
                    date_match = re.search(r'\((\d{4})ë…„\s+(\d{1,2})ì›”ë§\s+ê¸°ì¤€\)', post['title'])
                    if date_match:
                        year = int(date_match.group(1))
                        month = int(date_match.group(2))
                        
                        return {
                            'atch_file_no': atch_file_no,
                            'file_ord': file_ord,
                            'date': {'year': year, 'month': month},
                            'post_info': post
                        }
                    
                    return {
                        'atch_file_no': atch_file_no,
                        'file_ord': file_ord,
                        'post_info': post
                    }
            
            # ë°”ë¡œë³´ê¸° ë§í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°
            logger.warning(f"ë°”ë¡œë³´ê¸° ë§í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {post['title']}")
            
            # ë‚ ì§œ ì •ë³´ ì¶”ì¶œ
            date_match = re.search(r'\((\d{4})ë…„\s+(\d{1,2})ì›”ë§\s+ê¸°ì¤€\)', post['title'])
            if date_match:
                year = int(date_match.group(1))
                month = int(date_match.group(2))
                
                # ê²Œì‹œë¬¼ ë‚´ìš© ì¶”ì¶œ
                content_div = driver.find_element(By.CLASS_NAME, "view_cont")
                content = content_div.text if content_div else ""
                
                return {
                    'content': content,
                    'date': {'year': year, 'month': month},
                    'post_info': post
                }
            
            return None
            
        except Exception as e:
            logger.error(f"ë°”ë¡œë³´ê¸° ë§í¬ íŒŒë¼ë¯¸í„° ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return None

    def access_iframe_direct(self, driver, file_params):
        """iframeì— ì§ì ‘ ì ‘ê·¼í•˜ì—¬ ë°ì´í„° ì¶”ì¶œ"""
        if not file_params or not file_params.get('atch_file_no') or not file_params.get('file_ord'):
            logger.error("íŒŒì¼ íŒŒë¼ë¯¸í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        atch_file_no = file_params['atch_file_no']
        file_ord = file_params['file_ord']
        
        # ë°”ë¡œë³´ê¸° URL êµ¬ì„±
        view_url = f"https://www.msit.go.kr/bbs/documentView.do?atchFileNo={atch_file_no}&fileOrdr={file_ord}"
        logger.info(f"ë°”ë¡œë³´ê¸° URL: {view_url}")
        
        try:
            # í˜ì´ì§€ ë¡œë“œ
            driver.get(view_url)
            time.sleep(5)  # í˜ì´ì§€ ë¡œë“œ ëŒ€ê¸°
            
            # í˜„ì¬ ì°½ í•¸ë“¤ ì €ì¥
            original_handle = driver.current_window_handle
            
            # ìƒˆ ì°½ì´ ì—´ë ¸ëŠ”ì§€ í™•ì¸
            if len(driver.window_handles) > 1:
                logger.info("ìƒˆ ì°½ì´ ì—´ë ¸ìŠµë‹ˆë‹¤. ì „í™˜ ì‹œë„...")
                for handle in driver.window_handles:
                    if handle != original_handle:
                        driver.switch_to.window(handle)
                        break
            
            # í˜„ì¬ URL í™•ì¸
            current_url = driver.current_url
            logger.info(f"í˜„ì¬ URL: {current_url}")
            
            # SynapDocViewServer í™•ì¸
            if 'SynapDocViewServer' in current_url:
                logger.info("SynapDocViewServer ê°ì§€ë¨")
                
                # ì‹œíŠ¸ ëª©ë¡ í™•ì¸
                sheet_tabs = driver.find_elements(By.CSS_SELECTOR, ".sheet-list__sheet-tab")
                
                if sheet_tabs:
                    logger.info(f"ì‹œíŠ¸ íƒ­ {len(sheet_tabs)}ê°œ ë°œê²¬")
                    
                    all_sheets = {}
                    
                    # ê° ì‹œíŠ¸ ì²˜ë¦¬
                    for i, tab in enumerate(sheet_tabs):
                        sheet_name = tab.text.strip()
                        logger.info(f"ì‹œíŠ¸ {i+1}/{len(sheet_tabs)} ì²˜ë¦¬ ì¤‘: {sheet_name}")
                        
                        # ì²« ë²ˆì§¸ê°€ ì•„ë‹Œ ì‹œíŠ¸ëŠ” í´ë¦­í•˜ì—¬ ì „í™˜
                        if i > 0:
                            try:
                                tab.click()
                                time.sleep(3)  # ì‹œíŠ¸ ì „í™˜ ëŒ€ê¸°
                            except Exception as click_err:
                                logger.error(f"ì‹œíŠ¸ íƒ­ í´ë¦­ ì‹¤íŒ¨: {str(click_err)}")
                                continue
                        
                        try:
                            # iframe ì°¾ê¸°
                            iframe = driver.find_element(By.ID, "innerWrap")
                            
                            # iframeìœ¼ë¡œ ì „í™˜
                            driver.switch_to.frame(iframe)
                            
                            # í˜ì´ì§€ ì†ŒìŠ¤ ê°€ì ¸ì˜¤ê¸°
                            iframe_html = driver.page_source
                            
                            # í…Œì´ë¸” ì¶”ì¶œ
                            df = self.extract_table_from_html(iframe_html)
                            
                            # ê¸°ë³¸ í”„ë ˆì„ìœ¼ë¡œ ë³µê·€
                            driver.switch_to.default_content()
                            
                            if df is not None and not df.empty:
                                all_sheets[sheet_name] = df
                                logger.info(f"ì‹œíŠ¸ '{sheet_name}'ì—ì„œ ë°ì´í„°í”„ë ˆì„ ì¶”ì¶œ ì„±ê³µ: {df.shape}")
                            else:
                                logger.warning(f"ì‹œíŠ¸ '{sheet_name}'ì—ì„œ í…Œì´ë¸” ì¶”ì¶œ ì‹¤íŒ¨")
                                
                        except Exception as iframe_err:
                            logger.error(f"iframe ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(iframe_err)}")
                            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ í”„ë ˆì„ìœ¼ë¡œ ë³µê·€
                            driver.switch_to.default_content()
                    
                    # ëª¨ë“  ì‹œíŠ¸ ì²˜ë¦¬ í›„ ê²°ê³¼ ë°˜í™˜
                    if all_sheets:
                        logger.info(f"ì´ {len(all_sheets)}ê°œ ì‹œíŠ¸ì—ì„œ ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ")
                        return all_sheets
                    else:
                        logger.warning("ì–´ë–¤ ì‹œíŠ¸ì—ì„œë„ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                        return None
                        
                else:
                    # ì‹œíŠ¸ íƒ­ì´ ì—†ëŠ” ê²½ìš° ë‹¨ì¼ iframe ì²˜ë¦¬
                    logger.info("ì‹œíŠ¸ íƒ­ì´ ì—†ìŠµë‹ˆë‹¤. ë‹¨ì¼ iframe ì²˜ë¦¬ ì‹œë„...")
                    
                    try:
                        # iframe ì°¾ê¸°
                        iframe = driver.find_element(By.ID, "innerWrap")
                        
                        # iframeìœ¼ë¡œ ì „í™˜
                        driver.switch_to.frame(iframe)
                        
                        # í˜ì´ì§€ ì†ŒìŠ¤ ê°€ì ¸ì˜¤ê¸°
                        iframe_html = driver.page_source
                        
                        # í…Œì´ë¸” ì¶”ì¶œ
                        df = self.extract_table_from_html(iframe_html)
                        
                        # ê¸°ë³¸ í”„ë ˆì„ìœ¼ë¡œ ë³µê·€
                        driver.switch_to.default_content()
                        
                        if df is not None and not df.empty:
                            logger.info(f"ë‹¨ì¼ iframeì—ì„œ ë°ì´í„°í”„ë ˆì„ ì¶”ì¶œ ì„±ê³µ: {df.shape}")
                            return {"ê¸°ë³¸ ì‹œíŠ¸": df}
                        else:
                            logger.warning("iframeì—ì„œ í…Œì´ë¸” ì¶”ì¶œ ì‹¤íŒ¨")
                            return None
                            
                    except Exception as single_iframe_err:
                        logger.error(f"ë‹¨ì¼ iframe ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(single_iframe_err)}")
                        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ í”„ë ˆì„ìœ¼ë¡œ ë³µê·€
                        driver.switch_to.default_content()
                        return None
            
            else:
                # ì¼ë°˜ HTML í˜ì´ì§€ì—ì„œ í…Œì´ë¸” ì°¾ê¸°
                logger.info("ì¼ë°˜ HTML í˜ì´ì§€ì—ì„œ í…Œì´ë¸” ê²€ìƒ‰")
                
                try:
                    # í…Œì´ë¸” ì°¾ê¸°
                    tables = pd.read_html(driver.page_source)
                    
                    if tables:
                        logger.info(f"{len(tables)}ê°œ í…Œì´ë¸” ë°œê²¬")
                        
                        # ê°€ì¥ í° í…Œì´ë¸” ì„ íƒ
                        largest_table = max(tables, key=lambda t: t.size)
                        
                        logger.info(f"ê°€ì¥ í° í…Œì´ë¸” ì„ íƒ: {largest_table.shape}")
                        return {"ê¸°ë³¸ í…Œì´ë¸”": largest_table}
                    else:
                        logger.warning("í˜ì´ì§€ì—ì„œ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        return None
                        
                except Exception as table_err:
                    logger.error(f"HTML í…Œì´ë¸” ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(table_err)}")
                    return None
            
        except Exception as e:
            logger.error(f"iframe ì§ì ‘ ì ‘ê·¼ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return None

    def extract_table_from_html(self, html_content):
        """HTML ë‚´ìš©ì—ì„œ í…Œì´ë¸” ì¶”ì¶œ"""
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # í…Œì´ë¸” ìš”ì†Œ ì°¾ê¸°
            tables = soup.find_all('table')
            if not tables:
                logger.warning("HTMLì—ì„œ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                return None
            
            # ê°€ì¥ í° í…Œì´ë¸” ì„ íƒ (ë°ì´í„° í–‰ì´ ê°€ì¥ ë§ì€ í…Œì´ë¸”)
            largest_table = max(tables, key=lambda t: len(t.find_all('tr')))
            
            # í…Œì´ë¸” ë°ì´í„° ì¶”ì¶œ
            rows = []
            for tr in largest_table.find_all('tr'):
                row = [td.get_text(strip=True) for td in tr.find_all(['td', 'th'])]
                if row and any(row):  # ë¹ˆ í–‰ ì œì™¸
                    rows.append(row)
            
            # ë°ì´í„°ê°€ ì¶©ë¶„í•œì§€ í™•ì¸
            if len(rows) < 2:
                logger.warning("í…Œì´ë¸” ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŒ")
                return None
            
            # ì²« í–‰ì„ í—¤ë”ë¡œ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°í”„ë ˆì„ ìƒì„±
            df = pd.DataFrame(rows[1:], columns=rows[0])
            logger.info(f"í…Œì´ë¸” ì¶”ì¶œ ì„±ê³µ: {df.shape[0]}í–‰ {df.shape[1]}ì—´")
            return df

        
        except Exception as e:
            logger.error(f"HTMLì—ì„œ í…Œì´ë¸” ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return None

    def create_placeholder_dataframe(self, post_info):
        """ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë°ì´í„°í”„ë ˆì„ ìƒì„±"""
        try:
            # ë‚ ì§œ ì •ë³´ ì¶”ì¶œ
            date_match = re.search(r'\((\d{4})ë…„\s+(\d{1,2})ì›”ë§\s+ê¸°ì¤€\)', post_info['title'])
            if date_match:
                year = date_match.group(1)
                month = date_match.group(2)
                
                # ë³´ê³ ì„œ ìœ í˜• ê²°ì •
                report_type = self.determine_report_type(post_info['title'])
                
                # ê¸°ë³¸ ë°ì´í„°í”„ë ˆì„ ìƒì„±
                df = pd.DataFrame({
                    'êµ¬ë¶„': [f'{year}ë…„ {month}ì›” í†µê³„'],
                    'ê°’': ['ë°ì´í„°ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤'],
                    'ë¹„ê³ ': [f'{post_info["title"]} - ì ‘ê·¼ ì˜¤ë¥˜']
                })
                
                logger.info(f"í”Œë ˆì´ìŠ¤í™€ë” ë°ì´í„°í”„ë ˆì„ ìƒì„±: {year}ë…„ {month}ì›” {report_type}")
                return df
                
            return pd.DataFrame()  # ë‚ ì§œ ì •ë³´ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë°ì´í„°í”„ë ˆì„ ë°˜í™˜
            
        except Exception as e:
            logger.error(f"í”Œë ˆì´ìŠ¤í™€ë” ë°ì´í„°í”„ë ˆì„ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return pd.DataFrame()  # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¹ˆ ë°ì´í„°í”„ë ˆì„ ë°˜í™˜

    def determine_report_type(self, title):
        """ê²Œì‹œë¬¼ ì œëª©ì—ì„œ ë³´ê³ ì„œ ìœ í˜• ê²°ì •"""
        for report_type in self.report_types:
            if report_type in title:
                return report_type
        return "ê¸°íƒ€ í†µì‹  í†µê³„"

    def update_google_sheets(self, client, data):
        """Google Sheets ì—…ë°ì´íŠ¸"""
        if not client or not data:
            logger.error("Google Sheets ì—…ë°ì´íŠ¸ ë¶ˆê°€: í´ë¼ì´ì–¸íŠ¸ ë˜ëŠ” ë°ì´í„° ì—†ìŒ")
            return False
        
        try:
            # ì •ë³´ ì¶”ì¶œ
            post_info = data['post_info']
            
            # ë‚ ì§œ ì •ë³´ê°€ ì§ì ‘ ì œê³µë˜ì—ˆëŠ”ì§€ í™•ì¸
            if 'date' in data:
                year = data['date']['year']
                month = data['date']['month']
            else:
                # ì œëª©ì—ì„œ ë‚ ì§œ ì •ë³´ ì¶”ì¶œ
                date_match = re.search(r'\((\d{4})ë…„\s+(\d{1,2})ì›”ë§\s+ê¸°ì¤€\)', post_info['title'])
                if not date_match:
                    logger.error(f"ì œëª©ì—ì„œ ë‚ ì§œë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŒ: {post_info['title']}")
                    return False
                    
                year = int(date_match.group(1))
                month = int(date_match.group(2))
            
            # ë‚ ì§œ ë¬¸ìì—´ í¬ë§·
            date_str = f"{year}ë…„ {month}ì›”"
            report_type = self.determine_report_type(post_info['title'])
            
            # ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì—´ê¸°
            try:
                # IDë¡œ ë¨¼ì € ì‹œë„
                if self.spreadsheet_id:
                    try:
                        spreadsheet = client.open_by_key(self.spreadsheet_id)
                        logger.info(f"IDë¡œ ê¸°ì¡´ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì°¾ìŒ: {self.spreadsheet_id}")
                    except gspread.exceptions.APIError:
                        logger.warning(f"IDë¡œ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ë¥¼ ì—´ ìˆ˜ ì—†ìŒ: {self.spreadsheet_id}")
                        spreadsheet = None
                else:
                    spreadsheet = None
                
                # IDë¡œ ì°¾ì§€ ëª»í•œ ê²½ìš° ì´ë¦„ìœ¼ë¡œ ì‹œë„
                if not spreadsheet:
                    try:
                        spreadsheet = client.open(self.spreadsheet_name)
                        logger.info(f"ì´ë¦„ìœ¼ë¡œ ê¸°ì¡´ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì°¾ìŒ: {self.spreadsheet_name}")
                    except gspread.exceptions.SpreadsheetNotFound:
                        # ìƒˆ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ìƒì„±
                        spreadsheet = client.create(self.spreadsheet_name)
                        logger.info(f"ìƒˆ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ìƒì„±: {self.spreadsheet_name}")
                        
                        # ì°¸ì¡°ìš© ID ê¸°ë¡
                        logger.info(f"ìƒˆ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ID: {spreadsheet.id}")
            except Exception as e:
                logger.error(f"Google Sheets ì—´ê¸° ì¤‘ ì˜¤ë¥˜: {str(e)}")
                return False
            
            # ì‹œíŠ¸ ë°ì´í„° ì—¬ë¶€ í™•ì¸
            if 'sheets' in data:
                # ì—¬ëŸ¬ ì‹œíŠ¸ ì²˜ë¦¬
                for sheet_name, df in data['sheets'].items():
                    success = self.update_single_sheet(spreadsheet, sheet_name, df, date_str)
                    if not success:
                        logger.warning(f"ì‹œíŠ¸ '{sheet_name}' ì—…ë°ì´íŠ¸ ì‹¤íŒ¨")
                
                return True  # ìµœì†Œí•œ í•˜ë‚˜ì˜ ì‹œíŠ¸ëŠ” ì—…ë°ì´íŠ¸ ì‹œë„ë¨
                
            elif 'dataframe' in data:
                # ë‹¨ì¼ ë°ì´í„°í”„ë ˆì„ ì²˜ë¦¬
                return self.update_single_sheet(spreadsheet, report_type, data['dataframe'], date_str)
                
            else:
                logger.error("ì—…ë°ì´íŠ¸í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                return False
                
        except Exception as e:
            logger.error(f"Google Sheets ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return False

    def update_single_sheet(self, spreadsheet, sheet_name, df, date_str):
        """ë‹¨ì¼ ì‹œíŠ¸ ì—…ë°ì´íŠ¸"""
        try:
            # ì›Œí¬ì‹œíŠ¸ ì°¾ê¸° ë˜ëŠ” ìƒì„±
            try:
                worksheet = spreadsheet.worksheet(sheet_name)
                logger.info(f"ê¸°ì¡´ ì›Œí¬ì‹œíŠ¸ ì°¾ìŒ: {sheet_name}")
            except gspread.exceptions.WorksheetNotFound:
                worksheet = spreadsheet.add_worksheet(title=sheet_name, rows="1000", cols="50")
                worksheet.update_cell(1, 1, "í•­ëª©")
                logger.info(f"ìƒˆ ì›Œí¬ì‹œíŠ¸ ìƒì„±: {sheet_name}")
            
            # ë‚ ì§œ ì—´ í™•ì¸
            headers = worksheet.row_values(1)
            if date_str in headers:
                col_idx = headers.index(date_str) + 1
                logger.info(f"'{date_str}' ì—´ì´ ì´ë¯¸ ìœ„ì¹˜ {col_idx}ì— ì¡´ì¬í•©ë‹ˆë‹¤")
            else:
                # ìƒˆ ë‚ ì§œ ì—´ ì¶”ê°€
                col_idx = len(headers) + 1
                worksheet.update_cell(1, col_idx, date_str)
                logger.info(f"ìœ„ì¹˜ {col_idx}ì— ìƒˆ ì—´ '{date_str}' ì¶”ê°€")
            
            # ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ì‹œíŠ¸ ì—…ë°ì´íŠ¸
            self.update_sheet_from_dataframe(worksheet, df, col_idx)
            
            logger.info(f"ì›Œí¬ì‹œíŠ¸ '{sheet_name}'ì— '{date_str}' ë°ì´í„° ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"ì‹œíŠ¸ '{sheet_name}' ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return False

    def update_sheet_from_dataframe(self, worksheet, df, col_idx):
        """ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ì›Œí¬ì‹œíŠ¸ ì—…ë°ì´íŠ¸"""
        try:
            # ê¸°ì¡´ í•­ëª© (ì²« ë²ˆì§¸ ì—´) ê°€ì ¸ì˜¤ê¸°
            existing_items = worksheet.col_values(1)[1:]  # í—¤ë” ì œì™¸
            
            if df.shape[0] > 0:
                # ë°ì´í„°í”„ë ˆì„ì—ì„œ í•­ëª©ê³¼ ê°’ ì¶”ì¶œ
                # ì²« ë²ˆì§¸ ì—´ì€ í•­ëª©, ë‘ ë²ˆì§¸ ì—´ì€ ê°’ìœ¼ë¡œ ê°€ì •
                if df.shape[1] >= 2:
                    new_items = df.iloc[:, 0].astype(str).tolist()
                    values = df.iloc[:, 1].astype(str).tolist()
                    
                    # ë°°ì¹˜ ì—…ë°ì´íŠ¸ ì¤€ë¹„
                    cell_updates = []
                    
                    for i, (item, value) in enumerate(zip(new_items, values)):
                        if item and not pd.isna(item):  # ë¹ˆ í•­ëª© ì œì™¸
                            # í•­ëª©ì´ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
                            if item in existing_items:
                                row_idx = existing_items.index(item) + 2  # í—¤ë”ì™€ 0-ì¸ë±ìŠ¤ ë³´ì •
                            else:
                                # ìƒˆ í•­ëª© ì¶”ê°€
                                row_idx = len(existing_items) + 2
                                # í•­ëª© ì—…ë°ì´íŠ¸
                                cell_updates.append({
                                    'range': f'A{row_idx}',
                                    'values': [[item]]
                                })
                                existing_items.append(item)
                            
                            # ê°’ ì—…ë°ì´íŠ¸
                            value_to_update = "" if pd.isna(value) else value
                            cell_updates.append({
                                'range': f'{chr(64 + col_idx)}{row_idx}',
                                'values': [[value_to_update]]
                            })
                    
                    # ì¼ê´„ ì—…ë°ì´íŠ¸ ì‹¤í–‰
                    if cell_updates:
                        worksheet.batch_update(cell_updates)
                        logger.info(f"{len(cell_updates)}ê°œ ì…€ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
                        
            return True
            
        except Exception as e:
            logger.error(f"ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ì›Œí¬ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return False

    async def send_telegram_message(self, posts, data_updates=None):
        """í…”ë ˆê·¸ë¨ìœ¼ë¡œ ì•Œë¦¼ ë©”ì‹œì§€ ì „ì†¡"""
        if not posts and not data_updates:
            logger.info("ì•Œë¦¼ì„ ë³´ë‚¼ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤")
            return
            
        try:
            message = "ğŸ“Š *MSIT í†µì‹  í†µê³„ ëª¨ë‹ˆí„°ë§*\n\n"
            
            # ìƒˆ ê²Œì‹œë¬¼ ì •ë³´ ì¶”ê°€
            if posts:
                message += "ğŸ“± *ìƒˆë¡œìš´ í†µì‹  ê´€ë ¨ ê²Œì‹œë¬¼*\n\n"
                
                for post in posts:
                    message += f"ğŸ“… {post['date']}\n"
                    message += f"ğŸ“‘ {post['title']}\n"
                    message += f"ğŸ¢ {post['department']}\n"
                    if post.get('url'):
                        message += f"ğŸ”— [ê²Œì‹œë¬¼ ë§í¬]({post['url']})\n"
                    message += "\n"
            
            # ë°ì´í„° ì—…ë°ì´íŠ¸ ì •ë³´ ì¶”ê°€
            if data_updates:
                message += "ğŸ“Š *Google Sheets ë°ì´í„° ì—…ë°ì´íŠ¸*\n\n"
                
                for update in data_updates:
                    post_info = update['post_info']
                    
                    # ë‚ ì§œ ì •ë³´ ì¶”ì¶œ
                    if 'date' in update:
                        year = update['date']['year']
                        month = update['date']['month']
                    else:
                        date_match = re.search(r'\((\d{4})ë…„\s+(\d{1,2})ì›”ë§\s+ê¸°ì¤€\)', post_info['title'])
                        if date_match:
                            year = date_match.group(1)
                            month = date_match.group(2)
                        else:
                            year = "ì•Œ ìˆ˜ ì—†ìŒ"
                            month = "ì•Œ ìˆ˜ ì—†ìŒ"
                    
                    date_str = f"{year}ë…„ {month}ì›”"
                    report_type = self.determine_report_type(post_info['title'])
                    
                    message += f"ğŸ“… *{date_str}*\n"
                    message += f"ğŸ“‘ {report_type}\n"
                    message += f"ğŸ“— ì—…ë°ì´íŠ¸ ì™„ë£Œ\n\n"
            
            # ë©”ì‹œì§€ ì „ì†¡
            chat_id = int(self.chat_id)
            await self.bot.send_message(
                chat_id=chat_id,
                text=message,
                parse_mode='Markdown'
            )
            logger.info("í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ ì „ì†¡ ì„±ê³µ")
            
        except Exception as e:
            logger.error(f"í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ ì „ì†¡ ì¤‘ ì˜¤ë¥˜: {str(e)}")

    async def run_monitor(self, days_range=4, check_sheets=True):
        """ëª¨ë‹ˆí„°ë§ ì‹¤í–‰"""
        driver = None
        gs_client = None
        
        try:
            # WebDriver ì´ˆê¸°í™”
            driver = self.setup_driver()
            logger.info("WebDriver ì´ˆê¸°í™” ì™„ë£Œ")
            
            # Google Sheets í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
            if check_sheets and self.gspread_creds:
                gs_client = self.setup_gspread_client()
                if gs_client:
                    logger.info("Google Sheets í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
                else:
                    logger.warning("Google Sheets í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨")
            
            # MSIT ì›¹ì‚¬ì´íŠ¸ë¡œ ì´ë™
            driver.get(self.url)
            logger.info("MSIT ì›¹ì‚¬ì´íŠ¸ ì ‘ê·¼ ì™„ë£Œ")
            
            # ëª¨ë“  ê²Œì‹œë¬¼ ë° í†µì‹  í†µê³„ ê²Œì‹œë¬¼ ì¶”ì 
            all_posts = []
            telecom_stats_posts = []
            continue_search = True
            
            # í˜ì´ì§€ íŒŒì‹±
            while continue_search:
                page_posts, stats_posts, should_continue = self.parse_page(driver, days_range=days_range)
                all_posts.extend(page_posts)
                telecom_stats_posts.extend(stats_posts)
                
                if not should_continue:
                    break
                    
                if self.has_next_page(driver):
                    if not self.go_to_next_page(driver):
                        break
                else:
                    break
            
            # í†µì‹  í†µê³„ ê²Œì‹œë¬¼ ì²˜ë¦¬
            data_updates = []
            
            if gs_client and telecom_stats_posts and check_sheets:
                logger.info(f"{len(telecom_stats_posts)}ê°œ í†µì‹  í†µê³„ ê²Œì‹œë¬¼ ì²˜ë¦¬ ì¤‘")
                
                for post in telecom_stats_posts:
                    try:
                        # ë°”ë¡œë³´ê¸° ë§í¬ íŒŒë¼ë¯¸í„° ì¶”ì¶œ
                        file_params = self.find_view_link_params(driver, post)
                        
                        if not file_params:
                            logger.warning(f"ë°”ë¡œë³´ê¸° ë§í¬ íŒŒë¼ë¯¸í„° ì¶”ì¶œ ì‹¤íŒ¨: {post['title']}")
                            continue
                        
                        # ë°”ë¡œë³´ê¸° ë§í¬ê°€ ìˆëŠ” ê²½ìš°
                        if 'atch_file_no' in file_params and 'file_ord' in file_params:
                            # iframe ì§ì ‘ ì ‘ê·¼í•˜ì—¬ ë°ì´í„° ì¶”ì¶œ
                            sheets_data = self.access_iframe_direct(driver, file_params)
                            
                            if sheets_data:
                                # Google Sheets ì—…ë°ì´íŠ¸
                                update_data = {
                                    'sheets': sheets_data,
                                    'post_info': post
                                }
                                
                                if 'date' in file_params:
                                    update_data['date'] = file_params['date']
                                
                                success = self.update_google_sheets(gs_client, update_data)
                                if success:
                                    logger.info(f"Google Sheets ì—…ë°ì´íŠ¸ ì„±ê³µ: {post['title']}")
                                    data_updates.append(update_data)
                                else:
                                    logger.warning(f"Google Sheets ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {post['title']}")
                            else:
                                logger.warning(f"iframeì—ì„œ ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {post['title']}")
                                
                                # ëŒ€ì²´ ë°ì´í„° ìƒì„±
                                placeholder_df = self.create_placeholder_dataframe(post)
                                if not placeholder_df.empty:
                                    update_data = {
                                        'dataframe': placeholder_df,
                                        'post_info': post
                                    }
                                    
                                    if 'date' in file_params:
                                        update_data['date'] = file_params['date']
                                    
                                    success = self.update_google_sheets(gs_client, update_data)
                                    if success:
                                        logger.info(f"ëŒ€ì²´ ë°ì´í„°ë¡œ ì—…ë°ì´íŠ¸ ì„±ê³µ: {post['title']}")
                                        data_updates.append(update_data)
                        
                        # ê²Œì‹œë¬¼ ë‚´ìš©ë§Œ ìˆëŠ” ê²½ìš°
                        elif 'content' in file_params:
                            logger.info(f"ê²Œì‹œë¬¼ ë‚´ìš©ìœ¼ë¡œ ì²˜ë¦¬ ì¤‘: {post['title']}")
                            
                            # ëŒ€ì²´ ë°ì´í„° ìƒì„±
                            placeholder_df = self.create_placeholder_dataframe(post)
                            if not placeholder_df.empty:
                                update_data = {
                                    'dataframe': placeholder_df,
                                    'post_info': post
                                }
                                
                                if 'date' in file_params:
                                    update_data['date'] = file_params['date']
                                
                                success = self.update_google_sheets(gs_client, update_data)
                                if success:
                                    logger.info(f"ë‚´ìš© ê¸°ë°˜ ë°ì´í„°ë¡œ ì—…ë°ì´íŠ¸ ì„±ê³µ: {post['title']}")
                                    data_updates.append(update_data)
                    
                    except Exception as e:
                        logger.error(f"ê²Œì‹œë¬¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            
            # í…”ë ˆê·¸ë¨ ì•Œë¦¼ ì „ì†¡
            if all_posts or data_updates:
                await self.send_telegram_message(all_posts, data_updates)
            else:
                logger.info(f"ìµœê·¼ {days_range}ì¼ ë‚´ ìƒˆ ê²Œì‹œë¬¼ì´ ì—†ìŠµë‹ˆë‹¤")
        
        except Exception as e:
            logger.error(f"ëª¨ë‹ˆí„°ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            
            try:
                # ì˜¤ë¥˜ ì•Œë¦¼ ì „ì†¡
                error_post = {
                    'title': f"ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {str(e)}",
                    'date': datetime.now().strftime('%Y. %m. %d'),
                    'department': 'System Error'
                }
                await self.send_telegram_message([error_post])
            except Exception as telegram_err:
                logger.error(f"ì˜¤ë¥˜ ì•Œë¦¼ ì „ì†¡ ì¤‘ ì¶”ê°€ ì˜¤ë¥˜: {str(telegram_err)}")
        
        finally:
            # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
            if driver:
                driver.quit()
                logger.info("WebDriver ì¢…ë£Œ")

async def main():
    # í™˜ê²½ ë³€ìˆ˜ ê°€ì ¸ì˜¤ê¸°
    days_range = int(os.environ.get('DAYS_RANGE', '4'))
    check_sheets = os.environ.get('CHECK_SHEETS', 'true').lower() == 'true'
    
    # ëª¨ë‹ˆí„° ìƒì„± ë° ì‹¤í–‰
    try:
        logger.info(f"MSIT ëª¨ë‹ˆí„° ì‹œì‘ - days_range={days_range}, check_sheets={check_sheets}")
        logger.info(f"ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì´ë¦„: {os.environ.get('SPREADSHEET_NAME', 'MSIT í†µì‹  í†µê³„')}")
        
        monitor = MSITMonitor()
        await monitor.run_monitor(days_range=days_range, check_sheets=check_sheets)
    except Exception as e:
        logging.error(f"ë©”ì¸ í•¨ìˆ˜ ì˜¤ë¥˜: {str(e)}", exc_info=True)

if __name__ == "__main__":
    asyncio.run(main())
