import os
import re    
import json
import time
import logging
import asyncio
from datetime import datetime, timedelta
from pathlib import Path
import pandas as pd

from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException

from bs4 import BeautifulSoup
import telegram
import gspread
from oauth2client.service_account import ServiceAccountCredentials

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('msit_monitor')

class MSITMonitor:
    def __init__(self):
        # Telegram ì„¤ì •
        self.telegram_token = os.environ.get('TELCO_NEWS_TOKEN')
        self.chat_id = os.environ.get('TELCO_NEWS_TESTER')
        if not self.telegram_token or not self.chat_id:
            raise ValueError("í™˜ê²½ ë³€ìˆ˜ TELCO_NEWS_TOKENê³¼ TELCO_NEWS_TESTERê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        # Google Sheets ì„¤ì •
        self.gspread_creds = os.environ.get('MSIT_GSPREAD_ref')
        self.spreadsheet_id = os.environ.get('MSIT_SPREADSHEET_ID')
        self.spreadsheet_name = os.environ.get('SPREADSHEET_NAME', 'MSIT í†µì‹  í†µê³„')
    
        if not self.gspread_creds:
            logger.warning("í™˜ê²½ ë³€ìˆ˜ MSIT_GSPREAD_refê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Google Sheets ì—…ë°ì´íŠ¸ëŠ” ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
        
        # MSIT URL
        self.url = "https://www.msit.go.kr/bbs/list.do?sCode=user&mPid=74&mId=99"
        
        # Telegram ë´‡ ì´ˆê¸°í™”
        self.bot = telegram.Bot(token=self.telegram_token)
        
        # ì¶”ì í•  ë³´ê³ ì„œ ìœ í˜•
        self.report_types = [
            "ì´ë™ì „í™” ë° íŠ¸ë˜í”½ í†µê³„",
            "ì´ë™ì „í™” ë° ì‹œë‚´ì „í™” ë²ˆí˜¸ì´ë™ í˜„í™©",
            "ìœ ì„ í†µì‹ ì„œë¹„ìŠ¤ ê°€ì… í˜„í™©",
            "ë¬´ì„ í†µì‹ ì„œë¹„ìŠ¤ ê°€ì… í˜„í™©", 
            "íŠ¹ìˆ˜ë¶€ê°€í†µì‹ ì‚¬ì—…ìí˜„í™©",
            "ë¬´ì„ ë°ì´í„° íŠ¸ë˜í”½ í†µê³„",
            "ìœ Â·ë¬´ì„ í†µì‹ ì„œë¹„ìŠ¤ ê°€ì… í˜„í™© ë° ë¬´ì„ ë°ì´í„° íŠ¸ë˜í”½ í†µê³„"
        ]
        
        # ì„ì‹œ ë””ë ‰í† ë¦¬
        self.temp_dir = Path("./downloads")
        self.temp_dir.mkdir(exist_ok=True)

    def setup_driver(self):
        """Selenium WebDriver ì„¤ì •"""
        options = Options()
        #options.add_argument('--headless')
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--disable-gpu')
        options.add_argument('--window-size=1920,1080')

        # ì‚¬ìš©ì ì—ì´ì „íŠ¸ ë³€ê²½
        options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36")
        # ìë™í™” ê°ì§€ ìš°íšŒë¥¼ ìœ„í•œ ì˜µì…˜ ì¶”ê°€
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option("useAutomationExtension", False)
        options.add_argument("--disable-blink-features=AutomationControlled")
        
        # ì„±ëŠ¥ ìµœì í™” ì„¤ì •
        prefs = {
            "profile.default_content_setting_values.images": 2  # ì´ë¯¸ì§€ ë¡œë”© ë¹„í™œì„±í™”
        }
        options.add_experimental_option("prefs", prefs)
        
        # ë¶ˆí•„ìš”í•œ ë¡œê·¸ ë¹„í™œì„±í™”
        options.add_experimental_option('excludeSwitches', ['enable-logging'])
        
        # ì„œë¹„ìŠ¤ ì„¤ì •
        if os.path.exists('/usr/bin/chromium-browser'):
            options.binary_location = '/usr/bin/chromium-browser'
            service = Service('/usr/bin/chromedriver')
        else:
            try:
                from webdriver_manager.chrome import ChromeDriverManager
                service = Service(ChromeDriverManager().install())
            except ImportError:
                service = Service('/usr/bin/chromedriver')
        
        driver = webdriver.Chrome(service=service, options=options)
        driver.set_page_load_timeout(60)
        
        # Selenium Stealth ì ìš©
        from selenium_stealth import stealth
        stealth(driver,
                languages=["ko-KR", "ko"],
                vendor="Google Inc.",
                platform="Win32",
                webgl_vendor="Intel Inc.",
                renderer="Intel Iris OpenGL Engine",
                fix_hairline=True)
        return driver

    def setup_gspread_client(self):
        """Google Sheets í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        if not self.gspread_creds:
            return None
        
        try:
            # í™˜ê²½ ë³€ìˆ˜ì—ì„œ ìê²© ì¦ëª… íŒŒì‹±
            creds_dict = json.loads(self.gspread_creds)
            
            # ì„ì‹œ íŒŒì¼ì— ìê²© ì¦ëª… ì €ì¥
            temp_creds_path = self.temp_dir / "temp_creds.json"
            with open(temp_creds_path, 'w') as f:
                json.dump(creds_dict, f)
            
            # gspread í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
            scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
            credentials = ServiceAccountCredentials.from_json_keyfile_name(str(temp_creds_path), scope)
            client = gspread.authorize(credentials)
            
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            os.unlink(temp_creds_path)
            
            return client
        except Exception as e:
            logger.error(f"Google Sheets í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return None

    def is_telecom_stats_post(self, title):
        """ê²Œì‹œë¬¼ì´ í†µì‹  í†µê³„ ë³´ê³ ì„œì¸ì§€ í™•ì¸"""
        # "(YYYYë…„ MMì›”ë§ ê¸°ì¤€)" í˜•ì‹ì˜ ë‚ ì§œ íŒ¨í„´ í™•ì¸
        date_pattern = r'\((\d{4})ë…„\s+(\d{1,2})ì›”ë§\s+ê¸°ì¤€\)'
        has_date_pattern = re.search(date_pattern, title) is not None
        
        # ì œëª©ì— ë³´ê³ ì„œ ìœ í˜•ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        contains_report_type = any(report_type in title for report_type in self.report_types)
        
        return has_date_pattern and contains_report_type

    def extract_post_id(self, item):
        """BeautifulSoup í•­ëª©ì—ì„œ ê²Œì‹œë¬¼ ID ì¶”ì¶œ"""
        try:
            link_elem = item.find('a')
            if not link_elem:
                return None
                
            onclick_attr = link_elem.get('onclick', '')
            match = re.search(r"fn_detail\((\d+)\)", onclick_attr)
            if match:
                return match.group(1)
            return None
        except Exception as e:
            logger.error(f"ê²Œì‹œë¬¼ ID ì¶”ì¶œ ì¤‘ ì—ëŸ¬: {str(e)}")
            return None

    def get_post_url(self, post_id):
        """ê²Œì‹œë¬¼ IDë¡œë¶€í„° URL ìƒì„±"""
        if not post_id:
            return None
        return f"https://www.msit.go.kr/bbs/view.do?sCode=user&mId=99&mPid=74&nttSeqNo={post_id}"

    def is_in_date_range(self, date_str, days=4):
        """ê²Œì‹œë¬¼ ë‚ ì§œê°€ ì§€ì •ëœ ë²”ìœ„ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸"""
        try:
            # ë‚ ì§œ ë¬¸ìì—´ ì •ê·œí™”
            date_str = date_str.replace(',', ' ').strip()
            
            # ë‹¤ì–‘í•œ ë‚ ì§œ í˜•ì‹ ì‹œë„
            try:
                # "YYYY. MM. DD" í˜•ì‹
                post_date = datetime.strptime(date_str, '%Y. %m. %d').date()
            except ValueError:
                try:
                    # "MMM DD YYYY" í˜•ì‹
                    post_date = datetime.strptime(date_str, '%b %d %Y').date()
                except ValueError:
                    try:
                        # "YYYY-MM-DD" í˜•ì‹
                        post_date = datetime.strptime(date_str, '%Y-%m-%d').date()
                    except ValueError:
                        # ì •ê·œì‹ìœ¼ë¡œ ì‹œë„
                        match = re.search(r'(\d{4})[.\-\s]+(\d{1,2})[.\-\s]+(\d{1,2})', date_str)
                        if match:
                            year, month, day = map(int, match.groups())
                            post_date = datetime(year, month, day).date()
                        else:
                            logger.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” ë‚ ì§œ í˜•ì‹: {date_str}")
                            return True  # ì•Œ ìˆ˜ ì—†ëŠ” ê²½ìš° í¬í•¨
            
            # ë‚ ì§œ ë²”ìœ„ ê³„ì‚° (í•œêµ­ ì‹œê°„ëŒ€)
            korea_tz = datetime.now() + timedelta(hours=9)  # UTCì—ì„œ KSTë¡œ
            days_ago = (korea_tz - timedelta(days=days)).date()
            
            logger.info(f"ê²Œì‹œë¬¼ ë‚ ì§œ í™•ì¸: {post_date} vs {days_ago} ({days}ì¼ ì „, í•œêµ­ ì‹œê°„ ê¸°ì¤€)")
            return post_date >= days_ago
            
        except Exception as e:
            logger.error(f"ë‚ ì§œ íŒŒì‹± ì—ëŸ¬: {str(e)}")
            return True  # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ì ìœ¼ë¡œ í¬í•¨

    def has_next_page(self, driver):
        """ë‹¤ìŒ í˜ì´ì§€ê°€ ìˆëŠ”ì§€ í™•ì¸"""
        try:
            current_page = int(driver.find_element(By.CSS_SELECTOR, "a.page-link[aria-current='page']").text)
            next_page_link = driver.find_elements(By.CSS_SELECTOR, f"a.page-link[href*='pageIndex={current_page + 1}']")
            return len(next_page_link) > 0
        except Exception as e:
            logger.error(f"ë‹¤ìŒ í˜ì´ì§€ í™•ì¸ ì¤‘ ì—ëŸ¬: {str(e)}")
            return False

    def go_to_next_page(self, driver):
        """ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™"""
        try:
            current_page = int(driver.find_element(By.CSS_SELECTOR, "a.page-link[aria-current='page']").text)
            next_page = driver.find_element(By.CSS_SELECTOR, f"a.page-link[href*='pageIndex={current_page + 1}']")
            next_page.click()
            WebDriverWait(driver, 10).until(
                EC.staleness_of(driver.find_element(By.CSS_SELECTOR, "div.board_list"))
            )
            return True
        except Exception as e:
            logger.error(f"ë‹¤ìŒ í˜ì´ì§€ ì´ë™ ì¤‘ ì—ëŸ¬: {str(e)}")
            return False

    def parse_page(self, driver, days_range=4):
        """í˜„ì¬ í˜ì´ì§€ì—ì„œ ê´€ë ¨ ê²Œì‹œë¬¼ íŒŒì‹±"""
        all_posts = []
        telecom_stats_posts = []
        continue_search = True
        
        try:
            WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.CLASS_NAME, "board_list"))
            )
            
            soup = BeautifulSoup(driver.page_source, 'html.parser')
            posts = soup.find_all('div', {'class': 'toggle'})
            
            for item in posts:
                # í—¤ë” í–‰ ê±´ë„ˆë›°ê¸°
                if 'thead' in item.get('class', []):
                    continue

                try:
                    # ë‚ ì§œ ì •ë³´ ì¶”ì¶œ
                    date_elem = item.find('div', {'class': 'date', 'aria-label': 'ë“±ë¡ì¼'})
                    if not date_elem:
                        date_elem = item.find('div', {'class': 'date'})
                    if not date_elem:
                        continue
                        
                    date_str = date_elem.text.strip()
                    if not date_str or date_str == 'ë“±ë¡ì¼':
                        continue
                    
                    logger.info(f"ë‚ ì§œ ë¬¸ìì—´ ë°œê²¬: {date_str}")
                    
                    # ê²Œì‹œë¬¼ì´ ë‚ ì§œ ë²”ìœ„ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸
                    if not self.is_in_date_range(date_str, days=days_range):
                        continue_search = False
                        break
                    
                    # ì œëª© ë° ê²Œì‹œë¬¼ ID ì¶”ì¶œ
                    title_elem = item.find('p', {'class': 'title'})
                    if not title_elem:
                        continue
                        
                    title = title_elem.text.strip()
                    post_id = self.extract_post_id(item)
                    post_url = self.get_post_url(post_id)
                    
                    # ë¶€ì„œ ì •ë³´ ì¶”ì¶œ
                    dept_elem = item.find('dd', {'id': lambda x: x and 'td_CHRG_DEPT_NM' in x})
                    dept_text = dept_elem.text.strip() if dept_elem else "ë¶€ì„œ ì •ë³´ ì—†ìŒ"
                    
                    # ê²Œì‹œë¬¼ ì •ë³´ ë”•ì…”ë„ˆë¦¬ ìƒì„±
                    post_info = {
                        'title': title,
                        'date': date_str,
                        'department': dept_text,
                        'url': post_url,
                        'post_id': post_id
                    }
                    
                    # ëª¨ë“  ê²Œì‹œë¬¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                    all_posts.append(post_info)
                    
                    # í†µì‹  í†µê³„ ê²Œì‹œë¬¼ì¸ì§€ í™•ì¸
                    if self.is_telecom_stats_post(title):
                        logger.info(f"í†µì‹  í†µê³„ ê²Œì‹œë¬¼ ë°œê²¬: {title}")
                        telecom_stats_posts.append(post_info)
                        
                except Exception as e:
                    logger.error(f"ê²Œì‹œë¬¼ íŒŒì‹± ì¤‘ ì—ëŸ¬: {str(e)}")
                    continue
            
            return all_posts, telecom_stats_posts, continue_search
            
        except Exception as e:
            logger.error(f"í˜ì´ì§€ íŒŒì‹± ì¤‘ ì—ëŸ¬: {str(e)}")
            return [], [], False
            
    def find_view_link_params(self, driver, post):
        """ê²Œì‹œë¬¼ì—ì„œ ë°”ë¡œë³´ê¸° ë§í¬ íŒŒë¼ë¯¸í„° ì°¾ê¸°"""
        if not post.get('post_id'):
            logger.error(f"ê²Œì‹œë¬¼ ì ‘ê·¼ ë¶ˆê°€ {post['title']} - post_id ëˆ„ë½")
            return None

        logger.info(f"ê²Œì‹œë¬¼ ì—´ê¸°: {post['title']}")
        max_retries = 3
        for attempt in range(max_retries):
            try:
                detail_url = f"https://www.msit.go.kr/bbs/view.do?sCode=user&mId=99&mPid=74&nttSeqNo={post['post_id']}"
                driver.get(detail_url)
                time.sleep(1)
                # ì‹œìŠ¤í…œ ì ê²€ ì•ˆë‚´ ì˜¤ë²„ë ˆì´ ì¡´ì¬ ì—¬ë¶€ ì²´í¬
                try:
                    maintenance_visible = driver.find_element(By.XPATH, "//*[contains(text(), 'ì‹œìŠ¤í…œ ì ê²€ ì•ˆë‚´')]")
                    if maintenance_visible:
                        logger.info("ì‹œìŠ¤í…œ ì ê²€ ì•ˆë‚´ ì˜¤ë²„ë ˆì´ ê°ì§€ë¨. ì˜¤ë²„ë ˆì´ ì œê±° ì‹œë„ ì¤‘...")
                        driver.execute_script("var el = document.evaluate(\"//*[contains(text(), 'ì‹œìŠ¤í…œ ì ê²€ ì•ˆë‚´')]\", document, null, XPathResult.FIRST_ORDERED_NODE_TYPE, null).singleNodeValue; if(el) el.parentNode.removeChild(el);")
                        time.sleep(1)
                except Exception:
                    logger.info("ì‹œìŠ¤í…œ ì ê²€ ì•ˆë‚´ ì˜¤ë²„ë ˆì´ ì—†ìŒ ë˜ëŠ” ì´ë¯¸ ì œê±°ë¨.")
                
                # ì£¼ìš” ìš”ì†Œê°€ ë“±ì¥í•˜ëŠ”ì§€ 10ì´ˆ ëŒ€ê¸°
                WebDriverWait(driver, 10).until(
                    lambda x: len(x.find_elements(By.CLASS_NAME, "view_head")) > 0 or
                              len(x.find_elements(By.CLASS_NAME, "view_file")) > 0
                )
                break
            except TimeoutException:
                if attempt < max_retries - 1:
                    logger.warning(f"í˜ì´ì§€ ë¡œë“œ íƒ€ì„ì•„ì›ƒ, ì¬ì‹œë„ {attempt+1}/{max_retries}")
                    time.sleep(1)
                else:
                    logger.error(f"{max_retries}ë²ˆ ì‹œë„ í›„ í˜ì´ì§€ ë¡œë“œ ì‹¤íŒ¨")
                    snippet = driver.page_source[:1000]
                    logger.error("ìµœì¢… ì‹œë„ í›„ í˜ì´ì§€ HTML ìŠ¤ë‹ˆí«:\n" + snippet)
                    if "ì‹œìŠ¤í…œ ì ê²€ ì•ˆë‚´" in driver.page_source:
                        logger.warning("ì‹œìŠ¤í…œ ì ê²€ ì¤‘ì…ë‹ˆë‹¤.")
                        return None
                    return None
            except Exception as e:
                logger.error(f"ê²Œì‹œë¬¼ ìƒì„¸ ì •ë³´ ì ‘ê·¼ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                return None

        try:
            view_links = driver.find_elements(By.CSS_SELECTOR, "a.view[title='ìƒˆì°½ ì—´ë¦¼']")
            if not view_links:
                all_links = driver.find_elements(By.TAG_NAME, "a")
                view_links = [link for link in all_links if 'getExtension_path' in (link.get_attribute('onclick') or '')]
            if not view_links:
                all_links = driver.find_elements(By.TAG_NAME, "a")
                view_links = [link for link in all_links if 'ë°”ë¡œë³´ê¸°' in (link.text or '')]
            if view_links:
                view_link = view_links[0]
                onclick_attr = view_link.get_attribute('onclick')
                logger.info(f"ë°”ë¡œë³´ê¸° ë§í¬ ë°œê²¬, onclick: {onclick_attr}")
                match = re.search(r"getExtension_path\s*\(\s*['\"]([\d]+)['\"]?\s*,\s*['\"]([\d]+)['\"]", onclick_attr)
                if match:
                    atch_file_no = match.group(1)
                    file_ord = match.group(2)
                    date_match = re.search(r'\((\d{4})ë…„\s+(\d{1,2})ì›”ë§\s+ê¸°ì¤€\)', post['title'])
                    if date_match:
                        year = int(date_match.group(1))
                        month = int(date_match.group(2))
                        return {
                            'atch_file_no': atch_file_no,
                            'file_ord': file_ord,
                            'date': {'year': year, 'month': month},
                            'post_info': post
                        }
                    return {
                        'atch_file_no': atch_file_no,
                        'file_ord': file_ord,
                        'post_info': post
                    }
            logger.warning(f"ë°”ë¡œë³´ê¸° ë§í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {post['title']}")
            date_match = re.search(r'\((\d{4})ë…„\s+(\d{1,2})ì›”ë§\s+ê¸°ì¤€\)', post['title'])
            if date_match:
                year = int(date_match.group(1))
                month = int(date_match.group(2))
                content_div = driver.find_element(By.CLASS_NAME, "view_cont")
                content = content_div.text if content_div else ""
                return {
                    'content': content,
                    'date': {'year': year, 'month': month},
                    'post_info': post
                }
            return None
        except Exception as e:
            logger.error(f"ë°”ë¡œë³´ê¸° ë§í¬ íŒŒë¼ë¯¸í„° ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return None

    def access_iframe_direct(self, driver, file_params):
        """iframeì— ì§ì ‘ ì ‘ê·¼í•˜ì—¬ ë°ì´í„° ì¶”ì¶œ (ëª…ì‹œì  ëŒ€ê¸° í™œìš© ë° SynapDocViewServer ì²˜ë¦¬ í¬í•¨, ì˜¤ë¥˜ ë°œìƒ ì‹œ HTML ë¯¸ë¦¬ë³´ê¸° ë¡œê·¸ ì¶œë ¥)"""
        if not file_params or not file_params.get('atch_file_no') or not file_params.get('file_ord'):
            logger.error("íŒŒì¼ íŒŒë¼ë¯¸í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None

        atch_file_no = file_params['atch_file_no']
        file_ord = file_params['file_ord']
        view_url = f"https://www.msit.go.kr/bbs/documentView.do?atchFileNo={atch_file_no}&fileOrdr={file_ord}"
        logger.info(f"ë°”ë¡œë³´ê¸° URL: {view_url}")

        try:
            # í˜ì´ì§€ë¡œ ì´ë™ í›„, redirection ë° ë¡œë”©ì„ ìœ„í•´ ì¶©ë¶„í•œ ì‹œê°„(ìµœëŒ€ 40ì´ˆ) ëŒ€ê¸°
            driver.get(view_url)
            time.sleep(3)
            # URL ë³€í™” í™•ì¸ (redirection í›„)
            current_url = driver.current_url
            logger.info(f"í˜„ì¬ URL: {current_url}")
            
            # SynapDocViewServerê°€ í¬í•¨ëœ URLì´ë©´, ë¬¸ì„œë·°ì–´ í˜ì´ì§€ì„ì„ ì˜ë¯¸
            if 'SynapDocViewServer' in current_url:
                logger.info("SynapDocViewServer ê°ì§€ë¨")
                # í˜ì´ì§€ ë¡œë”©ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìœ¼ë¯€ë¡œ íƒ€ì„ì•„ì›ƒ 40ì´ˆ ì ìš©
                sheet_tabs = driver.find_elements(By.CSS_SELECTOR, ".sheet-list__sheet-tab")
                if sheet_tabs:
                    logger.info(f"ì‹œíŠ¸ íƒ­ {len(sheet_tabs)}ê°œ ë°œê²¬")
                    all_sheets = {}
                    for i, tab in enumerate(sheet_tabs):
                        sheet_name = tab.text.strip() if tab.text.strip() else f"ì‹œíŠ¸{i+1}"
                        if i > 0:
                            try:
                                tab.click()
                                time.sleep(3)
                            except Exception as click_err:
                                logger.error(f"ì‹œíŠ¸ íƒ­ í´ë¦­ ì‹¤íŒ¨ ({sheet_name}): {str(click_err)}")
                                continue
                        try:
                            iframe = WebDriverWait(driver, 40).until(
                                EC.presence_of_element_located((By.ID, "innerWrap"))
                            )
                            driver.switch_to.frame(iframe)
                            iframe_html = driver.page_source
                            df = self.extract_table_from_html(iframe_html)
                            driver.switch_to.default_content()
                            if df is not None and not df.empty:
                                all_sheets[sheet_name] = df
                                logger.info(f"ì‹œíŠ¸ '{sheet_name}'ì—ì„œ ë°ì´í„° ì¶”ì¶œ ì„±ê³µ: {df.shape[0]}í–‰, {df.shape[1]}ì—´")
                            else:
                                logger.warning(f"ì‹œíŠ¸ '{sheet_name}'ì—ì„œ í…Œì´ë¸” ì¶”ì¶œ ì‹¤íŒ¨")
                        except Exception as iframe_err:
                            logger.error(f"ì‹œíŠ¸ '{sheet_name}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(iframe_err)}")
                            try:
                                driver.switch_to.default_content()
                            except Exception:
                                pass
                    if all_sheets:
                        logger.info(f"ì´ {len(all_sheets)}ê°œ ì‹œíŠ¸ì—ì„œ ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ")
                        return all_sheets
                    else:
                        logger.warning("ì–´ë–¤ ì‹œíŠ¸ì—ì„œë„ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                        return None
                else:
                    # ì‹œíŠ¸ íƒ­ì´ ì—†ëŠ” ê²½ìš° ë‹¨ì¼ iframe ì²˜ë¦¬
                    logger.info("ì‹œíŠ¸ íƒ­ ì—†ìŒ, ë‹¨ì¼ iframe ì²˜ë¦¬ ì‹œë„ (SynapDocViewServer)")
                    iframe = WebDriverWait(driver, 40).until(
                        EC.presence_of_element_located((By.ID, "innerWrap"))
                    )
                    driver.switch_to.frame(iframe)
                    html_content = driver.page_source
                    df = self.extract_table_from_html(html_content)
                    driver.switch_to.default_content()
                    if df is not None and not df.empty:
                        logger.info(f"ë‹¨ì¼ iframeì—ì„œ ë°ì´í„° ì¶”ì¶œ ì„±ê³µ: {df.shape[0]}í–‰, {df.shape[1]}ì—´")
                        return {"ê¸°ë³¸ ì‹œíŠ¸": df}
                    else:
                        logger.warning("ë‹¨ì¼ iframeì—ì„œ í…Œì´ë¸” ì¶”ì¶œ ì‹¤íŒ¨")
                        return None
            else:
                # SynapDocViewServerê°€ ì—†ëŠ” ê²½ìš°(ì¼ë°˜ HTML í˜ì´ì§€)
                logger.info("SynapDocViewServer ë¯¸ê°ì§€, ì¼ë°˜ HTML í˜ì´ì§€ ì²˜ë¦¬")
                tables = pd.read_html(driver.page_source)
                if tables:
                    largest_table = max(tables, key=lambda t: t.size)
                    logger.info(f"ê°€ì¥ í° í…Œì´ë¸” ì„ íƒ: {largest_table.shape}")
                    return {"ê¸°ë³¸ í…Œì´ë¸”": largest_table}
                else:
                    logger.warning("í˜ì´ì§€ì—ì„œ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    return None

        except Exception as e:
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ, í˜„ì¬ í˜ì´ì§€ì˜ HTMLì„ ë¡œê·¸ì— ì¶œë ¥í•˜ì—¬ ë””ë²„ê·¸ ì§€ì›
            logger.error(f"iframe ì „í™˜ ë° ë°ì´í„° ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            try:
                html_debug = driver.page_source
                logger.error("ì˜¤ë¥˜ ë°œìƒ ì‹œ í˜ì´ì§€ HTML:\n" + html_debug)
                driver.switch_to.default_content()
            except Exception:
                pass
            return None



    def extract_table_from_html(self, html_content):
        """HTML ë‚´ìš©ì—ì„œ í…Œì´ë¸” ì¶”ì¶œ (colspan ë° rowspan ì²˜ë¦¬ í¬í•¨)"""
        try:
                soup = BeautifulSoup(html_content, 'html.parser')
                
                # ëª¨ë“  <table> ìš”ì†Œ ê²€ìƒ‰
                tables = soup.find_all('table')
                if not tables:
                        logger.warning("HTMLì—ì„œ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                        return None
                
                # ë‚´ë¶€ í•¨ìˆ˜: í•˜ë‚˜ì˜ í…Œì´ë¸”ì„ íŒŒì‹±í•˜ì—¬ 2ì°¨ì› ë¦¬ìŠ¤íŠ¸(í–‰ë ¬)ë¡œ ë³€í™˜ (rowspan, colspan ì²˜ë¦¬)
                def parse_table(table):
                        table_data = []
                        # pendingì€ (row_index, col_index) -> cell ë‚´ìš© ë”•ì…”ë„ˆë¦¬
                        pending = {}
                        rows = table.find_all('tr')
                        for row_idx, row in enumerate(rows):
                                current_row = []
                                col_idx = 0
                                
                                # í˜„ì¬ í–‰ ì‹œì‘ ì‹œ, ì´ë¯¸ ì´ì „ rowì˜ rowspanìœ¼ë¡œ ì±„ì›Œì•¼ í•  ì…€ ì²˜ë¦¬
                                while (row_idx, col_idx) in pending:
                                        current_row.append(pending[(row_idx, col_idx)])
                                        del pending[(row_idx, col_idx)]
                                        col_idx += 1
                                
                                # í˜„ì¬ í–‰ì˜ ê° ì…€ ì²˜ë¦¬
                                cells = row.find_all(['td', 'th'])
                                for cell in cells:
                                        # ë§Œì•½ í˜„ì¬ ìœ„ì¹˜ì— pending ì…€ì´ ìˆë‹¤ë©´ ë¨¼ì € ì±„ì›€
                                        while (row_idx, col_idx) in pending:
                                                current_row.append(pending[(row_idx, col_idx)])
                                                del pending[(row_idx, col_idx)]
                                                col_idx += 1
                                        
                                        text = cell.get_text(strip=True)
                                        try:
                                                colspan = int(cell.get("colspan", 1))
                                        except Exception:
                                                colspan = 1
                                        try:
                                                rowspan = int(cell.get("rowspan", 1))
                                        except Exception:
                                                rowspan = 1
                                        
                                        # í˜„ì¬ ì…€ì„ colspan íšŸìˆ˜ë§Œí¼ í˜„ì¬ í–‰ì— ì¶”ê°€
                                        for i in range(colspan):
                                                current_row.append(text)
                                                # rowspanì´ ìˆëŠ” ê²½ìš° í›„ì† í–‰ì— í•´ë‹¹ ì…€ ê°’ ì¶”ê°€
                                                if rowspan > 1:
                                                        for r in range(1, rowspan):
                                                                pending[(row_idx + r, col_idx)] = text
                                                col_idx += 1
                                
                                # ì…€ ì²˜ë¦¬ í›„, ë§Œì•½ ë‚¨ì€ pending ì…€ì´ ìˆë‹¤ë©´ ì±„ì›€
                                while (row_idx, col_idx) in pending:
                                        current_row.append(pending[(row_idx, col_idx)])
                                        del pending[(row_idx, col_idx)]
                                        col_idx += 1
                                
                                table_data.append(current_row)
                        return table_data
                
                # íŒŒì‹±ëœ í…Œì´ë¸” ì¤‘ í—¤ë”ì™€ ë°ì´í„° í–‰ì´ ìˆëŠ” í…Œì´ë¸”ë§Œ ì„ íƒ
                parsed_tables = []
                for table in tables:
                        data = parse_table(table)
                        if data and len(data) >= 2:
                                parsed_tables.append((len(data), data))
                if not parsed_tables:
                        logger.warning("ì „ì²˜ë¦¬ëœ í…Œì´ë¸” ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŒ")
                        return None
                
                # í–‰ ìˆ˜ê°€ ê°€ì¥ ë§ì€ í…Œì´ë¸” ì„ íƒ
                _, largest_table = max(parsed_tables, key=lambda x: x[0])
                if len(largest_table) < 2:
                        logger.warning("í…Œì´ë¸” ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŒ")
                        return None
                
                # ì²« ë²ˆì§¸ í–‰ì„ í—¤ë”ë¡œ ê°„ì£¼í•˜ê³  ë‚˜ë¨¸ì§€ë¥¼ ë°ì´í„°ë¡œ ì‚¬ìš©
                header = largest_table[0]
                data_rows = []
                for row in largest_table[1:]:
                        # í—¤ë” ì—´ ê°œìˆ˜ì— ë§ì¶° í–‰ ê¸¸ì´ ì¡°ì • (ë¶€ì¡±í•˜ë©´ ë¹ˆ ë¬¸ìì—´ ì±„ì›€, ì´ˆê³¼í•˜ë©´ ì˜ë¼ëƒ„)
                        if len(row) < len(header):
                                row.extend([""] * (len(header) - len(row)))
                        elif len(row) > len(header):
                                row = row[:len(header)]
                        data_rows.append(row)
                
                df = pd.DataFrame(data_rows, columns=header)
                logger.info(f"í…Œì´ë¸” ì¶”ì¶œ ì„±ê³µ: {df.shape[0]}í–‰ {df.shape[1]}ì—´")
                return df
        
        except Exception as e:
                logger.error(f"HTMLì—ì„œ í…Œì´ë¸” ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                return None


    def create_placeholder_dataframe(self, post_info):
        """ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë°ì´í„°í”„ë ˆì„ ìƒì„±"""
        try:
            # ë‚ ì§œ ì •ë³´ ì¶”ì¶œ
            date_match = re.search(r'\((\d{4})ë…„\s+(\d{1,2})ì›”ë§\s+ê¸°ì¤€\)', post_info['title'])
            if date_match:
                year = date_match.group(1)
                month = date_match.group(2)

                # ë³´ê³ ì„œ ìœ í˜• ê²°ì •
                report_type = self.determine_report_type(post_info['title'])

                # ê¸°ë³¸ ë°ì´í„°í”„ë ˆì„ ìƒì„±
                df = pd.DataFrame({
                    'êµ¬ë¶„': [f'{year}ë…„ {month}ì›” í†µê³„'],
                    'ê°’': ['ë°ì´í„°ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤'],
                    'ë¹„ê³ ': [f'{post_info["title"]} - ì ‘ê·¼ ì˜¤ë¥˜']
                })

                logger.info(f"í”Œë ˆì´ìŠ¤í™€ë” ë°ì´í„°í”„ë ˆì„ ìƒì„±: {year}ë…„ {month}ì›” {report_type}")
                return df

            return pd.DataFrame()  # ë‚ ì§œ ì •ë³´ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë°ì´í„°í”„ë ˆì„ ë°˜í™˜

        except Exception as e:
            logger.error(f"í”Œë ˆì´ìŠ¤í™€ë” ë°ì´í„°í”„ë ˆì„ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return pd.DataFrame()  # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¹ˆ ë°ì´í„°í”„ë ˆì„ ë°˜í™˜


    def determine_report_type(self, title):
        """ê²Œì‹œë¬¼ ì œëª©ì—ì„œ ë³´ê³ ì„œ ìœ í˜• ê²°ì •"""
        for report_type in self.report_types:
            if report_type in title:
                return report_type
        return "ê¸°íƒ€ í†µì‹  í†µê³„"

    def update_google_sheets(self, client, data):
        """Google Sheets ì—…ë°ì´íŠ¸"""
        if not client or not data:
            logger.error("Google Sheets ì—…ë°ì´íŠ¸ ë¶ˆê°€: í´ë¼ì´ì–¸íŠ¸ ë˜ëŠ” ë°ì´í„° ì—†ìŒ")
            return False
        
        try:
            # ì •ë³´ ì¶”ì¶œ
            post_info = data['post_info']
            
            # ë‚ ì§œ ì •ë³´ê°€ ì§ì ‘ ì œê³µë˜ì—ˆëŠ”ì§€ í™•ì¸
            if 'date' in data:
                year = data['date']['year']
                month = data['date']['month']
            else:
                # ì œëª©ì—ì„œ ë‚ ì§œ ì •ë³´ ì¶”ì¶œ
                date_match = re.search(r'\((\d{4})ë…„\s+(\d{1,2})ì›”ë§\s+ê¸°ì¤€\)', post_info['title'])
                if not date_match:
                    logger.error(f"ì œëª©ì—ì„œ ë‚ ì§œë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŒ: {post_info['title']}")
                    return False
                    
                year = int(date_match.group(1))
                month = int(date_match.group(2))
            
            # ë‚ ì§œ ë¬¸ìì—´ í¬ë§·
            date_str = f"{year}ë…„ {month}ì›”"
            report_type = self.determine_report_type(post_info['title'])
            
            # ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì—´ê¸°
            try:
                # IDë¡œ ë¨¼ì € ì‹œë„
                if self.spreadsheet_id:
                    try:
                        spreadsheet = client.open_by_key(self.spreadsheet_id)
                        logger.info(f"IDë¡œ ê¸°ì¡´ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì°¾ìŒ: {self.spreadsheet_id}")
                    except gspread.exceptions.APIError:
                        logger.warning(f"IDë¡œ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ë¥¼ ì—´ ìˆ˜ ì—†ìŒ: {self.spreadsheet_id}")
                        spreadsheet = None
                else:
                    spreadsheet = None
                
                # IDë¡œ ì°¾ì§€ ëª»í•œ ê²½ìš° ì´ë¦„ìœ¼ë¡œ ì‹œë„
                if not spreadsheet:
                    try:
                        spreadsheet = client.open(self.spreadsheet_name)
                        logger.info(f"ì´ë¦„ìœ¼ë¡œ ê¸°ì¡´ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì°¾ìŒ: {self.spreadsheet_name}")
                    except gspread.exceptions.SpreadsheetNotFound:
                        # ìƒˆ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ìƒì„±
                        spreadsheet = client.create(self.spreadsheet_name)
                        logger.info(f"ìƒˆ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ìƒì„±: {self.spreadsheet_name}")
                        
                        # ì°¸ì¡°ìš© ID ê¸°ë¡
                        logger.info(f"ìƒˆ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ID: {spreadsheet.id}")
            except Exception as e:
                logger.error(f"Google Sheets ì—´ê¸° ì¤‘ ì˜¤ë¥˜: {str(e)}")
                return False
            
            # ì‹œíŠ¸ ë°ì´í„° ì—¬ë¶€ í™•ì¸
            if 'sheets' in data:
                # ì—¬ëŸ¬ ì‹œíŠ¸ ì²˜ë¦¬
                for sheet_name, df in data['sheets'].items():
                    success = self.update_single_sheet(spreadsheet, sheet_name, df, date_str)
                    if not success:
                        logger.warning(f"ì‹œíŠ¸ '{sheet_name}' ì—…ë°ì´íŠ¸ ì‹¤íŒ¨")
                
                return True  # ìµœì†Œí•œ í•˜ë‚˜ì˜ ì‹œíŠ¸ëŠ” ì—…ë°ì´íŠ¸ ì‹œë„ë¨
                
            elif 'dataframe' in data:
                # ë‹¨ì¼ ë°ì´í„°í”„ë ˆì„ ì²˜ë¦¬
                return self.update_single_sheet(spreadsheet, report_type, data['dataframe'], date_str)
                
            else:
                logger.error("ì—…ë°ì´íŠ¸í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                return False
                
        except Exception as e:
            logger.error(f"Google Sheets ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return False

    def update_single_sheet(self, spreadsheet, sheet_name, df, date_str):
        """ë‹¨ì¼ ì‹œíŠ¸ ì—…ë°ì´íŠ¸"""
        try:
            # ì›Œí¬ì‹œíŠ¸ ì°¾ê¸° ë˜ëŠ” ìƒì„±
            try:
                worksheet = spreadsheet.worksheet(sheet_name)
                logger.info(f"ê¸°ì¡´ ì›Œí¬ì‹œíŠ¸ ì°¾ìŒ: {sheet_name}")
            except gspread.exceptions.WorksheetNotFound:
                worksheet = spreadsheet.add_worksheet(title=sheet_name, rows="1000", cols="50")
                worksheet.update_cell(1, 1, "í•­ëª©")
                logger.info(f"ìƒˆ ì›Œí¬ì‹œíŠ¸ ìƒì„±: {sheet_name}")
            
            # ë‚ ì§œ ì—´ í™•ì¸
            headers = worksheet.row_values(1)
            if date_str in headers:
                col_idx = headers.index(date_str) + 1
                logger.info(f"'{date_str}' ì—´ì´ ì´ë¯¸ ìœ„ì¹˜ {col_idx}ì— ì¡´ì¬í•©ë‹ˆë‹¤")
            else:
                # ìƒˆ ë‚ ì§œ ì—´ ì¶”ê°€
                col_idx = len(headers) + 1
                worksheet.update_cell(1, col_idx, date_str)
                logger.info(f"ìœ„ì¹˜ {col_idx}ì— ìƒˆ ì—´ '{date_str}' ì¶”ê°€")
            
            # ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ì‹œíŠ¸ ì—…ë°ì´íŠ¸
            self.update_sheet_from_dataframe(worksheet, df, col_idx)
            
            logger.info(f"ì›Œí¬ì‹œíŠ¸ '{sheet_name}'ì— '{date_str}' ë°ì´í„° ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            return True
            
        except Exception as e:
            logger.error(f"ì‹œíŠ¸ '{sheet_name}' ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return False

    def update_sheet_from_dataframe(self, worksheet, df, col_idx):
        """ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ì›Œí¬ì‹œíŠ¸ ì—…ë°ì´íŠ¸"""
        try:
            # ê¸°ì¡´ í•­ëª© (ì²« ë²ˆì§¸ ì—´) ê°€ì ¸ì˜¤ê¸°
            existing_items = worksheet.col_values(1)[1:]  # í—¤ë” ì œì™¸
            
            if df.shape[0] > 0:
                # ë°ì´í„°í”„ë ˆì„ì—ì„œ í•­ëª©ê³¼ ê°’ ì¶”ì¶œ
                # ì²« ë²ˆì§¸ ì—´ì€ í•­ëª©, ë‘ ë²ˆì§¸ ì—´ì€ ê°’ìœ¼ë¡œ ê°€ì •
                if df.shape[1] >= 2:
                    new_items = df.iloc[:, 0].astype(str).tolist()
                    values = df.iloc[:, 1].astype(str).tolist()
                    
                    # ë°°ì¹˜ ì—…ë°ì´íŠ¸ ì¤€ë¹„
                    cell_updates = []
                    
                    for i, (item, value) in enumerate(zip(new_items, values)):
                        if item and not pd.isna(item):  # ë¹ˆ í•­ëª© ì œì™¸
                            # í•­ëª©ì´ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
                            if item in existing_items:
                                row_idx = existing_items.index(item) + 2  # í—¤ë”ì™€ 0-ì¸ë±ìŠ¤ ë³´ì •
                            else:
                                # ìƒˆ í•­ëª© ì¶”ê°€
                                row_idx = len(existing_items) + 2
                                # í•­ëª© ì—…ë°ì´íŠ¸
                                cell_updates.append({
                                    'range': f'A{row_idx}',
                                    'values': [[item]]
                                })
                                existing_items.append(item)
                            
                            # ê°’ ì—…ë°ì´íŠ¸
                            value_to_update = "" if pd.isna(value) else value
                            cell_updates.append({
                                'range': f'{chr(64 + col_idx)}{row_idx}',
                                'values': [[value_to_update]]
                            })
                    
                    # ì¼ê´„ ì—…ë°ì´íŠ¸ ì‹¤í–‰
                    if cell_updates:
                        worksheet.batch_update(cell_updates)
                        logger.info(f"{len(cell_updates)}ê°œ ì…€ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
                        
            return True
            
        except Exception as e:
            logger.error(f"ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ì›Œí¬ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return False

    async def send_telegram_message(self, posts, data_updates=None):
        """í…”ë ˆê·¸ë¨ìœ¼ë¡œ ì•Œë¦¼ ë©”ì‹œì§€ ì „ì†¡"""
        if not posts and not data_updates:
            logger.info("ì•Œë¦¼ì„ ë³´ë‚¼ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤")
            return
            
        try:
            message = "ğŸ“Š *MSIT í†µì‹  í†µê³„ ëª¨ë‹ˆí„°ë§*\n\n"
            
            # ìƒˆ ê²Œì‹œë¬¼ ì •ë³´ ì¶”ê°€
            if posts:
                message += "ğŸ“± *ìƒˆë¡œìš´ í†µì‹  ê´€ë ¨ ê²Œì‹œë¬¼*\n\n"
                
                for post in posts:
                    message += f"ğŸ“… {post['date']}\n"
                    message += f"ğŸ“‘ {post['title']}\n"
                    message += f"ğŸ¢ {post['department']}\n"
                    if post.get('url'):
                        message += f"ğŸ”— [ê²Œì‹œë¬¼ ë§í¬]({post['url']})\n"
                    message += "\n"
            
            # ë°ì´í„° ì—…ë°ì´íŠ¸ ì •ë³´ ì¶”ê°€
            if data_updates:
                message += "ğŸ“Š *Google Sheets ë°ì´í„° ì—…ë°ì´íŠ¸*\n\n"
                
                for update in data_updates:
                    post_info = update['post_info']
                    
                    # ë‚ ì§œ ì •ë³´ ì¶”ì¶œ
                    if 'date' in update:
                        year = update['date']['year']
                        month = update['date']['month']
                    else:
                        date_match = re.search(r'\((\d{4})ë…„\s+(\d{1,2})ì›”ë§\s+ê¸°ì¤€\)', post_info['title'])
                        if date_match:
                            year = date_match.group(1)
                            month = date_match.group(2)
                        else:
                            year = "ì•Œ ìˆ˜ ì—†ìŒ"
                            month = "ì•Œ ìˆ˜ ì—†ìŒ"
                    
                    date_str = f"{year}ë…„ {month}ì›”"
                    report_type = self.determine_report_type(post_info['title'])
                    
                    message += f"ğŸ“… *{date_str}*\n"
                    message += f"ğŸ“‘ {report_type}\n"
                    message += f"ğŸ“— ì—…ë°ì´íŠ¸ ì™„ë£Œ\n\n"
            
            # ë©”ì‹œì§€ ì „ì†¡
            chat_id = int(self.chat_id)
            await self.bot.send_message(
                chat_id=chat_id,
                text=message,
                parse_mode='Markdown'
            )
            logger.info("í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ ì „ì†¡ ì„±ê³µ")
            
        except Exception as e:
            logger.error(f"í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ ì „ì†¡ ì¤‘ ì˜¤ë¥˜: {str(e)}")

    async def run_monitor(self, days_range=4, check_sheets=True):
        """ëª¨ë‹ˆí„°ë§ ì‹¤í–‰"""
        driver = None
        gs_client = None
        
        try:
            # WebDriver ì´ˆê¸°í™”
            driver = self.setup_driver()
            logger.info("WebDriver ì´ˆê¸°í™” ì™„ë£Œ")
            
            # Google Sheets í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
            if check_sheets and self.gspread_creds:
                gs_client = self.setup_gspread_client()
                if gs_client:
                    logger.info("Google Sheets í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
                else:
                    logger.warning("Google Sheets í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨")
            
            # MSIT ì›¹ì‚¬ì´íŠ¸ë¡œ ì´ë™
            driver.get(self.url)
            logger.info("MSIT ì›¹ì‚¬ì´íŠ¸ ì ‘ê·¼ ì™„ë£Œ")
            
            # ëª¨ë“  ê²Œì‹œë¬¼ ë° í†µì‹  í†µê³„ ê²Œì‹œë¬¼ ì¶”ì 
            all_posts = []
            telecom_stats_posts = []
            continue_search = True
            
            # í˜ì´ì§€ íŒŒì‹±
            while continue_search:
                page_posts, stats_posts, should_continue = self.parse_page(driver, days_range=days_range)
                all_posts.extend(page_posts)
                telecom_stats_posts.extend(stats_posts)
                
                if not should_continue:
                    break
                    
                if self.has_next_page(driver):
                    if not self.go_to_next_page(driver):
                        break
                else:
                    break
            
            # í†µì‹  í†µê³„ ê²Œì‹œë¬¼ ì²˜ë¦¬
            data_updates = []
            
            if gs_client and telecom_stats_posts and check_sheets:
                logger.info(f"{len(telecom_stats_posts)}ê°œ í†µì‹  í†µê³„ ê²Œì‹œë¬¼ ì²˜ë¦¬ ì¤‘")
                
                for post in telecom_stats_posts:
                    try:
                        # ë°”ë¡œë³´ê¸° ë§í¬ íŒŒë¼ë¯¸í„° ì¶”ì¶œ
                        file_params = self.find_view_link_params(driver, post)
                        
                        if not file_params:
                            logger.warning(f"ë°”ë¡œë³´ê¸° ë§í¬ íŒŒë¼ë¯¸í„° ì¶”ì¶œ ì‹¤íŒ¨: {post['title']}")
                            continue
                        
                        # ë°”ë¡œë³´ê¸° ë§í¬ê°€ ìˆëŠ” ê²½ìš°
                        if 'atch_file_no' in file_params and 'file_ord' in file_params:
                            # iframe ì§ì ‘ ì ‘ê·¼í•˜ì—¬ ë°ì´í„° ì¶”ì¶œ
                            sheets_data = self.access_iframe_direct(driver, file_params)
                            
                            if sheets_data:
                                # Google Sheets ì—…ë°ì´íŠ¸
                                update_data = {
                                    'sheets': sheets_data,
                                    'post_info': post
                                }
                                
                                if 'date' in file_params:
                                    update_data['date'] = file_params['date']
                                
                                success = self.update_google_sheets(gs_client, update_data)
                                if success:
                                    logger.info(f"Google Sheets ì—…ë°ì´íŠ¸ ì„±ê³µ: {post['title']}")
                                    data_updates.append(update_data)
                                else:
                                    logger.warning(f"Google Sheets ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {post['title']}")
                            else:
                                logger.warning(f"iframeì—ì„œ ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {post['title']}")
                                
                                # ëŒ€ì²´ ë°ì´í„° ìƒì„±
                                placeholder_df = self.create_placeholder_dataframe(post)
                                if not placeholder_df.empty:
                                    update_data = {
                                        'dataframe': placeholder_df,
                                        'post_info': post
                                    }
                                    
                                    if 'date' in file_params:
                                        update_data['date'] = file_params['date']
                                    
                                    success = self.update_google_sheets(gs_client, update_data)
                                    if success:
                                        logger.info(f"ëŒ€ì²´ ë°ì´í„°ë¡œ ì—…ë°ì´íŠ¸ ì„±ê³µ: {post['title']}")
                                        data_updates.append(update_data)
                        
                        # ê²Œì‹œë¬¼ ë‚´ìš©ë§Œ ìˆëŠ” ê²½ìš°
                        elif 'content' in file_params:
                            logger.info(f"ê²Œì‹œë¬¼ ë‚´ìš©ìœ¼ë¡œ ì²˜ë¦¬ ì¤‘: {post['title']}")
                            
                            # ëŒ€ì²´ ë°ì´í„° ìƒì„±
                            placeholder_df = self.create_placeholder_dataframe(post)
                            if not placeholder_df.empty:
                                update_data = {
                                    'dataframe': placeholder_df,
                                    'post_info': post
                                }
                                
                                if 'date' in file_params:
                                    update_data['date'] = file_params['date']
                                
                                success = self.update_google_sheets(gs_client, update_data)
                                if success:
                                    logger.info(f"ë‚´ìš© ê¸°ë°˜ ë°ì´í„°ë¡œ ì—…ë°ì´íŠ¸ ì„±ê³µ: {post['title']}")
                                    data_updates.append(update_data)
                    
                    except Exception as e:
                        logger.error(f"ê²Œì‹œë¬¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            
            # í…”ë ˆê·¸ë¨ ì•Œë¦¼ ì „ì†¡
            if all_posts or data_updates:
                await self.send_telegram_message(all_posts, data_updates)
            else:
                logger.info(f"ìµœê·¼ {days_range}ì¼ ë‚´ ìƒˆ ê²Œì‹œë¬¼ì´ ì—†ìŠµë‹ˆë‹¤")
        
        except Exception as e:
            logger.error(f"ëª¨ë‹ˆí„°ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            
            try:
                # ì˜¤ë¥˜ ì•Œë¦¼ ì „ì†¡
                error_post = {
                    'title': f"ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {str(e)}",
                    'date': datetime.now().strftime('%Y. %m. %d'),
                    'department': 'System Error'
                }
                await self.send_telegram_message([error_post])
            except Exception as telegram_err:
                logger.error(f"ì˜¤ë¥˜ ì•Œë¦¼ ì „ì†¡ ì¤‘ ì¶”ê°€ ì˜¤ë¥˜: {str(telegram_err)}")
        
        finally:
            # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
            if driver:
                driver.quit()
                logger.info("WebDriver ì¢…ë£Œ")

async def main():
    # í™˜ê²½ ë³€ìˆ˜ ê°€ì ¸ì˜¤ê¸°
    days_range = int(os.environ.get('DAYS_RANGE', '4'))
    check_sheets = os.environ.get('CHECK_SHEETS', 'true').lower() == 'true'
    
    # ëª¨ë‹ˆí„° ìƒì„± ë° ì‹¤í–‰
    try:
        logger.info(f"MSIT ëª¨ë‹ˆí„° ì‹œì‘ - days_range={days_range}, check_sheets={check_sheets}")
        logger.info(f"ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì´ë¦„: {os.environ.get('SPREADSHEET_NAME', 'MSIT í†µì‹  í†µê³„')}")
        
        monitor = MSITMonitor()
        await monitor.run_monitor(days_range=days_range, check_sheets=check_sheets)
    except Exception as e:
        logging.error(f"ë©”ì¸ í•¨ìˆ˜ ì˜¤ë¥˜: {str(e)}", exc_info=True)

if __name__ == "__main__":
    asyncio.run(main())
