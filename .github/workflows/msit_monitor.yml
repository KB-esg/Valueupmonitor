name: MSIT Telco Service Monitoring

on:
  schedule:
    - cron: '40 23 1-31/2 * *'  # UTC 23:40 (KST 08:40) 홀수날마다 실행
  workflow_dispatch:
    inputs:
      days_range:
        description: '몇 일 전까지의 게시물을 확인할지 설정'
        required: false
        default: '4'
        type: string
      check_sheets:
        description: 'Google Sheets 업데이트 여부'
        required: false
        default: 'true'
        type: boolean
      spreadsheet_name:
        description: 'Google Sheets 스프레드시트 이름'
        required: false
        default: 'MSIT 통신 통계'
        type: string

permissions:
  contents: write

jobs:
  monitor:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
    - name: Checkout repository
      uses: actions/checkout@v3
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        cache: 'pip'

    - name: Install Chrome
      run: |
        sudo apt-get update
        sudo apt-get install -y google-chrome-stable
        google-chrome --version  # 디버깅용 버전 출력

    - name: Install Xvfb
      run: sudo apt-get install -y xvfb

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        if [ -f requirements.txt ]; then
          pip install -r requirements.txt
        else
          pip install selenium beautifulsoup4 python-telegram-bot requests pandas gspread oauth2client lxml html5lib selenium-stealth webdriver-manager
        fi

    - name: Create directories
      run: |
        mkdir -p downloads
        mkdir -p screenshots
        mkdir -p html_content  # HTML 내용을 저장할 디렉토리 추가

    - name: Fix indentation issues
      run: |
        cat > fix_indentation.py << 'EOF'
        #!/usr/bin/env python
    
        def convert_tabs_to_spaces():
            with open('msit_monitor.py', 'r') as file:
                content = file.read()
        
            # Convert all tabs to 4 spaces
            fixed_content = content.replace('\t', '    ')
        
            with open('msit_monitor.py', 'w') as file:
                file.write(fixed_content)
        
            print("All tabs converted to spaces in the file")
    
        if __name__ == "__main__":
            convert_tabs_to_spaces()
        EOF
    
        python fix_indentation.py

    - name: Create document viewer script
      run: |
        cat > document_capture.py << 'EOF'
        from selenium import webdriver
        from selenium.webdriver.chrome.service import Service
        from selenium.webdriver.chrome.options import Options
        from selenium.webdriver.common.by import By
        from selenium.webdriver.support.ui import WebDriverWait
        from selenium.webdriver.support import expected_conditions as EC
        from webdriver_manager.chrome import ChromeDriverManager
        import time
        import sys
        import os
        import random
        import json
        import re

        def capture_document_content(url, file_id, order_id):
            options = Options()
            options.add_argument('--no-sandbox')
            options.add_argument('--disable-dev-shm-usage')
            options.add_argument("--headless")
            options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64)")
            options.add_experimental_option("excludeSwitches", ["enable-automation"])
            options.add_experimental_option("useAutomationExtension", False)
            
            # 중요: 고유한 사용자 데이터 디렉터리 사용
            unique_dir = f'/tmp/chrome-user-data-{int(time.time())}-{random.randint(1000, 9999)}'
            options.add_argument(f'--user-data-dir={unique_dir}')
            print(f"Chrome 사용자 데이터 디렉토리: {unique_dir}")
            
            print("ChromeDriver 설치 시작...")
            driver_path = ChromeDriverManager().install()
            print(f"ChromeDriver 설치 완료: {driver_path}")
            
            driver = webdriver.Chrome(service=Service(driver_path), options=options)
            
            try:
                print(f"문서 뷰어 URL 접속: {url}")
                driver.get(url)
                print("문서 로딩 대기 중...")
                time.sleep(10)  # 문서 뷰어 로딩 대기
                
                driver.save_screenshot(f"html_content/document_{file_id}_{order_id}_screenshot.png")
                print(f"문서 뷰어 스크린샷 저장 완료")
                
                # HTML 내용 저장
                html_content = driver.page_source
                with open(f"html_content/document_{file_id}_{order_id}_content.html", "w", encoding="utf-8") as f:
                    f.write(html_content)
                print(f"HTML 내용 저장 완료")
                
                # 시트 탭 확인
                sheet_tabs = driver.find_elements(By.CSS_SELECTOR, ".sheet-tab")
                sheet_names = []
                if sheet_tabs:
                    print(f"{len(sheet_tabs)}개 시트 탭 발견")
                    for idx, tab in enumerate(sheet_tabs):
                        sheet_name = tab.get_attribute("textContent") or f"Sheet{idx+1}"
                        sheet_names.append(sheet_name.strip())
                        print(f"시트 {idx+1}: {sheet_name.strip()}")
                        
                        # 각 시트 탭 클릭하고 내용 저장
                        try:
                            tab.click()
                            time.sleep(3)  # 탭 전환 대기
                            
                            driver.save_screenshot(f"html_content/document_{file_id}_{order_id}_sheet_{idx+1}.png")
                            
                            sheet_html = driver.page_source
                            with open(f"html_content/document_{file_id}_{order_id}_sheet_{idx+1}.html", "w", encoding="utf-8") as f:
                                f.write(sheet_html)
                            print(f"시트 {idx+1} HTML 내용 저장 완료")
                            
                            # JavaScript를 통해 테이블 내용 추출 시도
                            try:
                                tables_data = driver.execute_script('''
                                    const tables = document.querySelectorAll('table');
                                    let result = [];
                                    
                                    tables.forEach((table, tableIndex) => {
                                        let tableData = {
                                            id: tableIndex,
                                            rows: [],
                                            dimensions: { rows: 0, cols: 0 }
                                        };
                                        
                                        const rows = table.querySelectorAll('tr');
                                        tableData.dimensions.rows = rows.length;
                                        
                                        rows.forEach((row, rowIndex) => {
                                            const cells = row.querySelectorAll('td, th');
                                            if (rowIndex === 0) {
                                                tableData.dimensions.cols = cells.length;
                                            }
                                            
                                            let rowData = [];
                                            cells.forEach(cell => {
                                                rowData.push(cell.textContent.trim());
                                            });
                                            
                                            tableData.rows.push(rowData);
                                        });
                                        
                                        result.push(tableData);
                                    });
                                    
                                    return result;
                                ''')
                                
                                if tables_data:
                                    with open(f"html_content/document_{file_id}_{order_id}_sheet_{idx+1}_tables.json", "w", encoding="utf-8") as f:
                                        json.dump(tables_data, f, ensure_ascii=False, indent=2)
                                    print(f"시트 {idx+1}에서 {len(tables_data)}개 테이블 데이터 추출 완료")
                                else:
                                    print(f"시트 {idx+1}에서 테이블 데이터 추출 실패")
                            except Exception as js_error:
                                print(f"테이블 데이터 추출 JavaScript 오류: {str(js_error)}")
                                
                        except Exception as click_error:
                            print(f"시트 탭 클릭 오류: {str(click_error)}")
                            
                    # 시트 정보 저장
                    with open(f"html_content/document_{file_id}_{order_id}_sheets.json", "w", encoding="utf-8") as f:
                        json.dump(sheet_names, f, ensure_ascii=False, indent=2)
                else:
                    print("시트 탭을 찾을 수 없음")
                    
                # iframe 내용 확인
                iframes = driver.find_elements(By.TAG_NAME, "iframe")
                if iframes:
                    print(f"{len(iframes)}개 iframe 발견")
                    for idx, iframe in enumerate(iframes):
                        try:
                            driver.switch_to.frame(iframe)
                            iframe_html = driver.page_source
                            with open(f"html_content/document_{file_id}_{order_id}_iframe_{idx+1}.html", "w", encoding="utf-8") as f:
                                f.write(iframe_html)
                            print(f"iframe {idx+1} 내용 저장 완료")
                            driver.switch_to.default_content()  # 기본 컨텍스트로 복귀
                        except Exception as iframe_error:
                            print(f"iframe {idx+1} 처리 오류: {str(iframe_error)}")
                            driver.switch_to.default_content()
                    
                return True
                
            except Exception as e:
                print(f'문서 내용 캡처 오류: {str(e)}')
                return False
            finally:
                print("WebDriver 종료")
                driver.quit()
        
        if __name__ == "__main__":
            if len(sys.argv) < 2:
                print("사용법: python document_capture.py <문서뷰어URL> <파일ID> <순서ID>")
                sys.exit(1)
                
            url = sys.argv[1]
            file_id = sys.argv[2] if len(sys.argv) > 2 else "unknown"
            order_id = sys.argv[3] if len(sys.argv) > 3 else "1"
            
            success = capture_document_content(url, file_id, order_id)
            if success:
                print("문서 내용 캡처 성공")
            else:
                print("문서 내용 캡처 실패")
                sys.exit(1)
        EOF

    - name: Run monitoring script
      env:
        TELCO_NEWS_TOKEN: ${{ secrets.TELCO_NEWS_TOKEN }}
        TELCO_NEWS_TESTER: ${{ secrets.TELCO_NEWS_TESTER }}
        MSIT_GSPREAD_ref: ${{ secrets.MSIT_GSPREAD_ref }}
        MSIT_SPREADSHEET_ID: ${{ secrets.MSIT_SPREADSHEET_ID }}
        DAYS_RANGE: ${{ github.event.inputs.days_range || '4' }}
        CHECK_SHEETS: ${{ github.event.inputs.check_sheets || 'true' }}
        SPREADSHEET_NAME: ${{ github.event.inputs.spreadsheet_name || 'MSIT 통신 통계' }}
        PYTHONIOENCODING: utf-8
      run: |
        export DISPLAY=:99
        Xvfb :99 -screen 0 1920x1080x24 > /dev/null 2>&1 &
        sleep 2
        
        # 모니터링 스크립트 실행
        echo "모니터링 스크립트 실행..."
        python msit_monitor.py || { echo "모니터링 스크립트 실행 실패"; exit 1; }

    - name: Capture document content (if document view URL exists)
      if: always()
      run: |
        export DISPLAY=:99
        
        # 로그 파일에서 바로보기 URL 추출
        DOCUMENT_VIEW_URL=$(grep -o "바로보기 URL: [^ ]*" *.log 2>/dev/null | head -1 | sed 's/바로보기 URL: //')
        
        if [ -n "$DOCUMENT_VIEW_URL" ]; then
          echo "바로보기 URL 발견: $DOCUMENT_VIEW_URL"
          
          # URL에서 파일 ID와 순서 ID 추출
          FILE_ID=$(echo $DOCUMENT_VIEW_URL | grep -o "atchFileNo=[0-9]*" | sed 's/atchFileNo=//')
          ORDER_ID=$(echo $DOCUMENT_VIEW_URL | grep -o "fileOrdr=[0-9]*" | sed 's/fileOrdr=//')
          
          echo "문서 캡처 스크립트 실행..."
          python document_capture.py "$DOCUMENT_VIEW_URL" "$FILE_ID" "$ORDER_ID"
          
          # 캡처된 HTML 파일 확인
          echo "캡처된 HTML 파일 목록:"
          ls -la html_content/
        else
          echo "바로보기 URL을 찾을 수 없음"
        fi

    - name: Process captured HTML files
      if: always()
      run: |
        # HTML 파일이 존재하는지 확인
        if [ -d "html_content" ] && [ "$(ls -A html_content/*.html 2>/dev/null)" ]; then
          echo "HTML 파일 처리 중..."
          
          # JSON 테이블 파일이 존재하는지 확인
          TABLE_FILES=$(find html_content/ -name "*_tables.json" 2>/dev/null)
          
          if [ -n "$TABLE_FILES" ]; then
            echo "테이블 데이터 파일 발견:"
            ls -la $TABLE_FILES
            
            # 테이블 데이터 파일 내용 확인
            for file in $TABLE_FILES; do
              echo "파일 내용: $file"
              cat $file | head -50
              echo "..."
            done
            
            # 테이블 데이터 처리 스크립트 생성
            cat > process_tables.py << 'EOF'
            import json
            import os
            import pandas as pd
            import glob
            import sys

            def process_table_files():
                table_files = glob.glob('html_content/*_tables.json')
                if not table_files:
                    print("테이블 데이터 파일을 찾을 수 없음")
                    return False
                    
                print(f"{len(table_files)}개 테이블 파일 발견")
                
                all_tables = []
                
                for file_path in table_files:
                    sheet_name = os.path.basename(file_path).split('_sheet_')[1].split('_')[0]
                    print(f"시트 {sheet_name} 처리 중...")
                    
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            tables_data = json.load(f)
                            
                        for table_idx, table in enumerate(tables_data):
                            if not table.get('rows'):
                                continue
                                
                            try:
                                df = pd.DataFrame(table['rows'])
                                
                                # 첫 번째 행이 헤더인지 확인
                                if len(df) > 1:
                                    # 첫 번째 행을 헤더로 사용
                                    headers = df.iloc[0].tolist()
                                    df = df.iloc[1:]
                                    df.columns = headers
                                
                                # CSV로 저장
                                csv_file = f'html_content/extracted_table_sheet_{sheet_name}_table_{table_idx}.csv'
                                df.to_csv(csv_file, index=False, encoding='utf-8-sig')
                                print(f"테이블 데이터 CSV 저장 완료: {csv_file}")
                                
                                all_tables.append((sheet_name, table_idx, df))
                            except Exception as df_error:
                                print(f"테이블 {table_idx} 데이터프레임 변환 오류: {str(df_error)}")
                    except Exception as file_error:
                        print(f"파일 처리 오류: {str(file_error)}")
                
                if all_tables:
                    # 결합된 데이터 엑셀로 저장
                    try:
                        with pd.ExcelWriter('html_content/combined_tables.xlsx') as writer:
                            for sheet_name, table_idx, df in all_tables:
                                sheet_name_safe = f"{sheet_name}_Table{table_idx}"[:31]  # 엑셀 시트 이름 길이 제한
                                df.to_excel(writer, sheet_name=sheet_name_safe, index=False)
                        print("모든 테이블 데이터 엑셀 파일로 결합 완료")
                        return True
                    except Exception as excel_error:
                        print(f"엑셀 파일 생성 오류: {str(excel_error)}")
                
                return len(all_tables) > 0

            if __name__ == "__main__":
                success = process_table_files()
                if not success:
                    print("테이블 데이터 처리 실패")
                    sys.exit(1)
            EOF
            
            # 테이블 처리 스크립트 실행
            python process_tables.py || echo "테이블 처리 스크립트 실패, 계속 진행"
          else
            echo "테이블 데이터 파일이 없음"
          fi
        else
          echo "HTML 파일이 없음"
        fi

    - name: Archive artifacts
      if: always()
      run: |
        TIMESTAMP=$(date +%Y%m%d_%H%M%S)
        mkdir -p artifacts
        cp -r *.log *.png *.html downloads/* screenshots/* html_content/* *.bak artifacts/ 2>/dev/null || true
        echo "실행 정보:" > artifacts/run_info.txt
        echo "실행 ID: ${{ github.run_id }}" >> artifacts/run_info.txt
        echo "실행 번호: ${{ github.run_number }}" >> artifacts/run_info.txt
        echo "타임스탬프: ${TIMESTAMP}" >> artifacts/run_info.txt
        echo "실행자: ${{ github.actor }}" >> artifacts/run_info.txt
        echo "워크플로우: ${{ github.workflow }}" >> artifacts/run_info.txt
        tar -czf monitoring-artifacts-${TIMESTAMP}.tar.gz artifacts/
        echo "ARTIFACT_PATH=monitoring-artifacts-${TIMESTAMP}.tar.gz" >> $GITHUB_ENV
        echo "ARTIFACT_NAME=monitoring-artifacts-${TIMESTAMP}" >> $GITHUB_ENV
        echo "TIMESTAMP=${TIMESTAMP}" >> $GITHUB_ENV

    - name: Create Release
      if: always()
      uses: softprops/action-gh-release@v1
      with:
        tag_name: monitoring-${{ env.TIMESTAMP }}
        name: 모니터링 실행 ${{ github.run_number }} (${{ env.TIMESTAMP }})
        files: ${{ env.ARTIFACT_PATH }}
        body: |
          ## MSIT 통신 통계 모니터링 실행 결과
          - **실행 ID**: ${{ github.run_id }}
          - **실행 번호**: ${{ github.run_number }}
          - **실행 시간**: ${{ env.TIMESTAMP }}
          - **실행 유형**: ${{ github.event_name }}
          이 릴리스에는 모니터링 스크립트 실행 결과와 관련 로그 및 스크린샷이 포함되어 있습니다.
        token: ${{ secrets.GITHUB_TOKEN }}
