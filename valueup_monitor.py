import os
import requests
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
import telegram
import asyncio
import logging
from typing import List, Dict
import re

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

class KRXMonitor:
    def __init__(self):
        self.telegram_token = os.environ.get('TELEGRAM_TOKEN')
        self.chat_id = os.environ.get('CHAT_ID')
        if not self.telegram_token or not self.chat_id:
            raise ValueError("í™˜ê²½ ë³€ìˆ˜ TELEGRAM_TOKENê³¼ CHAT_IDê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            
        self.base_url = "https://kind.krx.co.kr/valueup/disclsstat.do"
        self.bot = telegram.Bot(token=self.telegram_token)

    def fetch_krx_data(self, page: int = 1) -> str:
        """KRX ì›¹ì‚¬ì´íŠ¸ì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        params = {
            "method": "valueupDisclsStatMain",
            "currentPageSize": "15",
            "pageIndex": str(page)
        }
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        try:
            response = requests.get(self.base_url, params=params, headers=headers)
            response.raise_for_status()
            return response.text
        except Exception as e:
            logging.error(f"KRX ë°ì´í„° ìš”ì²­ ì‹¤íŒ¨ (í˜ì´ì§€ {page}): {e}")
            raise

    def get_total_pages(self, html_content: str) -> int:
        """ì´ í˜ì´ì§€ ìˆ˜ ì¶”ì¶œ"""
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            info_div = soup.find('div', {'class': 'info', 'type': '00'})
            if info_div:
                # "1/6" í˜•íƒœì—ì„œ ì´ í˜ì´ì§€ ìˆ˜ ì¶”ì¶œ
                match = re.search(r'/(\d+)', info_div.text)
                if match:
                    return int(match.group(1))
            return 1
        except Exception as e:
            logging.error(f"ì´ í˜ì´ì§€ ìˆ˜ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return 1

    def parse_disclosures(self, html_content: str, week_ago: datetime) -> tuple[List[Dict], bool]:
        """HTML ì»¨í…ì¸ ì—ì„œ ê³µì‹œ ì •ë³´ íŒŒì‹±"""
        soup = BeautifulSoup(html_content, 'html.parser')
        table = soup.find('table', {'class': 'list type-00 mt10'})
        
        if not table:
            logging.error("í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return [], False

        disclosures = []
        need_next_page = False
        
        # tbody ë‚´ì˜ ëª¨ë“  tr íƒœê·¸ ì°¾ê¸°
        rows = table.find('tbody').find_all('tr')
        
        logging.info(f"ì´ {len(rows)}ê°œì˜ í–‰ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
        
        for row in rows:
            try:
                cols = row.find_all('td')
                if len(cols) >= 4:
                    date_str = cols[1].text.strip()
                    company = cols[2].find('a', {'id': 'companysum'}).text.strip()
                    title = cols[3].find('a').text.strip()
                    
                    try:
                        disclosure_date = datetime.strptime(date_str, '%Y-%m-%d %H:%M')
                        
                        if disclosure_date >= week_ago:
                            disclosures.append({
                                'date': date_str,
                                'company': company,
                                'title': title
                            })
                            logging.info(f"íŒŒì‹± ì„±ê³µ: {date_str} - {company}")
                        elif len(disclosures) > 0:
                            # ì¼ì£¼ì¼ ì´ì „ ë°ì´í„°ê°€ ë‚˜ì˜¤ë©´ ì¤‘ë‹¨
                            break
                        
                        # ë§ˆì§€ë§‰ í–‰ì´ ì¼ì£¼ì¼ ì´ë‚´ë¼ë©´ ë‹¤ìŒ í˜ì´ì§€ í•„ìš”
                        if row == rows[-1] and disclosure_date >= week_ago:
                            need_next_page = True
                            
                    except ValueError as e:
                        logging.error(f"ë‚ ì§œ íŒŒì‹± ì—ëŸ¬: {date_str} - {e}")
                        continue
                        
            except Exception as e:
                logging.error(f"í–‰ íŒŒì‹± ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
                continue

        return disclosures, need_next_page

    async def send_telegram_message(self, message: str):
        """í…”ë ˆê·¸ë¨ìœ¼ë¡œ ë©”ì‹œì§€ ì „ì†¡"""
        try:
            chat_id = int(self.chat_id)
            await self.bot.send_message(
                chat_id=chat_id,
                text=message,
                parse_mode='HTML',
                disable_web_page_preview=True
            )
            logging.info("í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ ì „ì†¡ ì„±ê³µ")
        except ValueError as e:
            logging.error(f"ì˜ëª»ëœ chat_id í˜•ì‹: {self.chat_id}")
            raise
        except Exception as e:
            logging.error(f"í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ ì „ì†¡ ì‹¤íŒ¨: {e}")
            raise

    def format_message(self, disclosures: List[Dict]) -> str:
        """ê³µì‹œ ì •ë³´ë¥¼ í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        if not disclosures:
            return "ìµœê·¼ ì¼ì£¼ì¼ê°„ ì‹ ê·œ ê¸°ì—…ê°€ì¹˜ ì œê³  ê³„íš ê³µì‹œê°€ ì—†ìŠµë‹ˆë‹¤."

        message = "<b>ğŸ”” ìµœê·¼ ì¼ì£¼ì¼ ê¸°ì—…ê°€ì¹˜ ì œê³  ê³„íš ê³µì‹œ</b>\n\n"
        
        from itertools import groupby
        from operator import itemgetter
        
        sorted_disclosures = sorted(disclosures, key=itemgetter('date'), reverse=True)
        
        for date, group in groupby(sorted_disclosures, key=itemgetter('date')):
            message += f"ğŸ“… <b>{date}</b>\n"
            for disc in group:
                message += f"â€¢ {disc['company']}\n"
                message += f"  â”” {disc['title']}\n"
            message += "\n"

        message += f"\nì´ {len(disclosures)}ê±´ì˜ ê³µì‹œê°€ ìˆìŠµë‹ˆë‹¤."
        return message

    async def run_weekly_check(self):
        """ì£¼ê°„ ëª¨ë‹ˆí„°ë§ ì‹¤í–‰"""
        try:
            all_disclosures = []
            page = 1
            week_ago = datetime.now() - timedelta(days=7)
            
            while True:
                html_content = self.fetch_krx_data(page)
                disclosures, need_next_page = self.parse_disclosures(html_content, week_ago)
                all_disclosures.extend(disclosures)
                
                if not need_next_page:
                    break
                    
                total_pages = self.get_total_pages(html_content)
                if page >= total_pages:
                    break
                    
                page += 1
                logging.info(f"ë‹¤ìŒ í˜ì´ì§€({page}) í™•ì¸ ì¤‘...")
            
            logging.info(f"ì „ì²´ {len(all_disclosures)}ê°œì˜ ê³µì‹œ ìˆ˜ì§‘ ì™„ë£Œ")
            message = self.format_message(all_disclosures)
            await self.send_telegram_message(message)
            
        except Exception as e:
            error_message = f"ëª¨ë‹ˆí„°ë§ ì¤‘ ì—ëŸ¬ ë°œìƒ: {str(e)}"
            logging.error(error_message)
            try:
                await self.send_telegram_message(f"âš ï¸ {error_message}")
            except Exception as telegram_error:
                logging.error(f"ì—ëŸ¬ ë©”ì‹œì§€ ì „ì†¡ ì‹¤íŒ¨: {telegram_error}")

def main():
    monitor = KRXMonitor()
    asyncio.run(monitor.run_weekly_check())

if __name__ == "__main__":
    main()
