import asyncio
from playwright.async_api import async_playwright
import pandas as pd
import gspread
from google.oauth2.service_account import Credentials
from datetime import datetime, timedelta
import json
import os
import requests
import time
import re
from PIL import Image, ImageDraw, ImageEnhance
import pytesseract
import numpy as np
import cv2
import glob
from tqdm import tqdm

class ESGFundScraper:
    def __init__(self):
        self.base_url = "https://www.fundguide.net/hkcenter/esg"
        self.telegram_bot_token = os.environ.get('TELCO_NEWS_TOKEN')
        self.telegram_chat_id = os.environ.get('TELCO_NEWS_TESTER')
        # í™˜ê²½ ë³€ìˆ˜ì—ì„œ ê¸°ê°„ ì„¤ì • ê°€ì ¸ì˜¤ê¸° (ê¸°ë³¸ê°’: 1ê°œì›”)
        self.collection_period = os.environ.get('COLLECTION_PERIOD', '01')
        self.period_text_map = {
            '01': '1ê°œì›”',
            '03': '3ê°œì›”',
            '06': '6ê°œì›”',
            'YTD': 'ì—°ì´ˆì´í›„',
            '12': '1ë…„',
            '36': '3ë…„',
            '60': '5ë…„'
        }
        print(f"ğŸ“… Collection period set to: {self.collection_period} ({self.period_text_map.get(self.collection_period, self.collection_period)})")
        
    async def extract_chart_data_via_javascript(self, page):
        """JavaScriptë¥¼ í†µí•´ Highcharts ë°ì´í„° ì§ì ‘ ì¶”ì¶œ"""
        try:
            chart_data = await page.evaluate('''
                () => {
                    // Highcharts ì¸ìŠ¤í„´ìŠ¤ ì°¾ê¸°
                    let chartData = {
                        dates: [],
                        setup_amounts: [],
                        returns: [],
                        debug_info: {}
                    };
                    
                    // ë°©ë²• 1: Highcharts.charts ë°°ì—´ì—ì„œ ì°¾ê¸°
                    if (typeof Highcharts !== 'undefined' && Highcharts.charts) {
                        for (let i = 0; i < Highcharts.charts.length; i++) {
                            let chart = Highcharts.charts[i];
                            if (chart && chart.container && chart.container.id === 'lineAreaZone') {
                                console.log('Found chart at index:', i);
                                chartData.debug_info.chart_found = true;
                                chartData.debug_info.chart_index = i;
                                
                                // Xì¶• ì¹´í…Œê³ ë¦¬ (ë‚ ì§œ)
                                if (chart.xAxis && chart.xAxis[0]) {
                                    // categoriesê°€ ì—†ìœ¼ë©´ tick labelsì—ì„œ ì¶”ì¶œ
                                    if (chart.xAxis[0].categories && chart.xAxis[0].categories.length > 0) {
                                        chartData.dates = chart.xAxis[0].categories;
                                        chartData.debug_info.date_source = 'categories';
                                    } else if (chart.xAxis[0].tickPositions) {
                                        // Xì¶• ë ˆì´ë¸”ì—ì„œ ì§ì ‘ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                                        const labels = [];
                                        chart.xAxis[0].ticks && Object.values(chart.xAxis[0].ticks).forEach(tick => {
                                            if (tick.label && tick.label.textStr) {
                                                labels.push(tick.label.textStr);
                                            }
                                        });
                                        chartData.dates = labels;
                                        chartData.debug_info.date_source = 'tick_labels';
                                    }
                                    
                                    // Xì¶• ì •ë³´ ë””ë²„ê¹…
                                    chartData.debug_info.xaxis_min = chart.xAxis[0].min;
                                    chartData.debug_info.xaxis_max = chart.xAxis[0].max;
                                    chartData.debug_info.xaxis_type = chart.xAxis[0].type;
                                }
                                
                                // ì‹œë¦¬ì¦ˆ ë°ì´í„°
                                if (chart.series && chart.series.length > 0) {
                                    chartData.debug_info.series_count = chart.series.length;
                                    chartData.debug_info.series_info = [];
                                    
                                    chart.series.forEach((series, index) => {
                                        const seriesInfo = {
                                            name: series.name,
                                            visible: series.visible,
                                            data_length: series.data ? series.data.length : 0,
                                            type: series.type
                                        };
                                        chartData.debug_info.series_info.push(seriesInfo);
                                        
                                        if (series.visible && series.data && series.data.length > 0) {
                                            const values = series.data.map(point => {
                                                if (point.y !== undefined) return point.y;
                                                if (point.options && point.options.y !== undefined) return point.options.y;
                                                return null;
                                            });
                                            
                                            // ë‚ ì§œê°€ ì—†ëŠ” ê²½ìš° ë°ì´í„° í¬ì¸íŠ¸ì—ì„œ ì¶”ì¶œ ì‹œë„
                                            if (chartData.dates.length === 0 && series.data[0].category) {
                                                chartData.dates = series.data.map(point => point.category || '');
                                                chartData.debug_info.date_source = 'series_categories';
                                            }
                                            
                                            // ì‹œë¦¬ì¦ˆ ì´ë¦„ìœ¼ë¡œ êµ¬ë¶„ (ì—†ìœ¼ë©´ ì¸ë±ìŠ¤ë¡œ)
                                            if (series.name) {
                                                if (series.name.includes('ì„¤ì •ì•¡') || series.name.includes('ì¢Œ')) {
                                                    chartData.setup_amounts = values;
                                                } else if (series.name.includes('ìˆ˜ìµë¥ ') || series.name.includes('ìš°')) {
                                                    chartData.returns = values;
                                                }
                                            } else {
                                                // ì´ë¦„ì´ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ì‹œë¦¬ì¦ˆë¥¼ ì„¤ì •ì•¡, ë‘ ë²ˆì§¸ë¥¼ ìˆ˜ìµë¥ ë¡œ ê°€ì •
                                                if (index === 0) {
                                                    chartData.setup_amounts = values;
                                                } else if (index === 1) {
                                                    chartData.returns = values;
                                                }
                                            }
                                        }
                                    });
                                }
                                
                                // Yì¶• ì •ë³´ë„ ì¶”ì¶œ (ê°’ ë²”ìœ„ íŒŒì•…ìš©)
                                if (chart.yAxis) {
                                    chartData.debug_info.yaxis_count = chart.yAxis.length;
                                    chartData.debug_info.yaxis_info = [];
                                    chart.yAxis.forEach((axis, index) => {
                                        chartData.debug_info.yaxis_info.push({
                                            index: index,
                                            min: axis.min,
                                            max: axis.max,
                                            title: axis.options.title ? axis.options.title.text : null
                                        });
                                    });
                                }
                                
                                break;
                            }
                        }
                    }
                    
                    // ë°©ë²• 2: data-highcharts-chart ì†ì„±ìœ¼ë¡œ ì°¾ê¸°
                    if (chartData.dates.length === 0) {
                        const chartDiv = document.querySelector('#lineAreaZone');
                        if (chartDiv) {
                            const chartIndex = chartDiv.getAttribute('data-highcharts-chart');
                            if (chartIndex && Highcharts.charts[chartIndex]) {
                                const chart = Highcharts.charts[chartIndex];
                                console.log('Found chart via data attribute');
                                chartData.debug_info.chart_found_method = 'data-attribute';
                                
                                // ìœ„ì™€ ë™ì¼í•œ ë¡œì§ìœ¼ë¡œ ë°ì´í„° ì¶”ì¶œ
                                if (chart.xAxis && chart.xAxis[0] && chart.xAxis[0].categories) {
                                    chartData.dates = chart.xAxis[0].categories;
                                }
                                
                                if (chart.series) {
                                    chart.series.forEach((series, index) => {
                                        if (series.data) {
                                            const values = series.data.map(point => point.y);
                                            if (index === 0) chartData.setup_amounts = values;
                                            else if (index === 1) chartData.returns = values;
                                        }
                                    });
                                }
                            }
                        }
                    }
                    
                    // ë°©ë²• 3: SVG ìš”ì†Œì—ì„œ ì§ì ‘ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ì°¨ì„ ì±…)
                    if (chartData.dates.length === 0) {
                        const xLabels = document.querySelectorAll('.highcharts-xaxis-labels text');
                        xLabels.forEach(label => {
                            if (label.textContent) {
                                chartData.dates.push(label.textContent);
                            }
                        });
                        if (chartData.dates.length > 0) {
                            chartData.debug_info.date_source = 'svg_labels';
                        }
                    }
                    
                    console.log('Extracted data:', chartData);
                    return chartData;
                }
            ''')
            
            if chart_data:
                print(f"ğŸ“Š JavaScript extraction result:")
                print(f"   Dates: {len(chart_data.get('dates', []))} items")
                print(f"   Setup amounts: {len(chart_data.get('setup_amounts', []))} items")
                print(f"   Returns: {len(chart_data.get('returns', []))} items")
                
                # ë””ë²„ê·¸ ì •ë³´ ì¶œë ¥
                if chart_data.get('debug_info'):
                    debug = chart_data['debug_info']
                    print(f"   Debug Info:")
                    print(f"     - Chart found: {debug.get('chart_found', False)}")
                    print(f"     - Date source: {debug.get('date_source', 'unknown')}")
                    print(f"     - Series count: {debug.get('series_count', 0)}")
                    if debug.get('series_info'):
                        for i, series in enumerate(debug['series_info']):
                            print(f"     - Series {i}: {series.get('name', 'unnamed')} ({series.get('data_length', 0)} points)")
                
                # ë°ì´í„° ê²€ì¦
                if chart_data.get('dates'):
                    print(f"   First 3 dates: {chart_data['dates'][:3]}...")
                    print(f"   Last 3 dates: {chart_data['dates'][-3:]}...")
                if chart_data.get('setup_amounts'):
                    print(f"   Setup amounts sample: {chart_data['setup_amounts'][:3]}...")
                if chart_data.get('returns'):
                    print(f"   Returns sample: {chart_data['returns'][:3]}...")
                    
                return chart_data
                
        except Exception as e:
            print(f"âŒ JavaScript extraction failed: {e}")
            import traceback
            traceback.print_exc()
        
        return None

    async def extract_chart_data(self, page, tab_name):
        """ì°¨íŠ¸ ë°ì´í„° ì¶”ì¶œ (JavaScriptì™€ OCR ë‘˜ ë‹¤ ìˆ˜í–‰í•˜ì—¬ ë¹„êµ)"""
        # 1. JavaScriptë¡œ ì§ì ‘ ì¶”ì¶œ ì‹œë„
        js_data = await self.extract_chart_data_via_javascript(page)
        
        # 2. ì´ë¯¸ì§€ OCR ë¶„ì„ë„ ìˆ˜í–‰ (ë¹„êµìš©)
        ocr_data = await self.extract_chart_data_with_ocr_analysis(page, tab_name)
        
        # ë‘ ë°©ë²• ëª¨ë‘ì˜ ê²°ê³¼ë¥¼ ë°˜í™˜
        return {
            'js_data': js_data,
            'ocr_data': ocr_data,
            'primary_data': js_data if js_data and js_data.get('dates') else ocr_data
        }
    
    async def extract_chart_data_with_ocr_analysis(self, page, tab_name):
        """ì°¨íŠ¸ ì´ë¯¸ì§€ OCR ë¶„ì„ ë° SVG ê²½ë¡œ ë¶„ì„"""
        chart_data = {
            'dates': [],
            'setup_amounts': [],
            'returns': []
        }
        
        try:
            # ì°¨íŠ¸ ì»¨í…Œì´ë„ˆ ì°¾ê¸°
            chart_container = await page.query_selector('#lineAreaZone')
            if not chart_container:
                print("âŒ Chart container #lineAreaZone not found")
                return chart_data
            
            # ì°¨íŠ¸ ì˜ì—­ ìŠ¤í¬ë¦°ìƒ·
            screenshot_dir = 'chart_analysis'
            if not os.path.exists(screenshot_dir):
                os.makedirs(screenshot_dir)
            
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            chart_path = f'{screenshot_dir}/{tab_name}_chart_{timestamp}.png'
            await chart_container.screenshot(path=chart_path)
            print(f"ğŸ“· Chart screenshot saved: {chart_path}")
            
            # SVG ê²½ë¡œ ë°ì´í„° ì§ì ‘ ì¶”ì¶œ ì‹œë„
            svg_data = await self.extract_svg_path_data(page)
            if svg_data and svg_data.get('dates'):
                print(f"âœ… SVG path analysis successful: {len(svg_data['dates'])} data points")
                return svg_data
            
            # SVG ë¶„ì„ì´ ì‹¤íŒ¨í•˜ë©´ ì´ë¯¸ì§€ OCR ì‹œë„
            # í˜„ì¬ëŠ” êµ¬í˜„í•˜ì§€ ì•ŠìŒ (í•„ìš”ì‹œ ì¶”ê°€ ê°€ëŠ¥)
            
        except Exception as e:
            print(f"âŒ Error in chart image analysis: {e}")
        
        return chart_data
    
    async def extract_svg_path_data(self, page):
        """SVG path ìš”ì†Œì—ì„œ ì§ì ‘ ë°ì´í„° í¬ì¸íŠ¸ ì¶”ì¶œ"""
        try:
            svg_data = await page.evaluate('''
                () => {
                    const result = {
                        dates: [],
                        setup_amounts: [],
                        returns: [],
                        debug_info: {}
                    };
                    
                    // Highcharts SVG ì»¨í…Œì´ë„ˆ ì°¾ê¸°
                    const chartContainer = document.querySelector('#lineAreaZone');
                    if (!chartContainer) return result;
                    
                    const svg = chartContainer.querySelector('svg.highcharts-root');
                    if (!svg) return result;
                    
                    // ëª¨ë“  ì‹œë¦¬ì¦ˆ path ì°¾ê¸°
                    const seriesPaths = svg.querySelectorAll('path.highcharts-graph');
                    result.debug_info.series_count = seriesPaths.length;
                    
                    if (seriesPaths.length === 0) {
                        // ë‹¤ë¥¸ ì„ íƒì ì‹œë„
                        const allPaths = svg.querySelectorAll('path[d]');
                        result.debug_info.total_paths = allPaths.length;
                        
                        // ì°¨íŠ¸ ë°ì´í„°ë¥¼ í¬í•¨í•˜ëŠ” path ì°¾ê¸° (ë³´í†µ ê¸´ path)
                        allPaths.forEach((path, index) => {
                            const d = path.getAttribute('d');
                            if (d && d.length > 100) { // ì¶©ë¶„íˆ ê¸´ pathë§Œ
                                const points = parsePathData(d);
                                if (points.length > 10) { // ì¶©ë¶„í•œ ë°ì´í„° í¬ì¸íŠ¸ê°€ ìˆëŠ” ê²½ìš°
                                    result.debug_info[`path_${index}`] = {
                                        points: points.length,
                                        class: path.getAttribute('class'),
                                        stroke: path.getAttribute('stroke')
                                    };
                                }
                            }
                        });
                    }
                    
                    // Xì¶• ë ˆì´ë¸”ì—ì„œ ë‚ ì§œ ì¶”ì¶œ
                    const xLabels = svg.querySelectorAll('.highcharts-xaxis-labels text');
                    const xLabelData = [];
                    xLabels.forEach(label => {
                        const text = label.textContent;
                        const x = parseFloat(label.getAttribute('x'));
                        if (text && !isNaN(x)) {
                            xLabelData.push({ text, x });
                        }
                    });
                    xLabelData.sort((a, b) => a.x - b.x);
                    result.dates = xLabelData.map(d => d.text);
                    result.debug_info.x_labels_count = result.dates.length;
                    
                    // Path ë°ì´í„° íŒŒì‹± í•¨ìˆ˜
                    function parsePathData(d) {
                        const points = [];
                        const commands = d.match(/[MLHVCSQTAZmlhvcsqtaz][^MLHVCSQTAZmlhvcsqtaz]*/g);
                        if (!commands) return points;
                        
                        let currentX = 0, currentY = 0;
                        commands.forEach(cmd => {
                            const type = cmd[0];
                            const args = cmd.slice(1).trim().split(/[\s,]+/).map(parseFloat);
                            
                            if (type === 'M' || type === 'L') {
                                currentX = args[0];
                                currentY = args[1];
                                points.push({ x: currentX, y: currentY });
                            } else if (type === 'm' || type === 'l') {
                                currentX += args[0];
                                currentY += args[1];
                                points.push({ x: currentX, y: currentY });
                            }
                        });
                        return points;
                    }
                    
                    // ê° ì‹œë¦¬ì¦ˆì˜ path ë°ì´í„° ì¶”ì¶œ
                    seriesPaths.forEach((path, index) => {
                        const d = path.getAttribute('d');
                        if (d) {
                            const points = parsePathData(d);
                            result.debug_info[`series_${index}_points`] = points.length;
                            
                            // SVG ì¢Œí‘œë¥¼ ì‹¤ì œ ê°’ìœ¼ë¡œ ë³€í™˜í•˜ê¸° ìœ„í•´ Yì¶• ë²”ìœ„ í•„ìš”
                            // ì¼ë‹¨ ì›ì‹œ ì¢Œí‘œë§Œ ì €ì¥
                            if (index === 0) {
                                result.debug_info.series_0_sample = points.slice(0, 5);
                            }
                        }
                    });
                    
                    // Highcharts ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ì‹¤ì œ ë°ì´í„° í¬ì¸íŠ¸ ìˆ˜ í™•ì¸
                    if (typeof Highcharts !== 'undefined' && Highcharts.charts) {
                        for (let chart of Highcharts.charts) {
                            if (chart && chart.container && chart.container.id === 'lineAreaZone') {
                                if (chart.series) {
                                    chart.series.forEach((series, idx) => {
                                        if (series.points) {
                                            result.debug_info[`highcharts_series_${idx}_points`] = series.points.length;
                                            
                                            // ëª¨ë“  í¬ì¸íŠ¸ì˜ ë‚ ì§œì™€ ê°’ ì¶”ì¶œ
                                            if (series.visible && series.points.length > 0) {
                                                const values = [];
                                                const dates = [];
                                                
                                                series.points.forEach(point => {
                                                    if (point.y !== undefined && point.y !== null) {
                                                        values.push(point.y);
                                                        // xê°’ì´ë‚˜ categoryì—ì„œ ë‚ ì§œ ì¶”ì¶œ
                                                        if (point.category) {
                                                            dates.push(point.category);
                                                        } else if (point.x !== undefined) {
                                                            dates.push(point.x);
                                                        }
                                                    }
                                                });
                                                
                                                if (idx === 0) {
                                                    result.setup_amounts = values;
                                                    if (dates.length > result.dates.length) {
                                                        result.dates = dates;
                                                    }
                                                } else if (idx === 1) {
                                                    result.returns = values;
                                                }
                                                
                                                result.debug_info[`extracted_from_series_${idx}`] = values.length;
                                            }
                                        }
                                    });
                                }
                                break;
                            }
                        }
                    }
                    
                    return result;
                }
            ''')
            
            if svg_data:
                print(f"ğŸ“Š SVG path analysis result:")
                print(f"   Dates: {len(svg_data.get('dates', []))} items")
                print(f"   Setup amounts: {len(svg_data.get('setup_amounts', []))} items")
                print(f"   Returns: {len(svg_data.get('returns', []))} items")
                
                if svg_data.get('debug_info'):
                    print(f"   Debug Info: {json.dumps(svg_data['debug_info'], indent=2)}")
                
                return svg_data
                
        except Exception as e:
            print(f"âŒ SVG path extraction failed: {e}")
            import traceback
            traceback.print_exc()
        
        return None
    
    async def parse_top_funds(self, page):
        """Top í€ë“œ ë°ì´í„° íŒŒì‹±"""
        top_funds_data = []
        
        # ìˆ˜ìµë¥  TOP 5
        return_funds = await page.query_selector_all('#topFundZone td:nth-child(1) li')
        return_rates = await page.query_selector_all('#topFundZone td:nth-child(2) li')
        
        for i in range(len(return_funds)):
            fund_elem = return_funds[i]
            rate_elem = return_rates[i] if i < len(return_rates) else None
            
            rank = await fund_elem.query_selector('i')
            rank_text = await rank.inner_text() if rank else ''
            
            fund_link = await fund_elem.query_selector('a')
            if fund_link:
                fund_name = await fund_link.inner_text()
                fund_code = await fund_link.get_attribute('data-fund_cd')
                rate_text = await rate_elem.inner_text() if rate_elem else ''
                
                top_funds_data.append({
                    'rank': rank_text,
                    'fund_name': fund_name.strip(),
                    'fund_code': fund_code or '',
                    'value': rate_text.strip(),
                    'type': 'ìˆ˜ìµë¥ '
                })
        
        # ì„¤ì •ì•¡ì¦ê°€ TOP 5
        growth_funds = await page.query_selector_all('#topFundZone td:nth-child(3) li')
        growth_amounts = await page.query_selector_all('#topFundZone td:nth-child(4) li')
        
        for i in range(len(growth_funds)):
            fund_elem = growth_funds[i]
            amount_elem = growth_amounts[i] if i < len(growth_amounts) else None
            
            rank = await fund_elem.query_selector('i')
            rank_text = await rank.inner_text() if rank else ''
            
            fund_link = await fund_elem.query_selector('a')
            if fund_link:
                fund_name = await fund_link.inner_text()
                fund_code = await fund_link.get_attribute('data-fund_cd')
                amount_text = await amount_elem.inner_text() if amount_elem else ''
                
                top_funds_data.append({
                    'rank': rank_text,
                    'fund_name': fund_name.strip(),
                    'fund_code': fund_code or '',
                    'value': amount_text.strip(),
                    'type': 'ì„¤ì •ì•¡ì¦ê°€'
                })
        
        return top_funds_data
    
    async def parse_new_funds(self, page):
        """ì‹ ê·œ í€ë“œ ë°ì´í„° íŒŒì‹±"""
        new_funds_data = []
        
        try:
            # ì‹ ê·œ í€ë“œê°€ ì—†ëŠ”ì§€ í™•ì¸
            no_data = await page.query_selector('#newFundZone .nodata')
            if no_data:
                print("   â„¹ï¸ No new funds found")
                return new_funds_data
            
            # ì‹ ê·œ í€ë“œ í…Œì´ë¸” ì°¾ê¸°
            # í…Œì´ë¸” êµ¬ì¡°ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì—¬ëŸ¬ ë°©ë²• ì‹œë„
            
            # ë°©ë²• 1: tr íƒœê·¸ ì§ì ‘ ì°¾ê¸°
            rows = await page.query_selector_all('#newFundZone tr')
            
            # ë°©ë²• 2: tbody ì•ˆì˜ tr ì°¾ê¸°
            if not rows:
                rows = await page.query_selector_all('#newFundZone tbody tr')
            
            # ë°©ë²• 3: table ì•ˆì˜ ëª¨ë“  tr ì°¾ê¸°
            if not rows:
                rows = await page.query_selector_all('#newFundZone table tr')
            
            print(f"   ğŸ“ Found {len(rows)} rows in new funds zone")
            
            for i, row in enumerate(rows):
                # í—¤ë” í–‰ ê±´ë„ˆë›°ê¸°
                if i == 0:
                    header_text = await row.inner_text()
                    if 'í€ë“œëª…' in header_text or 'ìš´ìš©ì‚¬' in header_text:
                        continue
                
                cols = await row.query_selector_all('td')
                if len(cols) >= 3:
                    fund_name = await cols[0].inner_text()
                    company = await cols[1].inner_text()
                    setup_date = await cols[2].inner_text()
                    
                    # ë¹ˆ ë°ì´í„° ê±´ë„ˆë›°ê¸°
                    if fund_name.strip() and company.strip():
                        new_funds_data.append({
                            'fund_name': fund_name.strip(),
                            'company': company.strip(),
                            'setup_date': setup_date.strip()
                        })
                        print(f"      - New fund: {fund_name.strip()}")
                elif len(cols) > 0:
                    # ì»¬ëŸ¼ ìˆ˜ê°€ ë‹¤ë¥¸ ê²½ìš° ë””ë²„ê¹…
                    print(f"      âš ï¸ Row {i} has {len(cols)} columns")
            
            print(f"   âœ… Parsed {len(new_funds_data)} new funds")
            
        except Exception as e:
            print(f"   âŒ Error parsing new funds: {e}")
            import traceback
            traceback.print_exc()
        
        return new_funds_data
    
    async def wait_for_chart_data_complete(self, page, expected_period):
        """ì°¨íŠ¸ ë°ì´í„°ê°€ ì™„ì „íˆ ë¡œë“œë  ë•Œê¹Œì§€ ëŒ€ê¸° (AJAX ëŒ€ì‘)"""
        print(f"â³ Waiting for chart data to load completely for {expected_period}...")
        
        # ì˜ˆìƒ ë°ì´í„° í¬ì¸íŠ¸ ìˆ˜ ê³„ì‚° (ëŒ€ëµì )
        expected_points = {
            '01': 20,      # 1ê°œì›”: ì•½ 20ì˜ì—…ì¼
            '03': 60,      # 3ê°œì›”: ì•½ 60ì˜ì—…ì¼
            '06': 120,     # 6ê°œì›”: ì•½ 120ì˜ì—…ì¼
            'YTD': 150,    # ì—°ì´ˆì´í›„: ê°€ë³€ì 
            '12': 250,     # 1ë…„: ì•½ 250ì˜ì—…ì¼
            '36': 750,     # 3ë…„: ì•½ 750ì˜ì—…ì¼
            '60': 1250     # 5ë…„: ì•½ 1250ì˜ì—…ì¼
        }
        
        min_expected = expected_points.get(expected_period, 20)
        max_wait_time = 30  # ìµœëŒ€ 30ì´ˆ ëŒ€ê¸°
        check_interval = 0.5  # 0.5ì´ˆë§ˆë‹¤ í™•ì¸
        
        # tqdm ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        try:
            pbar = tqdm(total=100, desc="Loading chart data", unit="%")
            use_tqdm = True
        except:
            print("â„¹ï¸ Progress bar not available, using simple logging")
            use_tqdm = False
            pbar = None
        
        try:
            start_time = time.time()
            previous_count = 0
            stable_count = 0
            
            while (time.time() - start_time) < max_wait_time:
                # í˜„ì¬ ë°ì´í„° í¬ì¸íŠ¸ ìˆ˜ í™•ì¸
                data_info = await page.evaluate('''
                    () => {
                        let maxPoints = 0;
                        let loadingStatus = 'checking';
                        
                        if (typeof Highcharts !== 'undefined' && Highcharts.charts) {
                            for (let chart of Highcharts.charts) {
                                if (chart && chart.container && chart.container.id === 'lineAreaZone') {
                                    if (chart.series) {
                                        chart.series.forEach(series => {
                                            if (series.visible) {
                                                // ì—¬ëŸ¬ ë°ì´í„° ì†ŒìŠ¤ í™•ì¸
                                                const counts = [
                                                    series.processedYData ? series.processedYData.length : 0,
                                                    series.points ? series.points.length : 0,
                                                    series.data ? series.data.length : 0
                                                ];
                                                maxPoints = Math.max(maxPoints, ...counts);
                                            }
                                        });
                                    }
                                    
                                    // ë¡œë”© ìƒíƒœ í™•ì¸
                                    if (chart.showLoading) {
                                        loadingStatus = 'loading';
                                    } else {
                                        loadingStatus = 'complete';
                                    }
                                    break;
                                }
                            }
                        }
                        
                        // AJAX ë¡œë”© ì¸ë””ì¼€ì´í„° í™•ì¸
                        const loadingIndicators = document.querySelectorAll('.loading, .spinner, .loader');
                        if (loadingIndicators.length > 0) {
                            loadingStatus = 'loading';
                        }
                        
                        return {
                            points: maxPoints,
                            status: loadingStatus
                        };
                    }
                ''')
                
                current_count = data_info['points']
                loading_status = data_info['status']
                
                # ì§„í–‰ë¥  ê³„ì‚°
                progress = min(100, (current_count / min_expected) * 100)
                
                if use_tqdm and pbar:
                    pbar.n = int(progress)
                    pbar.refresh()
                
                # ë¡œê·¸ ì¶œë ¥
                if current_count != previous_count:
                    if not use_tqdm:
                        print(f"ğŸ“Š Current data points: {current_count} (target: >{min_expected})")
                    stable_count = 0
                else:
                    stable_count += 1
                
                # ë°ì´í„°ê°€ ì¶©ë¶„íˆ ë¡œë“œë˜ì—ˆê³  ì•ˆì •ì ì¸ ê²½ìš°
                if current_count >= min_expected and stable_count > 3:
                    print(f"\nâœ… Data loading complete: {current_count} points")
                    break
                
                # ë¡œë”©ì´ ì™„ë£Œë˜ì—ˆê³  ë°ì´í„°ê°€ ì•ˆì •ì ì¸ ê²½ìš°
                if loading_status == 'complete' and stable_count > 5:
                    print(f"\nâœ… Loading complete with {current_count} points")
                    break
                
                previous_count = current_count
                await page.wait_for_timeout(int(check_interval * 1000))
                
            # ìµœì¢… ëŒ€ê¸°
            if use_tqdm and pbar:
                pbar.n = 100
                pbar.refresh()
                pbar.close()
            
            # ë„¤íŠ¸ì›Œí¬ ì•ˆì •í™”ë¥¼ ìœ„í•œ ì¶”ê°€ ëŒ€ê¸°
            await page.wait_for_timeout(1000)
            
            # ìµœì¢… ë°ì´í„° ìˆ˜ í™•ì¸
            final_info = await page.evaluate('''
                () => {
                    let result = { points: 0, series_info: [] };
                    
                    if (typeof Highcharts !== 'undefined' && Highcharts.charts) {
                        for (let chart of Highcharts.charts) {
                            if (chart && chart.container && chart.container.id === 'lineAreaZone') {
                                if (chart.series) {
                                    chart.series.forEach((series, idx) => {
                                        if (series.visible) {
                                            const info = {
                                                name: series.name || `Series ${idx}`,
                                                data: series.data ? series.data.length : 0,
                                                points: series.points ? series.points.length : 0,
                                                processedY: series.processedYData ? series.processedYData.length : 0
                                            };
                                            result.series_info.push(info);
                                            result.points = Math.max(result.points, info.processedY, info.points, info.data);
                                        }
                                    });
                                }
                                break;
                            }
                        }
                    }
                    return result;
                }
            ''')
            
            print(f"\nğŸ“Š Final data status:")
            print(f"   Total points: {final_info['points']}")
            for series in final_info.get('series_info', []):
                print(f"   - {series['name']}: data={series['data']}, points={series['points']}, processed={series['processedY']}")
                
        except Exception as e:
            print(f"\nâŒ Error waiting for data: {e}")
            if pbar:
                pbar.close()
            
    async def fetch_tab_data(self, page, tab_value, tab_name):
        """íŠ¹ì • íƒ­ì˜ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (AJAX ë¡œë”© ëŒ€ì‘)"""
        print(f"\nğŸ” Fetching data for {tab_name}...")
        
        # íƒ­ í´ë¦­
        await page.click(f'button[value="{tab_value}"]')
        await page.wait_for_timeout(2000)  # ì´ˆê¸° ë¡œë”© ëŒ€ê¸°
        
        # ê¸°ê°„ ì„ íƒ (ë“œë¡­ë‹¤ìš´ì—ì„œ ì„ íƒ)
        try:
            # ë“œë¡­ë‹¤ìš´ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            select_exists = await page.query_selector('#selTerm')
            if not select_exists:
                print("âš ï¸ Period selector not found, using default period")
            else:
                # í˜„ì¬ ì„ íƒëœ ê¸°ê°„ í™•ì¸
                current_period = await page.evaluate('''
                    () => {
                        const select = document.querySelector('#selTerm');
                        return select ? select.value : null;
                    }
                ''')
                print(f"ğŸ“… Current period value: {current_period}")
                
                # ì›í•˜ëŠ” ê¸°ê°„ ì„ íƒ
                if self.collection_period != '01' and current_period != self.collection_period:
                    print(f"ğŸ“… Changing period to: {self.period_text_map.get(self.collection_period)} ({self.collection_period})")
                    
                    # JavaScriptë¡œ ì§ì ‘ ì„ íƒ (ë” ì•ˆì •ì )
                    success = await page.evaluate('''
                        (targetValue) => {
                            const select = document.querySelector('#selTerm');
                            if (!select) return false;
                            
                            // ì˜µì…˜ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
                            const option = Array.from(select.options).find(opt => opt.value === targetValue);
                            if (!option) {
                                console.error('Option not found:', targetValue);
                                return false;
                            }
                            
                            // ê°’ ì„¤ì •
                            select.value = targetValue;
                            
                            // change ì´ë²¤íŠ¸ íŠ¸ë¦¬ê±°
                            const event = new Event('change', { bubbles: true });
                            select.dispatchEvent(event);
                            
                            // jQueryê°€ ìˆë‹¤ë©´ jQuery ì´ë²¤íŠ¸ë„ íŠ¸ë¦¬ê±°
                            if (typeof $ !== 'undefined' && $(select).length) {
                                $(select).trigger('change');
                            }
                            
                            return true;
                        }
                    ''', self.collection_period)
                    
                    if not success:
                        print(f"âš ï¸ Failed to select period via JavaScript, trying alternative method")
                        # ëŒ€ì²´ ë°©ë²•: select_option ì‚¬ìš© (íƒ€ì„ì•„ì›ƒ ì§§ê²Œ)
                        try:
                            await page.select_option('#selTerm', self.collection_period, timeout=5000)
                        except Exception as e:
                            print(f"âš ï¸ Alternative selection also failed: {e}")
                    
                    # ì„ íƒ í›„ ëŒ€ê¸°
                    await page.wait_for_timeout(1000)
                    
                    # ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ì™„ë£Œ ëŒ€ê¸°
                    try:
                        await page.wait_for_load_state('networkidle', timeout=10000)
                    except:
                        pass  # íƒ€ì„ì•„ì›ƒ ë¬´ì‹œ
                    
                    # ì°¨íŠ¸ ë°ì´í„° ì™„ì „ ë¡œë“œ ëŒ€ê¸°
                    await self.wait_for_chart_data_complete(page, self.collection_period)
                    
                    # ë³€ê²½ í™•ì¸
                    new_period = await page.evaluate('''
                        () => {
                            const select = document.querySelector('#selTerm');
                            if (select) {
                                const selectedOption = select.options[select.selectedIndex];
                                return {
                                    value: select.value,
                                    text: selectedOption ? selectedOption.text : null
                                };
                            }
                            return null;
                        }
                    ''')
                    
                    if new_period:
                        print(f"âœ… Period changed to: {new_period['text']} (value: {new_period['value']})")
                    
        except Exception as e:
            print(f"âš ï¸ Error in period selection: {e}")
            import traceback
            traceback.print_exc()
            print("âš ï¸ Continuing with default period...")
        
        # ë°ì´í„° ì¶”ì¶œ
        data = {
            'tab_name': tab_name,
            'collection_period': self.collection_period,
            'period_text': self.period_text_map.get(self.collection_period, self.collection_period),
            'top_funds': await self.parse_top_funds(page),
            'new_funds': await self.parse_new_funds(page),
            'chart_data': await self.extract_chart_data(page, tab_name)
        }
        
        return data
    
    async def scrape_all_tabs(self):
        """ëª¨ë“  íƒ­ì˜ ë°ì´í„° ìˆ˜ì§‘"""
        all_data = {}
        
        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=True)
            
            # í˜ì´ì§€ ì„¤ì • ê°œì„  (AJAX ëŒ€ì‘)
            context = await browser.new_context(
                viewport={'width': 1920, 'height': 1080},
                user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            )
            page = await context.new_page()
            
            # ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ë””ë²„ê¹… í™œì„±í™”
            if os.environ.get('DEBUG_NETWORK', 'false').lower() == 'true':
                page.on('request', lambda request: print(f"ğŸ“¡ Request: {request.url[:80]}..."))
                page.on('response', lambda response: print(f"ğŸ“¥ Response: {response.status} {response.url[:80]}..."))
            
            try:
                # í˜ì´ì§€ ë¡œë“œ
                print("ğŸ“‚ Loading ESG fund page...")
                await page.goto(self.base_url, wait_until='networkidle')
                await page.wait_for_timeout(3000)
                
                # JavaScript ì—ëŸ¬ í™•ì¸
                await page.evaluate('''
                    () => {
                        window.addEventListener('error', (e) => {
                            console.error('JS Error:', e.message);
                        });
                    }
                ''')
                
                # ê° íƒ­ ë°ì´í„° ìˆ˜ì§‘
                tabs = [
                    ('T0370', 'SRI'),
                    ('T0371', 'ESG_ì£¼ì‹'),
                    ('T0373', 'ESG_ì±„ê¶Œ')
                ]
                
                # ì „ì²´ ì§„í–‰ ìƒí™© í‘œì‹œ
                print(f"\nğŸ“Š Collecting data for {len(tabs)} tabs...")
                for i, (tab_value, tab_name) in enumerate(tabs, 1):
                    print(f"\n{'='*50}")
                    print(f"Tab {i}/{len(tabs)}: {tab_name}")
                    print(f"{'='*50}")
                    
                    data = await self.fetch_tab_data(page, tab_value, tab_name)
                    all_data[tab_name] = data
                    
                    # íƒ­ ê°„ ëŒ€ê¸° (ì„œë²„ ë¶€í•˜ ë°©ì§€)
                    if i < len(tabs):
                        await page.wait_for_timeout(2000)
                
            except Exception as e:
                print(f"âŒ Error during scraping: {e}")
                await self.send_telegram_message(f"âŒ ESG í€ë“œ ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                raise
            finally:
                await context.close()
                await browser.close()
        
        return all_data
    
    def to_dataframes(self, all_data):
        """ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜ (í†µí•©ëœ í˜•íƒœ)"""
        dfs = {}
        collection_date = datetime.now().strftime('%Y-%m-%d')
        collection_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        # 1. TOP5 í€ë“œ ë°ì´í„° (ëª¨ë“  íƒ­ í†µí•©)
        all_top_funds = []
        for tab_name, tab_data in all_data.items():
            for fund in tab_data['top_funds']:
                fund['tab_type'] = tab_name
                fund['collection_date'] = collection_date
                fund['collection_time'] = collection_time
                all_top_funds.append(fund)
        
        if all_top_funds:
            dfs['top_funds'] = pd.DataFrame(all_top_funds)
            print(f"âœ… Created unified TOP5 dataframe with {len(all_top_funds)} rows")
        
        # 2. ì‹ ê·œ í€ë“œ ë°ì´í„° (ëª¨ë“  íƒ­ í†µí•©)
        all_new_funds = []
        for tab_name, tab_data in all_data.items():
            for fund in tab_data['new_funds']:
                fund['tab_type'] = tab_name
                fund['collection_date'] = collection_date
                fund['collection_time'] = collection_time
                all_new_funds.append(fund)
        
        if all_new_funds:
            dfs['new_funds'] = pd.DataFrame(all_new_funds)
            print(f"âœ… Created unified new funds dataframe with {len(all_new_funds)} rows")
        
        # 3. ì¼ë³„ ì°¨íŠ¸ ë°ì´í„° (ëª¨ë“  íƒ­ í†µí•©) - ìˆ˜ì •ëœ ë¶€ë¶„
        all_chart_data = []
        for tab_name, tab_data in all_data.items():
            chart_data_wrapper = tab_data.get('chart_data', {})
            
            # primary_dataë¥¼ ì‚¬ìš© (JavaScript ë°ì´í„° ìš°ì„ , ì—†ìœ¼ë©´ OCR ë°ì´í„°)
            chart_data = chart_data_wrapper.get('primary_data', {})
            
            # primary_dataê°€ ì—†ìœ¼ë©´ js_data ì§ì ‘ í™•ì¸
            if not chart_data or not chart_data.get('dates'):
                chart_data = chart_data_wrapper.get('js_data', {})
            
            if chart_data and chart_data.get('dates'):
                dates = chart_data['dates']
                setup_amounts = chart_data.get('setup_amounts', [])
                returns = chart_data.get('returns', [])
                
                print(f"   ğŸ“Š Processing {tab_name} chart data:")
                print(f"      - Dates: {len(dates)}")
                print(f"      - Setup amounts: {len(setup_amounts)}")
                print(f"      - Returns: {len(returns)}")
                
                # ë°ì´í„° ê¸¸ì´ ë§ì¶”ê¸° - ê°€ì¥ ì§§ì€ ê¸¸ì´ë¡œ
                min_length = len(dates)
                if setup_amounts:
                    min_length = min(min_length, len(setup_amounts))
                if returns:
                    min_length = min(min_length, len(returns))
                
                print(f"      - Using {min_length} data points")
                
                for i in range(min_length):
                    # ìˆ«ì ë°ì´í„° ë³€í™˜ í•¨ìˆ˜
                    def to_numeric(value):
                        if value is None or value == '':
                            return None
                        try:
                            # ë¬¸ìì—´ì¸ ê²½ìš° ìˆ«ìë¡œ ë³€í™˜
                            if isinstance(value, str):
                                # ì‰¼í‘œ ì œê±°
                                value = value.replace(',', '')
                                # ì•ë’¤ ë”°ì˜´í‘œ ì œê±°
                                value = value.strip("'\"")
                            return float(value)
                        except (ValueError, TypeError):
                            return None
                    
                    all_chart_data.append({
                        'date': dates[i],
                        'setup_amount': to_numeric(setup_amounts[i]) if i < len(setup_amounts) and setup_amounts else None,
                        'return_rate': to_numeric(returns[i]) if i < len(returns) and returns else None,
                        'tab_type': tab_name,
                        'collection_date': collection_date,
                        'collection_time': collection_time,
                        'collection_period': self.collection_period,
                        'period_text': self.period_text_map.get(self.collection_period)
                    })
            else:
                print(f"   âš ï¸ No chart data found for {tab_name}")
        
        if all_chart_data:
            dfs['daily_chart'] = pd.DataFrame(all_chart_data)
            print(f"âœ… Created unified chart dataframe with {len(all_chart_data)} rows")
            
            # ë°ì´í„° ìƒ˜í”Œ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
            sample_df = dfs['daily_chart'].head(3)
            print(f"   Sample data:")
            print(f"   {sample_df[['date', 'setup_amount', 'return_rate', 'tab_type']].to_string()}")
        
        # 4. ì°¨íŠ¸ ë¹„êµ ê²€ì¦ ë°ì´í„° (JavaScript vs OCR) - ìƒˆë¡œ ì¶”ê°€
        all_comparison_data = []
        for tab_name, tab_data in all_data.items():
            chart_data_wrapper = tab_data.get('chart_data', {})
            js_data = chart_data_wrapper.get('js_data', {})
            ocr_data = chart_data_wrapper.get('ocr_data', {})
            
            # JavaScript ë°ì´í„°
            if js_data and js_data.get('dates'):
                for i, date in enumerate(js_data['dates']):
                    all_comparison_data.append({
                        'date': date,
                        'setup_amount': js_data['setup_amounts'][i] if i < len(js_data.get('setup_amounts', [])) else None,
                        'return_rate': js_data['returns'][i] if i < len(js_data.get('returns', [])) else None,
                        'tab_type': tab_name,
                        'method': 'JavaScript',
                        'collection_time': collection_time
                    })
            
            # OCR ë°ì´í„° (í˜„ì¬ëŠ” ë¹„ì–´ìˆì„ ê²ƒì„)
            if ocr_data and ocr_data.get('dates'):
                for i, date in enumerate(ocr_data['dates']):
                    all_comparison_data.append({
                        'date': date,
                        'setup_amount': ocr_data['setup_amounts'][i] if i < len(ocr_data.get('setup_amounts', [])) else None,
                        'return_rate': ocr_data['returns'][i] if i < len(ocr_data.get('returns', [])) else None,
                        'tab_type': tab_name,
                        'method': 'OCR',
                        'collection_time': collection_time
                    })
        
        if all_comparison_data:
            dfs['chart_comparison'] = pd.DataFrame(all_comparison_data)
            print(f"âœ… Created chart comparison dataframe with {len(all_comparison_data)} rows")
        
        return dfs
    
    def save_to_sheets(self, dfs):
        """Google Sheetsì— ë°ì´í„° ì €ì¥ (í†µí•©ëœ ì‹œíŠ¸)"""
        # ì„œë¹„ìŠ¤ ê³„ì • ì¸ì¦
        scope = ['https://spreadsheets.google.com/feeds',
                 'https://www.googleapis.com/auth/drive']
        
        creds_json = os.environ.get('GOOGLE_SERVICE')
        if not creds_json:
            print("âŒ No Google Sheets credentials found")
            return []
        
        try:
            creds_dict = json.loads(creds_json)
            service_account_email = creds_dict.get('client_email', 'Unknown')
            print(f"ğŸ“§ Using service account: {service_account_email}")
            
            creds = Credentials.from_service_account_info(creds_dict, scopes=scope)
            client = gspread.authorize(creds)
            
            sheet_id = os.environ.get('KRFUND_SPREADSHEET_ID')
            if not sheet_id:
                print("âŒ No Google Sheet ID found")
                return []
                
            spreadsheet = client.open_by_key(sheet_id)
            
            # ì‹œíŠ¸ ì´ë¦„ ë§¤í•‘
            sheet_mapping = {
                'top_funds': 'ESG_TOP5í€ë“œ',
                'new_funds': 'ESG_ì‹ ê·œí€ë“œ',
                'daily_chart': 'ESG_ì¼ë³„ì°¨íŠ¸',
                'chart_comparison': 'ESG_ì°¨íŠ¸ë¹„êµê²€ì¦'
            }
            
            updated_sheets = []
            
            for df_key, df in dfs.items():
                sheet_name = sheet_mapping.get(df_key, df_key)
                print(f"\nğŸ“‹ Processing {sheet_name} (df_key: {df_key})...")
                
                try:
                    # ì‹œíŠ¸ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±
                    try:
                        worksheet = spreadsheet.worksheet(sheet_name)
                        print(f"   âœ… Found existing sheet: {sheet_name}")
                    except:
                        print(f"   ğŸ“ Creating new sheet: {sheet_name}")
                        worksheet = spreadsheet.add_worksheet(title=sheet_name, rows=5000, cols=20)
                    
                    if df_key == 'daily_chart':
                        # ì¼ë³„ ì°¨íŠ¸ - ê¸°ì¡´ ë°ì´í„° ë³´ì¡´í•˜ë©´ì„œ ìƒˆ ë°ì´í„°ë§Œ ì¶”ê°€
                        try:
                            existing_data = worksheet.get_all_records()
                            print(f"   ğŸ“Š Existing data in daily chart: {len(existing_data)} rows")
                        except Exception as e:
                            print(f"   âš ï¸ Error reading existing data: {e}")
                            existing_data = []
                        
                        if existing_data:
                            existing_df = pd.DataFrame(existing_data)
                            
                            # ê¸°ì¡´ ë°ì´í„°ì— ì—†ëŠ” ìƒˆ ë°ì´í„°ë§Œ í•„í„°ë§
                            merge_keys = ['date', 'tab_type', 'collection_period']
                            
                            # ë¹„êµë¥¼ ìœ„í•œ í‚¤ ìƒì„±
                            existing_keys = set()
                            for _, row in existing_df.iterrows():
                                key = '|'.join([str(row.get(k, '')) for k in merge_keys])
                                existing_keys.add(key)
                            
                            new_rows_list = []
                            for _, row in df.iterrows():
                                key = '|'.join([str(row.get(k, '')) for k in merge_keys])
                                if key not in existing_keys:
                                    new_rows_list.append(row.to_dict())
                            
                            if new_rows_list:
                                new_rows = pd.DataFrame(new_rows_list)
                                print(f"   ğŸ“ Found {len(new_rows)} new rows to add")
                                
                                # ì°¨íŠ¸ ì°¸ì¡° ë³´ì¡´ ëª¨ë“œ í™•ì¸
                                preserve_refs = os.environ.get('PRESERVE_CHART_REFS', 'true').lower() == 'true'
                                
                                if preserve_refs:
                                    # ìƒˆ ë°ì´í„°ë¥¼ ëì— ì¶”ê°€ (ì°¨íŠ¸ ì°¸ì¡° ì•ˆì „)
                                    # ìƒˆ ë°ì´í„°ë¥¼ ë‚ ì§œ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬
                                    new_rows = new_rows.sort_values(
                                        by=['date', 'tab_type'], 
                                        ascending=[False, True]
                                    )
                                    
                                    # ìƒˆ í–‰ ì¶”ê°€ - ìˆ«ì í˜•ì‹ ë³´ì¡´
                                    new_values = []
                                    for _, row in new_rows.iterrows():
                                        row_values = []
                                        for col in existing_df.columns:
                                            value = row.get(col, '')
                                            # setup_amountì™€ return_rateëŠ” ìˆ«ìë¡œ ìœ ì§€
                                            if col in ['setup_amount', 'return_rate'] and value != '':
                                                row_values.append(value)  # ìˆ«ì ê·¸ëŒ€ë¡œ
                                            else:
                                                row_values.append(str(value))  # ë‚˜ë¨¸ì§€ëŠ” ë¬¸ìì—´
                                        new_values.append(row_values)
                                    
                                    if new_values:
                                        # USER_ENTEREDë¡œ ë³€ê²½í•˜ì—¬ Google Sheetsê°€ íƒ€ì…ì„ ìë™ ì¸ì‹
                                        worksheet.append_rows(new_values, value_input_option='USER_ENTERED')
                                        print(f"   âœ… Appended {len(new_rows)} new rows (preserving chart references)")
                                        print(f"   â„¹ï¸ Total rows now: {len(existing_data) + len(new_rows)}")
                                else:
                                    # ì „ì²´ ì¬ì •ë ¬ ëª¨ë“œ
                                    print(f"   ğŸ”„ Re-sorting entire dataset")
                                    combined_df = pd.concat([existing_df, new_rows], ignore_index=True)
                                    combined_df = combined_df.sort_values(
                                        by=['date', 'tab_type'], 
                                        ascending=[False, True]
                                    )
                                    
                                    # ì „ì²´ ë°ì´í„° ë‹¤ì‹œ ì“°ê¸° - ìˆ«ì í˜•ì‹ ë³´ì¡´
                                    worksheet.clear()
                                    
                                    # í—¤ë”
                                    headers = combined_df.columns.values.tolist()
                                    
                                    # ë°ì´í„° - ìˆ«ì ì»¬ëŸ¼ì€ ìˆ«ìë¡œ ìœ ì§€
                                    values = [headers]
                                    for _, row in combined_df.iterrows():
                                        row_values = []
                                        for col in combined_df.columns:
                                            value = row[col]
                                            # NaN ì²˜ë¦¬
                                            if pd.isna(value):
                                                row_values.append('')
                                            # setup_amountì™€ return_rateëŠ” ìˆ«ìë¡œ
                                            elif col in ['setup_amount', 'return_rate']:
                                                row_values.append(value)  # ìˆ«ì ê·¸ëŒ€ë¡œ
                                            else:
                                                row_values.append(str(value))
                                        values.append(row_values)
                                    
                                    worksheet.update(values, value_input_option='USER_ENTERED')
                                    print(f"   âœ… Daily chart updated with {len(combined_df)} total rows")
                            else:
                                print(f"   â„¹ï¸ No new data to add")
                        else:
                            # ì²« ë°ì´í„°ì¸ ê²½ìš°
                            print(f"   ğŸ“ First time data - creating new sheet content")
                            combined_df = df
                            combined_df = combined_df.sort_values(
                                by=['date', 'tab_type'], 
                                ascending=[False, True]
                            )
                            
                            # í—¤ë”
                            headers = combined_df.columns.values.tolist()
                            
                            # ë°ì´í„° - ìˆ«ì ì»¬ëŸ¼ì€ ìˆ«ìë¡œ ìœ ì§€
                            values = [headers]
                            for _, row in combined_df.iterrows():
                                row_values = []
                                for col in combined_df.columns:
                                    value = row[col]
                                    # NaN ì²˜ë¦¬
                                    if pd.isna(value):
                                        row_values.append('')
                                    # setup_amountì™€ return_rateëŠ” ìˆ«ìë¡œ
                                    elif col in ['setup_amount', 'return_rate']:
                                        row_values.append(value)  # ìˆ«ì ê·¸ëŒ€ë¡œ
                                    else:
                                        row_values.append(str(value))
                                values.append(row_values)
                            
                            worksheet.update(values, value_input_option='USER_ENTERED')
                            print(f"   âœ… Created daily chart with {len(combined_df)} rows")
                            
                    elif df_key == 'chart_comparison':
                        # ë¹„êµ ê²€ì¦ ë°ì´í„°ëŠ” ë§¤ë²ˆ ìƒˆë¡œ ì“°ê¸°
                        print(f"   ğŸ”„ Updating chart comparison data")
                        combined_df = df
                        combined_df = combined_df.sort_values(
                            by=['date', 'tab_type', 'method'], 
                            ascending=[False, True, True]
                        )
                        
                        # ì‹œíŠ¸ ì—…ë°ì´íŠ¸
                        worksheet.clear()
                        combined_df = combined_df.fillna('')
                        values = [combined_df.columns.values.tolist()] + combined_df.values.tolist()
                        
                        for i in range(len(values)):
                            for j in range(len(values[i])):
                                values[i][j] = str(values[i][j])
                        
                        worksheet.update(values)
                        print(f"   âœ… Chart comparison updated with {len(combined_df)} rows")
                        
                    else:
                        # TOP5ì™€ ì‹ ê·œí€ë“œëŠ” ê¸°ì¡´ ë¡œì§ ìœ ì§€
                        print(f"   ğŸ“Š Processing {df_key} data...")
                        existing_data = worksheet.get_all_records()
                        
                        if existing_data:
                            existing_df = pd.DataFrame(existing_data)
                            # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•œ í‚¤ ì„¤ì •
                            if df_key == 'top_funds':
                                key_cols = ['collection_date', 'tab_type', 'type', 'rank']
                            elif df_key == 'new_funds':
                                key_cols = ['collection_date', 'tab_type', 'fund_name']
                            else:
                                key_cols = list(df.columns)  # ê¸°ë³¸ê°’
                            
                            # ì¤‘ë³µ ì œê±° í›„ ê²°í•©
                            combined_df = pd.concat([df, existing_df], ignore_index=True)
                            combined_df = combined_df.drop_duplicates(subset=key_cols, keep='first')
                            # ìµœì‹  ë°ì´í„°ê°€ ìœ„ë¡œ ì˜¤ë„ë¡ ì •ë ¬
                            combined_df = combined_df.sort_values(
                                by=['collection_date', 'tab_type'], 
                                ascending=[False, True]
                            )
                            print(f"   ğŸ“Š Combined data: {len(df)} new + {len(existing_df)} existing = {len(combined_df)} total")
                        else:
                            combined_df = df
                            print(f"   ğŸ“ First time data: {len(combined_df)} rows")
                        
                        # ë°ì´í„° ì“°ê¸°
                        worksheet.clear()
                        combined_df = combined_df.fillna('')
                        values = [combined_df.columns.values.tolist()] + combined_df.values.tolist()
                        
                        for i in range(len(values)):
                            for j in range(len(values[i])):
                                values[i][j] = str(values[i][j])
                        
                        worksheet.update(values)
                        print(f"   âœ… {sheet_name} updated successfully")
                    
                    updated_sheets.append(sheet_name)
                    
                except Exception as e:
                    print(f"âŒ Error updating {sheet_name}: {e}")
                    import traceback
                    traceback.print_exc()
                    
            return updated_sheets
            
        except Exception as e:
            print(f"âŒ Error in save_to_sheets: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    def save_backup(self, dfs):
        """ë¡œì»¬ ë°±ì—… ì €ì¥"""
        backup_dir = 'data_backup'
        if not os.path.exists(backup_dir):
            os.makedirs(backup_dir)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        saved_files = []
        
        for key, df in dfs.items():
            filename = f'{backup_dir}/esg_fund_{key}_{timestamp}.csv'
            df.to_csv(filename, index=False, encoding='utf-8-sig')
            saved_files.append(filename)
            print(f"ğŸ’¾ Saved backup: {filename}")
        
        return saved_files
    
    def cleanup_old_files(self):
        """24ì‹œê°„ ì´ìƒ ëœ íŒŒì¼ ì‚­ì œ"""
        directories = ['data_backup', 'chart_analysis']
        deleted_count = 0
        
        for directory in directories:
            if os.path.exists(directory):
                now = datetime.now()
                cutoff_time = now - timedelta(hours=24)
                
                # ë””ë ‰í† ë¦¬ ë‚´ íŒŒì¼ í™•ì¸
                for filename in os.listdir(directory):
                    filepath = os.path.join(directory, filename)
                    
                    # íŒŒì¼ì¸ ê²½ìš°ë§Œ ì²˜ë¦¬
                    if os.path.isfile(filepath):
                        # íŒŒì¼ ìˆ˜ì • ì‹œê°„ í™•ì¸
                        file_time = datetime.fromtimestamp(os.path.getmtime(filepath))
                        
                        if file_time < cutoff_time:
                            try:
                                os.remove(filepath)
                                deleted_count += 1
                                print(f"ğŸ—‘ï¸ Deleted old file: {filepath}")
                            except Exception as e:
                                print(f"âŒ Error deleting {filepath}: {e}")
        
        if deleted_count > 0:
            print(f"âœ… Cleaned up {deleted_count} old files")
        
        return deleted_count
    
    def calculate_fund_metrics(self, dfs):
        """ê° í€ë“œ ìœ í˜•ë³„ ì„¤ì •ì•¡ ì¦ê°ë¥ ê³¼ ì£¼ê°„ ìˆ˜ìµë¥  ê³„ì‚°"""
        metrics = {}
        
        if 'daily_chart' not in dfs or dfs['daily_chart'].empty:
            return metrics
        
        df = dfs['daily_chart'].copy()
        
        # ë‚ ì§œë¥¼ datetimeìœ¼ë¡œ ë³€í™˜
        df['date'] = pd.to_datetime(df['date'])
        
        # ê° íƒ­ë³„ë¡œ ê³„ì‚°
        for tab_type in ['SRI', 'ESG_ì£¼ì‹', 'ESG_ì±„ê¶Œ']:
            tab_df = df[df['tab_type'] == tab_type].copy()
            
            if tab_df.empty:
                continue
            
            # ë‚ ì§œìˆœ ì •ë ¬ (ì˜¤ë˜ëœ ê²ƒë¶€í„°)
            tab_df = tab_df.sort_values('date')
            
            # ê°€ì¥ ìµœê·¼ ë°ì´í„°
            latest = tab_df.iloc[-1]
            
            # 1ì£¼ì¼ ì „ ë°ì´í„° ì°¾ê¸°
            one_week_ago = latest['date'] - pd.Timedelta(days=7)
            week_ago_data = tab_df[tab_df['date'] <= one_week_ago]
            
            if not week_ago_data.empty:
                week_ago = week_ago_data.iloc[-1]
                
                # ì„¤ì •ì•¡ ì¦ê°ë¥  ê³„ì‚°
                if pd.notna(latest['setup_amount']) and pd.notna(week_ago['setup_amount']) and week_ago['setup_amount'] != 0:
                    setup_change = ((latest['setup_amount'] - week_ago['setup_amount']) / week_ago['setup_amount']) * 100
                else:
                    setup_change = None
                
                # ì£¼ê°„ ìˆ˜ìµë¥  (return_rateì˜ ì°¨ì´)
                if pd.notna(latest['return_rate']) and pd.notna(week_ago['return_rate']):
                    weekly_return = latest['return_rate'] - week_ago['return_rate']
                else:
                    weekly_return = None
            else:
                setup_change = None
                weekly_return = None
            
            # íƒ­ ì´ë¦„ ë§¤í•‘
            display_name = {
                'SRI': 'SRI í€ë“œ',
                'ESG_ì£¼ì‹': 'ESG ì£¼ì‹í˜•',
                'ESG_ì±„ê¶Œ': 'ESG ì±„ê¶Œí˜•'
            }.get(tab_type, tab_type)
            
            metrics[display_name] = {
                'latest_setup_amount': latest['setup_amount'] if pd.notna(latest['setup_amount']) else None,
                'latest_return_rate': latest['return_rate'] if pd.notna(latest['return_rate']) else None,
                'setup_change_pct': setup_change,
                'weekly_return': weekly_return,
                'latest_date': latest['date'].strftime('%Y-%m-%d')
            }
            
            print(f"   ğŸ“Š {display_name} ì§€í‘œ:")
            print(f"      - ìµœì‹  ì„¤ì •ì•¡: {latest['setup_amount']:.2f}ì–µì›" if pd.notna(latest['setup_amount']) else "      - ìµœì‹  ì„¤ì •ì•¡: N/A")
            print(f"      - ì„¤ì •ì•¡ ì¦ê°ë¥ : {setup_change:.2f}%" if setup_change is not None else "      - ì„¤ì •ì•¡ ì¦ê°ë¥ : N/A")
            print(f"      - ì£¼ê°„ ìˆ˜ìµë¥ : {weekly_return:.2f}%" if weekly_return is not None else "      - ì£¼ê°„ ìˆ˜ìµë¥ : N/A")
        
        return metrics
    
    def send_telegram_message(self, message):
        """Telegram ë©”ì‹œì§€ ì „ì†¡"""
        if not self.telegram_bot_token or not self.telegram_chat_id:
            print("âŒ Telegram credentials not found")
            return
        
        try:
            url = f"https://api.telegram.org/bot{self.telegram_bot_token}/sendMessage"
            data = {
                "chat_id": self.telegram_chat_id,
                "text": message,
                "parse_mode": "Markdown"
            }
            response = requests.post(url, data=data)
            response.raise_for_status()
        except Exception as e:
            print(f"âŒ Error sending Telegram message: {e}")
    
    def create_summary_html(self, all_data):
        """ì°¨íŠ¸ ë¶„ì„ ê²°ê³¼ë¥¼ HTMLë¡œ ì •ë¦¬"""
        html_content = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <meta charset="utf-8">
            <title>ESG Fund Chart Analysis - {datetime.now().strftime('%Y-%m-%d %H:%M')}</title>
            <style>
                body {{ font-family: Arial, sans-serif; margin: 20px; }}
                h1, h2 {{ color: #333; }}
                .tab-section {{ margin: 30px 0; padding: 20px; border: 1px solid #ddd; }}
                .chart-image {{ max-width: 100%; margin: 20px 0; }}
                .data-summary {{ background: #f5f5f5; padding: 15px; margin: 10px 0; }}
                .period-info {{ background: #e8f4f8; padding: 10px; margin-bottom: 20px; }}
            </style>
        </head>
        <body>
            <h1>ESG Fund Chart Analysis Report</h1>
            <div class="period-info">
                <strong>Collection Period:</strong> {self.period_text_map.get(self.collection_period)}<br>
                <strong>Generated:</strong> {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
            </div>
        """
        
        for tab_name, tab_data in all_data.items():
            html_content += f"""
            <div class="tab-section">
                <h2>{tab_name}</h2>
                <div class="data-summary">
                    <strong>Top Funds:</strong> {len(tab_data.get('top_funds', []))} items<br>
                    <strong>New Funds:</strong> {len(tab_data.get('new_funds', []))} items<br>
            """
            
            chart_data = tab_data.get('chart_data', {})
            if chart_data:
                primary = chart_data.get('primary_data', {})
                if primary and primary.get('dates'):
                    html_content += f"""
                    <strong>Chart Data Points:</strong> {len(primary.get('dates', []))} dates<br>
                    <strong>Data Source:</strong> {'JavaScript' if chart_data.get('js_data') else 'OCR'}
                    """
            
            html_content += f"""
                </div>
                <img class="chart-image" src="{tab_name}_chart_*.png" alt="{tab_name} Chart">
            </div>
            """
        
        html_content += """
        </body>
        </html>
        """
        
        # HTML íŒŒì¼ ì €ì¥
        html_path = 'chart_analysis/analysis_summary.html'
        with open(html_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        print(f"ğŸ“„ Created HTML summary: {html_path}")
        return html_path
    
    async def run(self):
        """ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        start_time = time.time()
        print(f"ğŸš€ Starting ESG Fund data collection at {datetime.now()}")
        
        try:
            # 0. ì˜¤ë˜ëœ íŒŒì¼ ì •ë¦¬
            deleted_files = self.cleanup_old_files()
            
            # 1. ëª¨ë“  íƒ­ ë°ì´í„° ìˆ˜ì§‘
            all_data = await self.scrape_all_tabs()
            
            # 2. DataFrame ë³€í™˜ (í†µí•©ëœ í˜•íƒœ)
            dfs = self.to_dataframes(all_data)
            
            # 3. ë°ì´í„° í†µê³„
            total_records = sum(len(df) for df in dfs.values())
            
            # 4. Google Sheets ì €ì¥
            updated_sheets = self.save_to_sheets(dfs)
            
            # 5. ë¡œì»¬ ë°±ì—…
            saved_files = self.save_backup(dfs)
            
            # 6. HTML ìš”ì•½ ìƒì„±
            summary_html = self.create_summary_html(all_data)
            
            # 7. ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
            execution_time = round(time.time() - start_time, 2)
            
            # 8. ìƒì„¸ í†µê³„
            stats = {}
            for key, df in dfs.items():
                if key == 'top_funds':
                    stats['TOP5 í€ë“œ'] = f"{len(df)}ê°œ (ìˆ˜ìµë¥ /ì„¤ì •ì•¡ì¦ê°€)"
                elif key == 'new_funds':
                    stats['ì‹ ê·œ í€ë“œ'] = f"{len(df)}ê°œ"
                elif key == 'daily_chart':
                    unique_dates = df['date'].nunique() if 'date' in df.columns else 0
                    stats['ì°¨íŠ¸ ë°ì´í„°'] = f"{unique_dates}ì¼ì¹˜"
                elif key == 'chart_comparison':
                    stats['ë¹„êµ ê²€ì¦ ë°ì´í„°'] = f"{len(df)}ê°œ"
            
            # 9. í€ë“œ ì§€í‘œ ê³„ì‚°
            fund_metrics = self.calculate_fund_metrics(dfs)
            
            # 10. ì„±ê³µ ë©”ì‹œì§€ ì „ì†¡
            period_text = self.period_text_map.get(self.collection_period, self.collection_period)
            
            # ê¸°ë³¸ ë©”ì‹œì§€
            message = f"""âœ… *ESG í€ë“œ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ*

ğŸ“… ìˆ˜ì§‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ğŸ“Š ì´ ë ˆì½”ë“œ: {total_records}ê°œ
ğŸ“ ì—…ë°ì´íŠ¸ ì‹œíŠ¸: {len(updated_sheets)}ê°œ
ğŸ—‘ï¸ ì •ë¦¬ëœ íŒŒì¼: {deleted_files}ê°œ
â±ï¸ ì‹¤í–‰ ì‹œê°„: {execution_time}ì´ˆ
ğŸ“ˆ ìˆ˜ì§‘ ê¸°ê°„: {period_text}

*ìˆ˜ì§‘ í˜„í™©:*
{chr(10).join([f"â€¢ {k}: {v}" for k, v in stats.items()])}"""

            # í€ë“œ ì§€í‘œ ì¶”ê°€
            if fund_metrics:
                message += "\n\n*ğŸ“Š ì£¼ê°„ í€ë“œ ë™í–¥:*"
                
                for fund_name, metrics in fund_metrics.items():
                    message += f"\n\n**{fund_name}**"
                    
                    # ì„¤ì •ì•¡ ì •ë³´
                    if metrics['latest_setup_amount'] is not None:
                        message += f"\nğŸ’° ì„¤ì •ì•¡: {metrics['latest_setup_amount']:,.1f}ì–µì›"
                        if metrics['setup_change_pct'] is not None:
                            if metrics['setup_change_pct'] > 0:
                                message += f" (ğŸ“ˆ +{metrics['setup_change_pct']:.1f}%)"
                            elif metrics['setup_change_pct'] < 0:
                                message += f" (ğŸ“‰ {metrics['setup_change_pct']:.1f}%)"
                            else:
                                message += f" (â¡ï¸ 0.0%)"
                    
                    # ìˆ˜ìµë¥  ì •ë³´
                    if metrics['weekly_return'] is not None:
                        if metrics['weekly_return'] > 0:
                            message += f"\nğŸ“Š ì£¼ê°„ìˆ˜ìµë¥ : +{metrics['weekly_return']:.2f}%"
                        else:
                            message += f"\nğŸ“Š ì£¼ê°„ìˆ˜ìµë¥ : {metrics['weekly_return']:.2f}%"
                    
                    # í˜„ì¬ ìˆ˜ìµë¥ 
                    if metrics['latest_return_rate'] is not None:
                        message += f"\nğŸ“ í˜„ì¬ìˆ˜ìµë¥ : {metrics['latest_return_rate']:.2f}%"
            
            # ì‹ ê·œ í€ë“œ ì •ë³´ ì¶”ê°€
            if 'new_funds' in dfs and not dfs['new_funds'].empty:
                new_funds_df = dfs['new_funds']
                # ì˜¤ëŠ˜ ë‚ ì§œì˜ ì‹ ê·œ í€ë“œë§Œ í•„í„°ë§
                today = datetime.now().strftime('%Y-%m-%d')
                today_new_funds = new_funds_df[new_funds_df['collection_date'] == today]
                
                if not today_new_funds.empty:
                    message += "\n\n*ğŸ†• ì‹ ê·œ ì¶œì‹œ í€ë“œ:*"
                    
                    # íƒ­ íƒ€ì…ë³„ë¡œ ê·¸ë£¹í™”
                    for tab_type in today_new_funds['tab_type'].unique():
                        tab_funds = today_new_funds[today_new_funds['tab_type'] == tab_type]
                        
                        # íƒ­ ì´ë¦„ í‘œì‹œ
                        tab_display = {
                            'SRI': 'SRI',
                            'ESG_ì£¼ì‹': 'ESG ì£¼ì‹í˜•',
                            'ESG_ì±„ê¶Œ': 'ESG ì±„ê¶Œí˜•'
                        }.get(tab_type, tab_type)
                        
                        message += f"\n\n**[{tab_display}]**"
                        
                        for _, fund in tab_funds.iterrows():
                            message += f"\nâ€¢ {fund['fund_name']}"
                            message += f"\n  - ìš´ìš©ì‚¬: {fund['company']}"
                            message += f"\n  - ì„¤ì •ì¼: {fund['setup_date']}"
                else:
                    # ì´ë²ˆ ì£¼ì˜ ì‹ ê·œ í€ë“œ í™•ì¸ (ìµœê·¼ 7ì¼)
                    week_ago = (datetime.now() - pd.Timedelta(days=7)).strftime('%Y-%m-%d')
                    week_new_funds = new_funds_df[new_funds_df['collection_date'] >= week_ago]
                    
                    if not week_new_funds.empty:
                        message += "\n\n*ğŸ†• ì´ë²ˆ ì£¼ ì‹ ê·œ ì¶œì‹œ í€ë“œ:*"
                        
                        for tab_type in week_new_funds['tab_type'].unique():
                            tab_funds = week_new_funds[week_new_funds['tab_type'] == tab_type]
                            
                            tab_display = {
                                'SRI': 'SRI',
                                'ESG_ì£¼ì‹': 'ESG ì£¼ì‹í˜•',
                                'ESG_ì±„ê¶Œ': 'ESG ì±„ê¶Œí˜•'
                            }.get(tab_type, tab_type)
                            
                            message += f"\n\n**[{tab_display}]**"
                            
                            # ì¤‘ë³µ ì œê±° (í€ë“œëª… ê¸°ì¤€)
                            unique_funds = tab_funds.drop_duplicates(subset=['fund_name'])
                            
                            for _, fund in unique_funds.iterrows():
                                message += f"\nâ€¢ {fund['fund_name']}"
                                message += f"\n  - ìš´ìš©ì‚¬: {fund['company']}"
                                message += f"\n  - ì„¤ì •ì¼: {fund['setup_date']}"
            
            message += f"\n\n*ìˆ˜ì§‘ ë²”ìœ„:*\nâ€¢ SRI í€ë“œ\nâ€¢ ESG ì£¼ì‹í˜• í€ë“œ\nâ€¢ ESG ì±„ê¶Œí˜• í€ë“œ"
            
            self.send_telegram_message(message)
            print("âœ… Data collection completed successfully")
            
        except Exception as e:
            error_message = f"""âŒ *ESG í€ë“œ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨*

ğŸ“… ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ğŸš« ì˜¤ë¥˜: {str(e)}

ê´€ë¦¬ìì—ê²Œ í™•ì¸ì„ ìš”ì²­í•˜ì„¸ìš”."""
            
            self.send_telegram_message(error_message)
            print(f"âŒ Data collection failed: {e}")
            raise

if __name__ == "__main__":
    scraper = ESGFundScraper()
    asyncio.run(scraper.run())
