import asyncio
from playwright.async_api import async_playwright
import pandas as pd
import gspread
from google.oauth2.service_account import Credentials
from datetime import datetime
import json
import os
import requests
import time
import re
from PIL import Image, ImageDraw, ImageEnhance
import pytesseract
import numpy as np
import cv2
import base64
from io import BytesIO

class ESGFundScraper:
    def __init__(self):
        self.base_url = "https://www.fundguide.net/hkcenter/esg"
        self.telegram_bot_token = os.environ.get('TELCO_NEWS_TOKEN')
        self.telegram_chat_id = os.environ.get('TELCO_NEWS_TESTER')
        
    def display_image_info(self, image_path, description=""):
        """ì´ë¯¸ì§€ ì •ë³´ë¥¼ í‘œì‹œí•˜ê³  í™•ì¸ ë°©ë²• ì•ˆë‚´"""
        try:
            # PILë¡œ ì´ë¯¸ì§€ ì—´ê¸°
            img = Image.open(image_path)
            width, height = img.size
            file_size = os.path.getsize(image_path)
            
            print(f"\nğŸ“¸ {description}: {os.path.basename(image_path)}")
            print(f"   ğŸ“ í¬ê¸°: {width}x{height} pixels")
            print(f"   ğŸ’¾ íŒŒì¼ í¬ê¸°: {file_size:,} bytes")
            print(f"   ğŸ“‚ ê²½ë¡œ: {os.path.abspath(image_path)}")
            
            # GitHub Actions í™˜ê²½ì—ì„œëŠ” ì•„í‹°íŒ©íŠ¸ë¡œ ì €ì¥ë¨ì„ ì•ˆë‚´
            if os.environ.get('GITHUB_ACTIONS'):
                print(f"   â˜ï¸  GitHub Actionsì—ì„œ ì‹¤í–‰ ì¤‘ - ì•„í‹°íŒ©íŠ¸ì—ì„œ í™•ì¸ ê°€ëŠ¥")
            else:
                print(f"   ğŸ–±ï¸  ë¡œì»¬ì—ì„œ íŒŒì¼ì„ ì§ì ‘ ì—´ì–´ì„œ í™•ì¸ ê°€ëŠ¥")
                
            # ì´ë¯¸ì§€ íˆìŠ¤í† ê·¸ë¨ ê°„ë‹¨ ë¶„ì„ (ì°¨íŠ¸ ë°ì´í„° ìœ ë¬´ í™•ì¸ìš©)
            img_gray = img.convert('L')
            histogram = img_gray.histogram()
            
            # ë°ì€ í”½ì…€ê³¼ ì–´ë‘ìš´ í”½ì…€ ë¹„ìœ¨ë¡œ ì°¨íŠ¸ ë³µì¡ë„ ì¶”ì •
            bright_pixels = sum(histogram[200:])  # ë°ì€ í”½ì…€
            dark_pixels = sum(histogram[:100])    # ì–´ë‘ìš´ í”½ì…€
            total_pixels = width * height
            
            bright_ratio = bright_pixels / total_pixels * 100
            dark_ratio = dark_pixels / total_pixels * 100
            
            print(f"   ğŸ¨ ë°ì€ ì˜ì—­: {bright_ratio:.1f}% | ì–´ë‘ìš´ ì˜ì—­: {dark_ratio:.1f}%")
            
            # ì°¨íŠ¸ ë¼ì¸ ì¶”ì • (ì¤‘ê°„ ë°ê¸° í”½ì…€)
            line_pixels = sum(histogram[100:200])
            line_ratio = line_pixels / total_pixels * 100
            print(f"   ğŸ“ˆ ì˜ˆìƒ ì°¨íŠ¸ ë¼ì¸ ì˜ì—­: {line_ratio:.1f}%")
            
            if line_ratio > 10:
                print(f"   âœ… ì¶©ë¶„í•œ ì°¨íŠ¸ ë°ì´í„°ê°€ ê°ì§€ë¨")
            else:
                print(f"   âš ï¸  ì°¨íŠ¸ ë°ì´í„°ê°€ ë¶€ì¡±í•  ìˆ˜ ìˆìŒ")
                
        except Exception as e:
            print(f"âŒ Error analyzing image: {e}")
    
    def create_image_summary_html(self, screenshot_dir, tab_name):
        """ë¶„ì„ëœ ì´ë¯¸ì§€ë“¤ì˜ HTML ìš”ì•½ íŒŒì¼ ìƒì„±"""
        try:
            # ìƒì„±ëœ ì´ë¯¸ì§€ íŒŒì¼ë“¤ í™•ì¸
            image_files = []
            for file in os.listdir(screenshot_dir):
                if file.startswith(tab_name) and file.endswith('.png'):
                    image_files.append(file)
            
            html_content = f"""
<!DOCTYPE html>
<html>
<head>
    <title>Chart Analysis - {tab_name}</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 20px; background: #f5f5f5; }}
        .container {{ max-width: 1200px; margin: 0 auto; background: white; padding: 20px; border-radius: 8px; }}
        .header {{ background: #2c3e50; color: white; padding: 20px; border-radius: 8px; margin-bottom: 20px; }}
        .image-section {{ margin: 30px 0; border: 1px solid #ddd; padding: 20px; border-radius: 8px; background: #fafafa; }}
        .image-section h3 {{ color: #2c3e50; margin-top: 0; border-bottom: 2px solid #3498db; padding-bottom: 10px; }}
        .image-grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; }}
        .image-item {{ text-align: center; background: white; padding: 15px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }}
        .image-item img {{ max-width: 100%; height: auto; border: 2px solid #bdc3c7; border-radius: 4px; }}
        .image-item p {{ margin: 10px 0; font-size: 14px; color: #666; font-weight: bold; }}
        .timestamp {{ color: #888; font-size: 12px; }}
        .file-list {{ background: #ecf0f1; padding: 15px; border-radius: 8px; margin: 20px 0; }}
        .file-list h4 {{ margin-top: 0; color: #2c3e50; }}
        .file-list ul {{ list-style-type: none; padding: 0; }}
        .file-list li {{ background: white; margin: 5px 0; padding: 8px; border-radius: 4px; font-family: monospace; }}
        .github-notice {{ background: #e8f4fd; border: 1px solid #3498db; padding: 15px; border-radius: 8px; margin: 20px 0; }}
        .github-notice h4 {{ color: #2980b9; margin-top: 0; }}
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ” ESG Fund Chart Analysis - {tab_name}</h1>
            <p class="timestamp">Generated at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
        </div>
        
        <div class="github-notice">
            <h4>ğŸ“¦ GitHub Actionsì—ì„œ ì‹¤í–‰ ì¤‘</h4>
            <p>ëª¨ë“  ì´ë¯¸ì§€ íŒŒì¼ì€ <strong>ì•„í‹°íŒ©íŠ¸</strong>ë¡œ ì €ì¥ë©ë‹ˆë‹¤.</p>
            <p>GitHub Actions ì‹¤í–‰ ì™„ë£Œ í›„ <strong>Artifacts</strong> ì„¹ì…˜ì—ì„œ ë‹¤ìš´ë¡œë“œí•˜ì—¬ í™•ì¸í•˜ì„¸ìš”.</p>
        </div>
        
        <div class="file-list">
            <h4>ğŸ“ ìƒì„±ëœ ì´ë¯¸ì§€ íŒŒì¼ë“¤</h4>
            <ul>
"""
            
            # íŒŒì¼ ëª©ë¡ ì¶”ê°€
            for file in sorted(image_files):
                file_path = os.path.join(screenshot_dir, file)
                if os.path.exists(file_path):
                    file_size = os.path.getsize(file_path)
                    html_content += f'                <li>ğŸ“¸ {file} ({file_size:,} bytes)</li>\n'
            
            html_content += """
            </ul>
        </div>
        
        <div class="image-section">
            <h3>ğŸ“± í˜ì´ì§€ ì „ì²´ ìº¡ì²˜</h3>
            <div class="image-grid">
                <div class="image-item">
                    <img src="{tab_name}_full_page.png" alt="Full Page" onerror="this.style.display='none'">
                    <p>ì „ì²´ í˜ì´ì§€ ìŠ¤í¬ë¦°ìƒ·</p>
                </div>
            </div>
        </div>
        
        <div class="image-section">
            <h3>ğŸ“Š ì°¨íŠ¸ ì˜ì—­ ìº¡ì²˜</h3>
            <div class="image-grid">
                <div class="image-item">
                    <img src="{tab_name}_chart_exact.png" alt="Exact Chart" onerror="this.style.display='none'">
                    <p>ì •í™•í•œ ì°¨íŠ¸ ì˜ì—­</p>
                </div>
                <div class="image-item">
                    <img src="{tab_name}_chart_extended.png" alt="Extended Chart" onerror="this.style.display='none'">
                    <p>í™•ì¥ëœ ì°¨íŠ¸ ì˜ì—­ (ì¶• í¬í•¨)</p>
                </div>
            </div>
        </div>
        
        <div class="image-section">
            <h3>ğŸ“ ì¶• ë¶„ì„ ê²°ê³¼</h3>
            <div class="image-grid">
                <div class="image-item">
                    <img src="{tab_name}_left_y_axis.png" alt="Left Y Axis" onerror="this.style.display='none'">
                    <p>ì™¼ìª½ Yì¶• (ì„¤ì •ì•¡)</p>
                </div>
                <div class="image-item">
                    <img src="{tab_name}_right_y_axis.png" alt="Right Y Axis" onerror="this.style.display='none'">
                    <p>ì˜¤ë¥¸ìª½ Yì¶• (ìˆ˜ìµë¥ )</p>
                </div>
                <div class="image-item">
                    <img src="{tab_name}_x_axis_improved.png" alt="X Axis Improved" onerror="this.style.display='none'">
                    <p>ê°œì„ ëœ Xì¶• (ë‚ ì§œ)</p>
                </div>
            </div>
        </div>
        
        <div class="image-section">
            <h3>ğŸ”§ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ê²°ê³¼</h3>
            <div class="image-grid">
                <div class="image-item">
                    <img src="{tab_name}_x_axis_binary.png" alt="X Axis Binary" onerror="this.style.display='none'">
                    <p>ì´ì§„í™”ëœ Xì¶• (OCRìš©)</p>
                </div>
                <div class="image-item">
                    <img src="{tab_name}_chart_area_pil.png" alt="Chart Area" onerror="this.style.display='none'">
                    <p>ìˆœìˆ˜ ì°¨íŠ¸ ì˜ì—­</p>
                </div>
            </div>
        </div>
        
        <div class="image-section">
            <h3>ğŸ¯ ë¼ì¸ ê°ì§€ ê²°ê³¼</h3>
            <div class="image-grid">
                <div class="image-item">
                    <img src="{tab_name}_blue_mask.png" alt="Blue Mask" onerror="this.style.display='none'">
                    <p>íŒŒë€ìƒ‰ ë¼ì¸ ë§ˆìŠ¤í¬ (ì„¤ì •ì•¡)</p>
                </div>
                <div class="image-item">
                    <img src="{tab_name}_red_mask.png" alt="Red Mask" onerror="this.style.display='none'">
                    <p>ë¹¨ê°„ìƒ‰ ë¼ì¸ ë§ˆìŠ¤í¬ (ìˆ˜ìµë¥ )</p>
                </div>
            </div>
        </div>
        
        <div class="image-section">
            <h3>ğŸ“‹ ë¶„ì„ ì²´í¬ë¦¬ìŠ¤íŠ¸</h3>
            <ol>
                <li><strong>ì „ì²´ í˜ì´ì§€:</strong> ì°¨íŠ¸ê°€ ì˜¬ë°”ë¥´ê²Œ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸</li>
                <li><strong>ì°¨íŠ¸ ì˜ì—­:</strong> ì •í™•í•œ ì°¨íŠ¸ ë²”ìœ„ê°€ ìº¡ì²˜ë˜ì—ˆëŠ”ì§€ í™•ì¸</li>
                <li><strong>Yì¶• ê°’:</strong> ì„¤ì •ì•¡ê³¼ ìˆ˜ìµë¥  ë²”ìœ„ê°€ OCRë¡œ ì½í˜”ëŠ”ì§€ í™•ì¸</li>
                <li><strong>Xì¶• ë‚ ì§œ:</strong> ë‚ ì§œê°€ ì •í™•íˆ ì¶”ì¶œë˜ì—ˆëŠ”ì§€ í™•ì¸</li>
                <li><strong>ì´ì§„í™” ì´ë¯¸ì§€:</strong> í…ìŠ¤íŠ¸ê°€ ëª…í™•í•˜ê²Œ ë³´ì´ëŠ”ì§€ í™•ì¸</li>
                <li><strong>ë¼ì¸ ë§ˆìŠ¤í¬:</strong> ì°¨íŠ¸ ë¼ì¸ì´ ì˜¬ë°”ë¥´ê²Œ ê°ì§€ë˜ì—ˆëŠ”ì§€ í™•ì¸</li>
            </ol>
            
            <div class="github-notice">
                <h4>ğŸ” ë¬¸ì œ í•´ê²° ê°€ì´ë“œ</h4>
                <ul>
                    <li><strong>ë‚ ì§œ ì¶”ì¶œ ì‹¤íŒ¨:</strong> Xì¶• ì´ë¯¸ì§€ì—ì„œ ë‚ ì§œê°€ ë³´ì´ëŠ”ì§€ í™•ì¸</li>
                    <li><strong>ë¼ì¸ ê°ì§€ ì‹¤íŒ¨:</strong> ìƒ‰ìƒ ë§ˆìŠ¤í¬ì—ì„œ ë¼ì¸ì´ ë³´ì´ëŠ”ì§€ í™•ì¸</li>
                    <li><strong>OCR ì˜¤ë¥˜:</strong> ì´ì§„í™” ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ê°€ ëª…í™•í•œì§€ í™•ì¸</li>
                    <li><strong>ì°¨íŠ¸ ì˜ì—­ ë¬¸ì œ:</strong> ì „ì²´ í˜ì´ì§€ì—ì„œ ì°¨íŠ¸ ìœ„ì¹˜ í™•ì¸</li>
                </ul>
            </div>
        </div>
    </div>
</body>
</html>
""".format(tab_name=tab_name)
            
            html_path = f'{screenshot_dir}/{tab_name}_analysis_summary.html'
            with open(html_path, 'w', encoding='utf-8') as f:
                f.write(html_content)
            
            print(f"ğŸ“„ HTML ìš”ì•½ íŒŒì¼ ìƒì„±: {html_path}")
            print(f"   ğŸŒ GitHub Actions Artifactsì—ì„œ í™•ì¸ ê°€ëŠ¥")
            print(f"   ğŸ“ ì´ {len(image_files)}ê°œ ì´ë¯¸ì§€ íŒŒì¼ ìƒì„±ë¨")
            
            return html_path
            
        except Exception as e:
            print(f"âŒ Error creating HTML summary: {e}")
            return None
    
    async def extract_chart_data_with_ocr_analysis(self, page, tab_name):
        """ì°¨íŠ¸ ì´ë¯¸ì§€ OCRê³¼ ì¢Œí‘œ ë¶„ì„ì„ í†µí•œ ë°ì´í„° ì¶”ì¶œ"""
        chart_data = {
            'dates': [],
            'setup_amounts': [],
            'returns': []
        }
        
        try:
            # ì°¨íŠ¸ ì˜ì—­ ì°¾ê¸°
            chart_element = await page.query_selector('#lineAreaZone')
            if not chart_element:
                print("Chart element not found")
                return chart_data
            
            # ì°¨íŠ¸ ì˜ì—­ì˜ í¬ê¸°ì™€ ìœ„ì¹˜ ê°€ì ¸ì˜¤ê¸°
            box = await chart_element.bounding_box()
            if not box:
                print("Could not get chart bounding box")
                return chart_data
            
            print(f"ğŸ“Š Chart area: x={box['x']}, y={box['y']}, width={box['width']}, height={box['height']}")
            
            # ìŠ¤í¬ë¦°ìƒ· ì €ì¥ ë””ë ‰í† ë¦¬
            screenshot_dir = 'chart_analysis'
            if not os.path.exists(screenshot_dir):
                os.makedirs(screenshot_dir)
            
            # ë¨¼ì € í˜ì´ì§€ ì „ì²´ ìŠ¤í¬ë¦°ìƒ·ìœ¼ë¡œ ë””ë²„ê¹…
            full_page_path = f'{screenshot_dir}/{tab_name}_full_page.png'
            await page.screenshot(path=full_page_path, full_page=True)
            print(f"ğŸ“· Full page screenshot: {full_page_path}")
            
            # ì°¨íŠ¸ ì˜ì—­ë§Œ ë” ì •í™•í•˜ê²Œ ìº¡ì²˜ (íŒ¨ë”© ìµœì†Œí™”)
            chart_screenshot_path = f'{screenshot_dir}/{tab_name}_chart_exact.png'
            await page.screenshot(
                path=chart_screenshot_path,
                clip={
                    'x': box['x'],
                    'y': box['y'], 
                    'width': box['width'],
                    'height': box['height']
                }
            )
            
            print(f"ğŸ“· Exact chart screenshot saved: {chart_screenshot_path}")
            self.display_image_info(chart_screenshot_path, "ì •í™•í•œ ì°¨íŠ¸ ì˜ì—­")
            
            # ë” ë„“ì€ ì˜ì—­ìœ¼ë¡œ ì°¨íŠ¸ + ì¶• ìº¡ì²˜
            extended_chart_path = f'{screenshot_dir}/{tab_name}_chart_extended.png'
            await page.screenshot(
                path=extended_chart_path,
                clip={
                    'x': max(0, box['x'] - 80),
                    'y': max(0, box['y'] - 30),
                    'width': min(1920, box['width'] + 160),
                    'height': min(1080, box['height'] + 80)
                }
            )
            
            print(f"ğŸ“· Extended chart screenshot saved: {extended_chart_path}")
            self.display_image_info(extended_chart_path, "í™•ì¥ëœ ì°¨íŠ¸ ì˜ì—­ (ì¶• í¬í•¨)")
            
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë° ë¶„ì„
            chart_image = Image.open(extended_chart_path)
            chart_data = await self.analyze_chart_image(chart_image, tab_name, screenshot_dir)
            
            # SVG ìš”ì†Œì—ì„œ ì§ì ‘ ë°ì´í„° ì¶”ì¶œ ì‹œë„
            svg_data = await self.extract_svg_chart_data(page)
            if svg_data:
                print("âœ… SVG ë°ì´í„° ì¶”ì¶œ ì„±ê³µ!")
                chart_data.update(svg_data)
            
            # HTML ìš”ì•½ íŒŒì¼ ìƒì„±
            self.create_image_summary_html(screenshot_dir, tab_name)
            
        except Exception as e:
            print(f"âŒ Error in chart OCR analysis: {e}")
            import traceback
            traceback.print_exc()
        
        return chart_data
    
    async def extract_svg_chart_data(self, page):
        """SVG ìš”ì†Œì—ì„œ ì§ì ‘ ì°¨íŠ¸ ë°ì´í„° ì¶”ì¶œ"""
        svg_data = {
            'dates': [],
            'setup_amounts': [],
            'returns': []
        }
        
        try:
            print("ğŸ” Attempting to extract data from SVG elements...")
            
            # Xì¶• í…ìŠ¤íŠ¸ ë ˆì´ë¸”ì—ì„œ ë‚ ì§œ ì¶”ì¶œ
            x_labels = await page.query_selector_all('.highcharts-xaxis-labels text')
            dates = []
            for label in x_labels:
                text = await label.inner_text()
                if text and '.' in text:  # ë‚ ì§œ í˜•ì‹ í™•ì¸
                    dates.append(text.strip())
            
            print(f"ğŸ“… Found {len(dates)} dates from SVG: {dates}")
            
            # Yì¶• ë ˆì´ë¸”ì—ì„œ ê°’ ë²”ìœ„ ì¶”ì¶œ
            y_labels = await page.query_selector_all('.highcharts-yaxis-labels text')
            left_y_values = []
            right_y_values = []
            
            for i, label in enumerate(y_labels):
                text = await label.inner_text()
                if text:
                    # í…ìŠ¤íŠ¸ì—ì„œ ìˆ«ì ì¶”ì¶œ
                    clean_text = text.replace(',', '').replace('%', '')
                    try:
                        value = float(clean_text)
                        # ìœ„ì¹˜ì— ë”°ë¼ ì™¼ìª½/ì˜¤ë¥¸ìª½ Yì¶• êµ¬ë¶„ (ëŒ€ëµì )
                        if i < len(y_labels) // 2:
                            left_y_values.append(value)
                        else:
                            right_y_values.append(value)
                    except:
                        pass
            
            print(f"ğŸ“Š Left Y-axis values from SVG: {sorted(left_y_values, reverse=True)}")
            print(f"ğŸ“Š Right Y-axis values from SVG: {sorted(right_y_values, reverse=True)}")
            
            # SVG path ìš”ì†Œì—ì„œ ì‹¤ì œ ì°¨íŠ¸ ë¼ì¸ ì¢Œí‘œ ì¶”ì¶œ
            chart_paths = await page.query_selector_all('.highcharts-series path')
            
            for i, path in enumerate(chart_paths):
                d_attr = await path.get_attribute('d')
                if d_attr:
                    print(f"ğŸ“ˆ Chart path {i}: {d_attr[:100]}...")
                    # SVG pathë¥¼ íŒŒì‹±í•˜ì—¬ ì¢Œí‘œ ì¶”ì¶œ (ë³µì¡í•œ ì‘ì—…ì´ë¯€ë¡œ ê¸°ë³¸ ì •ë³´ë§Œ)
            
            # íˆ´íŒì—ì„œ í˜„ì¬ í‘œì‹œëœ ê°’ ì¶”ì¶œ ì‹œë„
            tooltip = await page.query_selector('.highcharts-tooltip')
            if tooltip:
                tooltip_text = await tooltip.inner_text()
                print(f"ğŸ’¬ Current tooltip: {tooltip_text}")
            
            # ë ˆì „ë“œì—ì„œ ì‹œë¦¬ì¦ˆ ì •ë³´ í™•ì¸
            legends = await page.query_selector_all('.highcharts-legend-item text')
            for legend in legends:
                legend_text = await legend.inner_text()
                print(f"ğŸ“œ Legend: {legend_text}")
            
            if dates:
                svg_data['dates'] = dates
                # ë‚ ì§œ ìˆ˜ë§Œí¼ ì„ì‹œ ë°ì´í„° ìƒì„± (ì‹¤ì œ ê°’ì€ ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ì¶”ì¶œ)
                svg_data['setup_amounts'] = [None] * len(dates)
                svg_data['returns'] = [None] * len(dates)
                
        except Exception as e:
            print(f"âŒ Error extracting SVG data: {e}")
        
        return svg_data
    
    async def analyze_chart_image(self, chart_image, tab_name, screenshot_dir):
        """ì°¨íŠ¸ ì´ë¯¸ì§€ ë¶„ì„ ë° ë°ì´í„° ì¶”ì¶œ"""
        chart_data = {
            'dates': [],
            'setup_amounts': [],
            'returns': []
        }
        
        try:
            # ì´ë¯¸ì§€ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
            img_array = np.array(chart_image)
            
            # 1. Yì¶• ê°’ë“¤ ì¶”ì¶œ
            y_axis_values = self.extract_y_axis_values(chart_image, screenshot_dir, tab_name)
            
            # 2. Xì¶• ë‚ ì§œë“¤ ì¶”ì¶œ
            x_axis_dates = self.extract_x_axis_dates(chart_image, screenshot_dir, tab_name)
            
            # 3. ì°¨íŠ¸ ë¼ì¸ ì¢Œí‘œ ì¶”ì¶œ
            line_coordinates = self.extract_chart_lines(chart_image, screenshot_dir, tab_name)
            
            # 4. ì¢Œí‘œì™€ Yì¶• ê°’ì„ ì´ìš©í•œ ì‹¤ì œ ê°’ ê³„ì‚°
            if y_axis_values and line_coordinates and x_axis_dates:
                calculated_data = self.calculate_values_from_coordinates(
                    line_coordinates, y_axis_values, x_axis_dates
                )
                chart_data.update(calculated_data)
            
        except Exception as e:
            print(f"âŒ Error analyzing chart image: {e}")
        
        return chart_data
    
    def extract_y_axis_values(self, image, screenshot_dir, tab_name):
        """Yì¶• ê°’ë“¤ ì¶”ì¶œ"""
        y_axis_data = {
            'left_axis': [],  # ì„¤ì •ì•¡ (ì–µì›)
            'right_axis': [], # ìˆ˜ìµë¥  (%)
            'left_coords': [],
            'right_coords': []
        }
        
        try:
            width, height = image.size
            
            # ì™¼ìª½ Yì¶• ì˜ì—­ (ì„¤ì •ì•¡)
            left_y_axis = image.crop((0, 0, int(width * 0.15), height))
            left_y_path = f'{screenshot_dir}/{tab_name}_left_y_axis.png'
            left_y_axis.save(left_y_path)
            
            print(f"ğŸ“Š Left Y-axis cropped and saved: {left_y_path}")
            self.display_image_info(left_y_path, "ì™¼ìª½ Yì¶• (ì„¤ì •ì•¡)")
            
            # ì˜¤ë¥¸ìª½ Yì¶• ì˜ì—­ (ìˆ˜ìµë¥ )
            right_y_axis = image.crop((int(width * 0.85), 0, width, height))
            right_y_path = f'{screenshot_dir}/{tab_name}_right_y_axis.png'
            right_y_axis.save(right_y_path)
            
            print(f"ğŸ“Š Right Y-axis cropped and saved: {right_y_path}")
            self.display_image_info(right_y_path, "ì˜¤ë¥¸ìª½ Yì¶• (ìˆ˜ìµë¥ )")
            
            # OCRë¡œ Yì¶• ê°’ë“¤ ì¶”ì¶œ
            custom_config = r'--oem 3 --psm 6 -c tessedit_char_whitelist=0123456789.,%'
            
            # ì™¼ìª½ Yì¶• ê°’ë“¤ (ì„¤ì •ì•¡)
            left_text = pytesseract.image_to_string(left_y_axis, config=custom_config)
            print(f"ğŸ” Left Y-axis OCR result: {repr(left_text)}")
            
            left_values = []
            for line in left_text.split('\n'):
                # ìˆ«ì íŒ¨í„´ ì°¾ê¸° (ì‰¼í‘œ í¬í•¨)
                numbers = re.findall(r'[\d,]+\.?\d*', line.strip())
                for num_str in numbers:
                    try:
                        value = float(num_str.replace(',', ''))
                        if value > 1000:  # ì„¤ì •ì•¡ì€ ë³´í†µ í° ìˆ˜
                            left_values.append(value)
                    except:
                        pass
            
            # ì˜¤ë¥¸ìª½ Yì¶• ê°’ë“¤ (ìˆ˜ìµë¥ )
            right_text = pytesseract.image_to_string(right_y_axis, config=custom_config)
            print(f"ğŸ” Right Y-axis OCR result: {repr(right_text)}")
            
            right_values = []
            for line in right_text.split('\n'):
                numbers = re.findall(r'[\d.]+', line.strip())
                for num_str in numbers:
                    try:
                        value = float(num_str)
                        if 0 <= value <= 10:  # ìˆ˜ìµë¥ ì€ ë³´í†µ ì‘ì€ ìˆ˜
                            right_values.append(value)
                    except:
                        pass
            
            y_axis_data['left_axis'] = sorted(set(left_values), reverse=True)  # ìœ„ì—ì„œ ì•„ë˜ë¡œ
            y_axis_data['right_axis'] = sorted(set(right_values), reverse=True)
            
            print(f"ğŸ“ˆ Extracted left Y-axis values (ì„¤ì •ì•¡): {y_axis_data['left_axis']}")
            print(f"ğŸ“ˆ Extracted right Y-axis values (ìˆ˜ìµë¥ ): {y_axis_data['right_axis']}")
            
        except Exception as e:
            print(f"âŒ Error extracting Y-axis values: {e}")
        
        return y_axis_data
    
    def extract_x_axis_dates(self, image, screenshot_dir, tab_name):
        """Xì¶• ë‚ ì§œë“¤ ì¶”ì¶œ (ê°œì„ ëœ ë°©ë²•)"""
        dates = []
        
        try:
            width, height = image.size
            
            # Xì¶• ì˜ì—­ì„ ë” ì •í™•í•˜ê²Œ ì¶”ì¶œ (ì°¨íŠ¸ í•˜ë‹¨ë¶€)
            x_axis = image.crop((
                int(width * 0.1),   # ì™¼ìª½ ì—¬ë°±
                int(height * 0.8),  # ë” ìœ„ìª½ë¶€í„°
                int(width * 0.9),   # ì˜¤ë¥¸ìª½ ì—¬ë°±
                height              # ëê¹Œì§€
            ))
            x_axis_path = f'{screenshot_dir}/{tab_name}_x_axis_improved.png'
            x_axis.save(x_axis_path)
            
            print(f"ğŸ“… Improved X-axis cropped and saved: {x_axis_path}")
            self.display_image_info(x_axis_path, "ê°œì„ ëœ Xì¶• (ë‚ ì§œ)")
            
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            # 1. ëŒ€ë¹„ í–¥ìƒ
            enhancer = ImageEnhance.Contrast(x_axis)
            x_axis_enhanced = enhancer.enhance(2.0)
            
            # 2. ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            x_axis_gray = x_axis_enhanced.convert('L')
            
            # 3. ì´ì§„í™” (í…ìŠ¤íŠ¸ ì¶”ì¶œì„ ìœ„í•´)
            threshold = 128
            x_axis_binary = x_axis_gray.point(lambda p: p > threshold and 255)
            
            binary_path = f'{screenshot_dir}/{tab_name}_x_axis_binary.png'
            x_axis_binary.save(binary_path)
            self.display_image_info(binary_path, "ì´ì§„í™”ëœ Xì¶•")
            
            # ì—¬ëŸ¬ OCR ì„¤ì •ìœ¼ë¡œ ì‹œë„
            ocr_configs = [
                r'--oem 3 --psm 8',  # ë‹¨ì¼ ë‹¨ì–´
                r'--oem 3 --psm 7',  # ë‹¨ì¼ í…ìŠ¤íŠ¸ ë¼ì¸
                r'--oem 3 --psm 6',  # ê· ì¼í•œ í…ìŠ¤íŠ¸ ë¸”ë¡
                r'--oem 3 --psm 13', # ì›ì‹œ ë¼ì¸ (ìˆ«ì/ë‚ ì§œ)
            ]
            
            all_dates = []
            for i, config in enumerate(ocr_configs):
                try:
                    text_result = pytesseract.image_to_string(x_axis_binary, config=config)
                    print(f"ğŸ” X-axis OCR attempt {i+1}: {repr(text_result)}")
                    
                    # ë‚ ì§œ íŒ¨í„´ë“¤ ì‹œë„
                    date_patterns = [
                        r'(\d{4})[.\-/\s]+(\d{1,2})[.\-/\s]+(\d{1,2})',  # YYYY.MM.DD
                        r'(\d{1,2})[.\-/\s]+(\d{1,2})[.\-/\s]+(\d{4})',  # MM.DD.YYYY
                        r'(\d{4})(\d{2})(\d{2})',  # YYYYMMDD
                    ]
                    
                    for pattern in date_patterns:
                        matches = re.findall(pattern, text_result)
                        for match in matches:
                            try:
                                if len(match[0]) == 4:  # ì²« ë²ˆì§¸ê°€ ë…„ë„
                                    year, month, day = match
                                else:  # ë§ˆì§€ë§‰ì´ ë…„ë„
                                    month, day, year = match
                                
                                # ë‚ ì§œ ìœ íš¨ì„± ê²€ì‚¬
                                if 2020 <= int(year) <= 2030 and 1 <= int(month) <= 12 and 1 <= int(day) <= 31:
                                    formatted_date = f"{year}.{month.zfill(2)}.{day.zfill(2)}"
                                    if formatted_date not in all_dates:
                                        all_dates.append(formatted_date)
                            except:
                                pass
                                
                except Exception as e:
                    print(f"âŒ OCR attempt {i+1} failed: {e}")
            
            # ê²°ê³¼ ì •ë¦¬
            dates = sorted(list(set(all_dates)))
            print(f"ğŸ“… Final extracted dates: {dates}")
            
            # ë‚ ì§œê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ë‚ ì§œ ìƒì„± (ìµœê·¼ 1ê°œì›”)
            if not dates:
                print("âš ï¸ No dates found, generating default date range")
                from datetime import datetime, timedelta
                end_date = datetime.now()
                start_date = end_date - timedelta(days=30)
                
                # ì¼ì£¼ì¼ ê°„ê²©ìœ¼ë¡œ ë‚ ì§œ ìƒì„±
                current_date = start_date
                while current_date <= end_date:
                    dates.append(current_date.strftime('%Y.%m.%d'))
                    current_date += timedelta(days=7)
                    
                print(f"ğŸ“… Generated default dates: {dates}")
            
        except Exception as e:
            print(f"âŒ Error extracting X-axis dates: {e}")
        
        return dates
    
    def extract_chart_lines(self, image, screenshot_dir, tab_name):
        """ì°¨íŠ¸ ë¼ì¸ì˜ ì¢Œí‘œ ì¶”ì¶œ"""
        line_coords = {
            'setup_amount_line': [],  # ì„¤ì •ì•¡ ë¼ì¸ ì¢Œí‘œ
            'return_rate_line': []    # ìˆ˜ìµë¥  ë¼ì¸ ì¢Œí‘œ
        }
        
        try:
            # OpenCVë¡œ ì´ë¯¸ì§€ ì²˜ë¦¬
            img_cv = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
            
            # ì°¨íŠ¸ ì˜ì—­ë§Œ ì¶”ì¶œ (ì¶• ì œì™¸)
            height, width = img_cv.shape[:2]
            chart_area = img_cv[
                int(height * 0.1):int(height * 0.8),  # Y ë²”ìœ„
                int(width * 0.15):int(width * 0.85)   # X ë²”ìœ„
            ]
            
            # ì°¨íŠ¸ ì˜ì—­ ì €ì¥
            chart_area_path = f'{screenshot_dir}/{tab_name}_chart_area.png'
            cv2.imwrite(chart_area_path, chart_area)
            
            print(f"ğŸ“Š Chart area extracted: {chart_area_path}")
            
            # PILë¡œ ë³€í™˜í•´ì„œ ì½˜ì†” í‘œì‹œ
            chart_area_pil = Image.fromarray(cv2.cvtColor(chart_area, cv2.COLOR_BGR2RGB))
            chart_area_pil.save(f'{screenshot_dir}/{tab_name}_chart_area_pil.png')
            self.display_image_info(f'{screenshot_dir}/{tab_name}_chart_area_pil.png', "ìˆœìˆ˜ ì°¨íŠ¸ ì˜ì—­")
            
            # ë¼ì¸ ìƒ‰ìƒë³„ë¡œ ì¶”ì¶œ
            # íŒŒë€ìƒ‰ ê³„ì—´ (ì„¤ì •ì•¡ - ë©´ì  ì°¨íŠ¸ì˜ ë¼ì¸)
            blue_mask = self.create_color_mask(chart_area, 'blue')
            blue_line_coords = self.extract_line_coordinates(blue_mask, 'blue')
            
            # ë¹¨ê°„ìƒ‰/ì£¼í™©ìƒ‰ ê³„ì—´ (ìˆ˜ìµë¥  - ë¼ì¸ ì°¨íŠ¸)
            red_mask = self.create_color_mask(chart_area, 'red')
            red_line_coords = self.extract_line_coordinates(red_mask, 'red')
            
            # ë§ˆìŠ¤í¬ ì´ë¯¸ì§€ ì €ì¥
            cv2.imwrite(f'{screenshot_dir}/{tab_name}_blue_mask.png', blue_mask * 255)
            cv2.imwrite(f'{screenshot_dir}/{tab_name}_red_mask.png', red_mask * 255)
            
            print(f"ğŸ”µ Blue line coordinates (ì„¤ì •ì•¡): {len(blue_line_coords)} points")
            print(f"ğŸ”´ Red line coordinates (ìˆ˜ìµë¥ ): {len(red_line_coords)} points")
            
            line_coords['setup_amount_line'] = blue_line_coords
            line_coords['return_rate_line'] = red_line_coords
            
        except Exception as e:
            print(f"âŒ Error extracting chart lines: {e}")
        
        return line_coords
    
    def create_color_mask(self, image, color_type):
        """íŠ¹ì • ìƒ‰ìƒì˜ ë§ˆìŠ¤í¬ ìƒì„±"""
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        
        if color_type == 'blue':
            # íŒŒë€ìƒ‰ ë²”ìœ„
            lower_blue = np.array([100, 50, 50])
            upper_blue = np.array([130, 255, 255])
            mask = cv2.inRange(hsv, lower_blue, upper_blue)
        elif color_type == 'red':
            # ë¹¨ê°„ìƒ‰/ì£¼í™©ìƒ‰ ë²”ìœ„
            lower_red1 = np.array([0, 50, 50])
            upper_red1 = np.array([10, 255, 255])
            lower_red2 = np.array([170, 50, 50])
            upper_red2 = np.array([180, 255, 255])
            mask1 = cv2.inRange(hsv, lower_red1, upper_red1)
            mask2 = cv2.inRange(hsv, lower_red2, upper_red2)
            mask = cv2.bitwise_or(mask1, mask2)
        else:
            mask = np.zeros(hsv.shape[:2], dtype=np.uint8)
        
        return mask
    
    def extract_line_coordinates(self, mask, color_name):
        """ë§ˆìŠ¤í¬ì—ì„œ ë¼ì¸ ì¢Œí‘œ ì¶”ì¶œ"""
        coordinates = []
        
        try:
            # í˜•íƒœí•™ì  ì—°ì‚°ìœ¼ë¡œ ë…¸ì´ì¦ˆ ì œê±°
            kernel = np.ones((3, 3), np.uint8)
            mask_clean = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
            mask_clean = cv2.morphologyEx(mask_clean, cv2.MORPH_OPEN, kernel)
            
            # ì»¨íˆ¬ì–´ ì°¾ê¸°
            contours, _ = cv2.findContours(mask_clean, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            if contours:
                # ê°€ì¥ í° ì»¨íˆ¬ì–´ ì„ íƒ (ì£¼ìš” ë¼ì¸)
                largest_contour = max(contours, key=cv2.contourArea)
                
                # Xì¢Œí‘œ ìˆœìœ¼ë¡œ ì •ë ¬ëœ í¬ì¸íŠ¸ë“¤ ì¶”ì¶œ
                points = largest_contour.reshape(-1, 2)
                points = points[points[:, 0].argsort()]  # Xì¢Œí‘œë¡œ ì •ë ¬
                
                # ì¤‘ë³µ Xì¢Œí‘œ ì œê±°í•˜ê³  í‰ê·  Yì¢Œí‘œ ê³„ì‚°
                unique_points = {}
                for x, y in points:
                    if x not in unique_points:
                        unique_points[x] = []
                    unique_points[x].append(y)
                
                for x in sorted(unique_points.keys()):
                    avg_y = np.mean(unique_points[x])
                    coordinates.append((x, avg_y))
            
        except Exception as e:
            print(f"âŒ Error extracting {color_name} line coordinates: {e}")
        
        return coordinates
    
    def calculate_values_from_coordinates(self, line_coordinates, y_axis_values, x_axis_dates):
        """ì¢Œí‘œì™€ Yì¶• ê°’ì„ ì´ìš©í•œ ì‹¤ì œ ê°’ ê³„ì‚°"""
        calculated_data = {
            'dates': [],
            'setup_amounts': [],
            'returns': []
        }
        
        try:
            setup_line = line_coordinates.get('setup_amount_line', [])
            return_line = line_coordinates.get('return_rate_line', [])
            left_y_values = y_axis_values.get('left_axis', [])
            right_y_values = y_axis_values.get('right_axis', [])
            
            if not (setup_line or return_line) or not x_axis_dates:
                print("âš ï¸ Insufficient data for calculation")
                return calculated_data
            
            print(f"ğŸ§® Calculating values from coordinates...")
            print(f"   Setup line points: {len(setup_line)}")
            print(f"   Return line points: {len(return_line)}")
            print(f"   Available dates: {len(x_axis_dates)}")
            print(f"   Left Y values: {left_y_values}")
            print(f"   Right Y values: {right_y_values}")
            
            # ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ë³´ê°„
            for i, date in enumerate(x_axis_dates):
                calculated_data['dates'].append(date)
                
                # X ì¢Œí‘œ ë¹„ìœ¨ ê³„ì‚° (ë‚ ì§œ ì¸ë±ìŠ¤ ê¸°ë°˜)
                x_ratio = i / max(1, len(x_axis_dates) - 1)
                
                # ì„¤ì •ì•¡ ê³„ì‚°
                if setup_line and left_y_values:
                    setup_amount = self.interpolate_value_from_line(
                        setup_line, x_ratio, left_y_values, 'setup'
                    )
                    calculated_data['setup_amounts'].append(setup_amount)
                else:
                    calculated_data['setup_amounts'].append(None)
                
                # ìˆ˜ìµë¥  ê³„ì‚°
                if return_line and right_y_values:
                    return_rate = self.interpolate_value_from_line(
                        return_line, x_ratio, right_y_values, 'return'
                    )
                    calculated_data['returns'].append(return_rate)
                else:
                    calculated_data['returns'].append(None)
            
            print(f"âœ… Calculated {len(calculated_data['dates'])} data points")
            
        except Exception as e:
            print(f"âŒ Error calculating values: {e}")
        
        return calculated_data
    
    def interpolate_value_from_line(self, line_coords, x_ratio, y_values, value_type):
        """ë¼ì¸ ì¢Œí‘œì—ì„œ íŠ¹ì • X ë¹„ìœ¨ì— í•´ë‹¹í•˜ëŠ” Yê°’ ë³´ê°„"""
        try:
            if not line_coords or not y_values or len(y_values) < 2:
                return None
            
            # X ì¢Œí‘œë¥¼ 0-1 ë¹„ìœ¨ë¡œ ì •ê·œí™”
            x_coords = [coord[0] for coord in line_coords]
            y_coords = [coord[1] for coord in line_coords]
            
            if not x_coords:
                return None
            
            x_min, x_max = min(x_coords), max(x_coords)
            target_x = x_min + (x_max - x_min) * x_ratio
            
            # ê°€ì¥ ê°€ê¹Œìš´ ë‘ ì  ì°¾ê¸°
            closest_idx = 0
            min_distance = abs(x_coords[0] - target_x)
            
            for i, x_coord in enumerate(x_coords):
                distance = abs(x_coord - target_x)
                if distance < min_distance:
                    min_distance = distance
                    closest_idx = i
            
            # Y ì¢Œí‘œ ê°€ì ¸ì˜¤ê¸°
            y_coord = y_coords[closest_idx]
            
            # Yì¶• ê°’ ë²”ìœ„ì™€ ë¹„êµí•˜ì—¬ ì‹¤ì œ ê°’ ê³„ì‚°
            y_min_value = min(y_values)
            y_max_value = max(y_values)
            
            # Y ì¢Œí‘œë¥¼ 0-1 ë¹„ìœ¨ë¡œ ì •ê·œí™” (ì´ë¯¸ì§€ì—ì„œëŠ” ìœ„ìª½ì´ 0ì´ë¯€ë¡œ ë°˜ì „)
            chart_height = max(y_coords) - min(y_coords) if len(set(y_coords)) > 1 else 1
            y_ratio = 1 - ((y_coord - min(y_coords)) / chart_height)
            
            # ì‹¤ì œ ê°’ ê³„ì‚°
            actual_value = y_min_value + (y_max_value - y_min_value) * y_ratio
            
            return round(actual_value, 2)
            
        except Exception as e:
            print(f"âŒ Error interpolating {value_type} value: {e}")
            return None
    
    async def fetch_tab_data(self, page, tab_value, tab_name):
        """íŠ¹ì • íƒ­ì˜ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        print(f"ğŸ” Fetching data for {tab_name}...")
        
        # íƒ­ í´ë¦­
        await page.click(f'button[value="{tab_value}"]')
        await page.wait_for_timeout(3000)  # ë°ì´í„° ë¡œë”© ëŒ€ê¸°
        
        # ë°ì´í„° ì¶”ì¶œ
        data = {
            'tab_name': tab_name,
            'top_funds': await self.parse_top_funds(page),
            'new_funds': await self.parse_new_funds(page),
            'chart_data': await self.extract_chart_data_with_ocr_analysis(page, tab_name)
        }
        
        return data
    
    async def parse_top_funds(self, page):
        """Top í€ë“œ ë°ì´í„° íŒŒì‹±"""
        top_funds_data = {
            'return_top': [],
            'growth_top': []
        }
        
        # ìˆ˜ìµë¥  TOP 5
        return_funds = await page.query_selector_all('#topFundZone td:nth-child(1) li')
        return_rates = await page.query_selector_all('#topFundZone td:nth-child(2) li')
        
        for i in range(len(return_funds)):
            fund_elem = return_funds[i]
            rate_elem = return_rates[i] if i < len(return_rates) else None
            
            rank = await fund_elem.query_selector('i')
            rank_text = await rank.inner_text() if rank else ''
            
            fund_link = await fund_elem.query_selector('a')
            if fund_link:
                fund_name = await fund_link.inner_text()
                fund_code = await fund_link.get_attribute('data-fund_cd')
                rate_text = await rate_elem.inner_text() if rate_elem else ''
                
                top_funds_data['return_top'].append({
                    'rank': rank_text,
                    'fund_name': fund_name.strip(),
                    'fund_code': fund_code or '',
                    'return_rate': rate_text.strip()
                })
        
        # ì„¤ì •ì•¡ì¦ê°€ TOP 5
        growth_funds = await page.query_selector_all('#topFundZone td:nth-child(3) li')
        growth_amounts = await page.query_selector_all('#topFundZone td:nth-child(4) li')
        
        for i in range(len(growth_funds)):
            fund_elem = growth_funds[i]
            amount_elem = growth_amounts[i] if i < len(growth_amounts) else None
            
            rank = await fund_elem.query_selector('i')
            rank_text = await rank.inner_text() if rank else ''
            
            fund_link = await fund_elem.query_selector('a')
            if fund_link:
                fund_name = await fund_link.inner_text()
                fund_code = await fund_link.get_attribute('data-fund_cd')
                amount_text = await amount_elem.inner_text() if amount_elem else ''
                
                top_funds_data['growth_top'].append({
                    'rank': rank_text,
                    'fund_name': fund_name.strip(),
                    'fund_code': fund_code or '',
                    'growth_amount': amount_text.strip()
                })
        
        return top_funds_data
    
    async def parse_new_funds(self, page):
        """ì‹ ê·œ í€ë“œ ë°ì´í„° íŒŒì‹±"""
        new_funds_data = []
        
        # ì‹ ê·œ í€ë“œê°€ ì—†ëŠ”ì§€ í™•ì¸
        no_data = await page.query_selector('#newFundZone .nodata')
        if no_data:
            return new_funds_data
        
        # ì‹ ê·œ í€ë“œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        rows = await page.query_selector_all('#newFundZone tr')
        for row in rows:
            cols = await row.query_selector_all('td')
            if len(cols) >= 3:
                fund_name = await cols[0].inner_text()
                company = await cols[1].inner_text()
                setup_date = await cols[2].inner_text()
                
                new_funds_data.append({
                    'fund_name': fund_name.strip(),
                    'company': company.strip(),
                    'setup_date': setup_date.strip()
                })
        
        return new_funds_data
    
    async def scrape_all_tabs(self):
        """ëª¨ë“  íƒ­ì˜ ë°ì´í„° ìˆ˜ì§‘"""
        all_data = {}
        
        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=True)
            page = await browser.new_page()
            
            try:
                # í˜ì´ì§€ ë¡œë“œ
                await page.goto(self.base_url, wait_until='networkidle')
                await page.wait_for_timeout(3000)
                
                # ê° íƒ­ ë°ì´í„° ìˆ˜ì§‘
                tabs = [
                    ('T0370', 'SRI'),
                    ('T0371', 'ESG_ì£¼ì‹'),
                    ('T0373', 'ESG_ì±„ê¶Œ')
                ]
                
                for tab_value, tab_name in tabs:
                    data = await self.fetch_tab_data(page, tab_value, tab_name)
                    all_data[tab_name] = data
                    await page.wait_for_timeout(1000)  # íƒ­ ê°„ ëŒ€ê¸°
                
            except Exception as e:
                print(f"âŒ Error during scraping: {e}")
                await self.send_telegram_message(f"âŒ ESG í€ë“œ ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                raise
            finally:
                await browser.close()
        
        return all_data
    
    def to_dataframes(self, all_data):
        """ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜"""
        dfs = {}
        collection_date = datetime.now().strftime('%Y-%m-%d')
        collection_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        for tab_name, tab_data in all_data.items():
            # ìˆ˜ìµë¥  TOP 5
            if tab_data['top_funds']['return_top']:
                df_key = f'{tab_name}_return_top'
                df = pd.DataFrame(tab_data['top_funds']['return_top'])
                df['tab_type'] = tab_name
                df['collection_date'] = collection_date
                df['collection_time'] = collection_time
                dfs[df_key] = df
            
            # ì„¤ì •ì•¡ì¦ê°€ TOP 5
            if tab_data['top_funds']['growth_top']:
                df_key = f'{tab_name}_growth_top'
                df = pd.DataFrame(tab_data['top_funds']['growth_top'])
                df['tab_type'] = tab_name
                df['collection_date'] = collection_date
                df['collection_time'] = collection_time
                dfs[df_key] = df
            
            # ì‹ ê·œ í€ë“œ
            if tab_data['new_funds']:
                df_key = f'{tab_name}_new_funds'
                df = pd.DataFrame(tab_data['new_funds'])
                df['tab_type'] = tab_name
                df['collection_date'] = collection_date
                df['collection_time'] = collection_time
                dfs[df_key] = df
            
            # ì¼ë³„ ì°¨íŠ¸ ë°ì´í„° (ì„¤ì •ì•¡/ìˆ˜ìµë¥ )
            if tab_data.get('chart_data') and tab_data['chart_data'].get('dates'):
                df_key = f'{tab_name}_daily_chart'
                
                # ë°ì´í„° ê¸¸ì´ ë§ì¶”ê¸°
                dates = tab_data['chart_data']['dates']
                setup_amounts = tab_data['chart_data']['setup_amounts']
                returns = tab_data['chart_data']['returns']
                
                # ê°€ì¥ ì§§ì€ ê¸¸ì´ì— ë§ì¶”ê¸°
                min_length = min(len(dates), len(setup_amounts) if setup_amounts else 0, len(returns) if returns else 0)
                
                if min_length > 0:
                    chart_df = pd.DataFrame({
                        'date': dates[:min_length],
                        'setup_amount': setup_amounts[:min_length] if setup_amounts else [None] * min_length,
                        'return_rate': returns[:min_length] if returns else [None] * min_length
                    })
                    chart_df['tab_type'] = tab_name
                    chart_df['collection_time'] = collection_time
                    dfs[df_key] = chart_df
                    print(f"âœ… Created chart dataframe for {tab_name} with {min_length} rows")
        
        return dfs
    
    def save_to_sheets(self, dfs):
        """Google Sheetsì— ë°ì´í„° ì €ì¥"""
        # ì„œë¹„ìŠ¤ ê³„ì • ì¸ì¦
        scope = ['https://spreadsheets.google.com/feeds',
                 'https://www.googleapis.com/auth/drive']
        
        creds_json = os.environ.get('GOOGLE_SERVICE')
        if not creds_json:
            print("âŒ No Google Sheets credentials found")
            return []
        
        try:
            creds_dict = json.loads(creds_json)
            service_account_email = creds_dict.get('client_email', 'Unknown')
            print(f"ğŸ“§ Using service account: {service_account_email}")
            
            creds = Credentials.from_service_account_info(creds_dict, scopes=scope)
            client = gspread.authorize(creds)
            
            sheet_id = os.environ.get('KRFUND_SPREADSHEET_ID')
            if not sheet_id:
                print("âŒ No Google Sheet ID found")
                return []
                
            spreadsheet = client.open_by_key(sheet_id)
            
            # ì‹œíŠ¸ ì´ë¦„ ë§¤í•‘
            sheet_mapping = {
                'SRI_return_top': 'SRI_ìˆ˜ìµë¥ TOP5',
                'SRI_growth_top': 'SRI_ì„¤ì •ì•¡ì¦ê°€TOP5',
                'SRI_new_funds': 'SRI_ì‹ ê·œí€ë“œ',
                'SRI_daily_chart': 'SRI_ì¼ë³„ì°¨íŠ¸',
                'ESG_ì£¼ì‹_return_top': 'ESGì£¼ì‹_ìˆ˜ìµë¥ TOP5',
                'ESG_ì£¼ì‹_growth_top': 'ESGì£¼ì‹_ì„¤ì •ì•¡ì¦ê°€TOP5',
                'ESG_ì£¼ì‹_new_funds': 'ESGì£¼ì‹_ì‹ ê·œí€ë“œ',
                'ESG_ì£¼ì‹_daily_chart': 'ESGì£¼ì‹_ì¼ë³„ì°¨íŠ¸',
                'ESG_ì±„ê¶Œ_return_top': 'ESGì±„ê¶Œ_ìˆ˜ìµë¥ TOP5',
                'ESG_ì±„ê¶Œ_growth_top': 'ESGì±„ê¶Œ_ì„¤ì •ì•¡ì¦ê°€TOP5',
                'ESG_ì±„ê¶Œ_new_funds': 'ESGì±„ê¶Œ_ì‹ ê·œí€ë“œ',
                'ESG_ì±„ê¶Œ_daily_chart': 'ESGì±„ê¶Œ_ì¼ë³„ì°¨íŠ¸'
            }
            
            updated_sheets = []
            
            for df_key, df in dfs.items():
                sheet_name = sheet_mapping.get(df_key, df_key)
                
                try:
                    # ì‹œíŠ¸ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±
                    try:
                        worksheet = spreadsheet.worksheet(sheet_name)
                    except:
                        worksheet = spreadsheet.add_worksheet(title=sheet_name, rows=1000, cols=20)
                    
                    # ê¸°ì¡´ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                    existing_data = worksheet.get_all_records()
                    
                    if existing_data:
                        existing_df = pd.DataFrame(existing_data)
                        combined_df = pd.concat([existing_df, df], ignore_index=True)
                    else:
                        combined_df = df
                    
                    # ë°ì´í„° ì“°ê¸°
                    worksheet.clear()
                    worksheet.update([combined_df.columns.values.tolist()] + combined_df.values.tolist())
                    
                    updated_sheets.append(sheet_name)
                    print(f"âœ… Successfully updated {sheet_name}")
                    
                except Exception as e:
                    print(f"âŒ Error updating {sheet_name}: {e}")
                    
            return updated_sheets
            
        except Exception as e:
            print(f"âŒ Error in save_to_sheets: {e}")
            return []
    
    def save_backup(self, dfs):
        """ë¡œì»¬ ë°±ì—… ì €ì¥"""
        backup_dir = 'data_backup'
        if not os.path.exists(backup_dir):
            os.makedirs(backup_dir)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        saved_files = []
        
        for key, df in dfs.items():
            filename = f'{backup_dir}/esg_fund_{key}_{timestamp}.csv'
            df.to_csv(filename, index=False, encoding='utf-8-sig')
            saved_files.append(filename)
        
        return saved_files
    
    def send_telegram_message(self, message):
        """Telegram ë©”ì‹œì§€ ì „ì†¡"""
        if not self.telegram_bot_token or not self.telegram_chat_id:
            print("âŒ Telegram credentials not found")
            return
        
        try:
            url = f"https://api.telegram.org/bot{self.telegram_bot_token}/sendMessage"
            data = {
                "chat_id": self.telegram_chat_id,
                "text": message,
                "parse_mode": "Markdown"
            }
            response = requests.post(url, data=data)
            response.raise_for_status()
        except Exception as e:
            print(f"âŒ Error sending Telegram message: {e}")
    
    async def run(self):
        """ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        start_time = time.time()
        print(f"ğŸš€ Starting ESG Fund data collection at {datetime.now()}")
        
        try:
            # 1. ëª¨ë“  íƒ­ ë°ì´í„° ìˆ˜ì§‘
            all_data = await self.scrape_all_tabs()
            
            # 2. DataFrame ë³€í™˜
            dfs = self.to_dataframes(all_data)
            
            # 3. ë°ì´í„° í†µê³„
            total_records = sum(len(df) for df in dfs.values())
            
            # 4. Google Sheets ì €ì¥
            updated_sheets = self.save_to_sheets(dfs)
            
            # 5. ë¡œì»¬ ë°±ì—…
            saved_files = self.save_backup(dfs)
            
            # 6. ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
            execution_time = round(time.time() - start_time, 2)
            
            # 7. ì„±ê³µ ë©”ì‹œì§€ ì „ì†¡
            sheets_count = len(updated_sheets) if isinstance(updated_sheets, list) else 0
            message = f"""âœ… *ESG í€ë“œ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ*

ğŸ“… ìˆ˜ì§‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ğŸ“Š ìˆ˜ì§‘ ë°ì´í„°: {total_records}ê°œ ë ˆì½”ë“œ
ğŸ“ ì—…ë°ì´íŠ¸ ì‹œíŠ¸: {sheets_count}ê°œ
ğŸ’¾ ë°±ì—… íŒŒì¼: {len(saved_files)}ê°œ
â±ï¸ ì‹¤í–‰ ì‹œê°„: {execution_time}ì´ˆ

*ìˆ˜ì§‘ í•­ëª©:*
- SRI í€ë“œ
- ESG ì£¼ì‹í˜• í€ë“œ  
- ESG ì±„ê¶Œí˜• í€ë“œ

ê° í•­ëª©ë³„ ìˆ˜ìµë¥  TOP5, ì„¤ì •ì•¡ì¦ê°€ TOP5, ì‹ ê·œí€ë“œ, ì¼ë³„ ì°¨íŠ¸ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ"""
            
            self.send_telegram_message(message)
            print("âœ… Data collection completed successfully")
            
        except Exception as e:
            error_message = f"""âŒ *ESG í€ë“œ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨*

ğŸ“… ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ğŸš« ì˜¤ë¥˜: {str(e)}

ê´€ë¦¬ìì—ê²Œ í™•ì¸ì„ ìš”ì²­í•˜ì„¸ìš”."""
            
            self.send_telegram_message(error_message)
            print(f"âŒ Data collection failed: {e}")
            raise

if __name__ == "__main__":
    scraper = ESGFundScraper()
    asyncio.run(scraper.run())
