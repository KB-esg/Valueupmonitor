import asyncio
from playwright.async_api import async_playwright
import pandas as pd
import gspread
from google.oauth2.service_account import Credentials
from datetime import datetime
import json
import os
import requests
import time
import re
from PIL import Image, ImageDraw, ImageEnhance
import pytesseract
import numpy as np
import cv2

class ESGFundScraper:
    def __init__(self):
        self.base_url = "https://www.fundguide.net/hkcenter/esg"
        self.telegram_bot_token = os.environ.get('TELCO_NEWS_TOKEN')
        self.telegram_chat_id = os.environ.get('TELCO_NEWS_TESTER')
        # í™˜ê²½ ë³€ìˆ˜ì—ì„œ ê¸°ê°„ ì„¤ì • ê°€ì ¸ì˜¤ê¸° (ê¸°ë³¸ê°’: 1ê°œì›”)
        self.collection_period = os.environ.get('COLLECTION_PERIOD', '01')
        self.period_text_map = {
            '01': '1ê°œì›”',
            '03': '3ê°œì›”',
            '06': '6ê°œì›”',
            'YTD': 'ì—°ì´ˆì´í›„',
            '12': '1ë…„',
            '36': '3ë…„',
            '60': '5ë…„'
        }
        print(f"ğŸ“… Collection period set to: {self.collection_period} ({self.period_text_map.get(self.collection_period, self.collection_period)})")
        
    async def extract_chart_data_via_javascript(self, page):
        """JavaScriptë¥¼ í†µí•´ Highcharts ë°ì´í„° ì§ì ‘ ì¶”ì¶œ"""
        try:
            chart_data = await page.evaluate('''
                () => {
                    // Highcharts ì¸ìŠ¤í„´ìŠ¤ ì°¾ê¸°
                    let chartData = {
                        dates: [],
                        setup_amounts: [],
                        returns: []
                    };
                    
                    // ë°©ë²• 1: Highcharts.charts ë°°ì—´ì—ì„œ ì°¾ê¸°
                    if (typeof Highcharts !== 'undefined' && Highcharts.charts) {
                        for (let i = 0; i < Highcharts.charts.length; i++) {
                            let chart = Highcharts.charts[i];
                            if (chart && chart.container && chart.container.id === 'lineAreaZone') {
                                console.log('Found chart at index:', i);
                                
                                // Xì¶• ì¹´í…Œê³ ë¦¬ (ë‚ ì§œ)
                                if (chart.xAxis && chart.xAxis[0]) {
                                    // categoriesê°€ ì—†ìœ¼ë©´ tick labelsì—ì„œ ì¶”ì¶œ
                                    if (chart.xAxis[0].categories) {
                                        chartData.dates = chart.xAxis[0].categories;
                                    } else if (chart.xAxis[0].tickPositions) {
                                        // Xì¶• ë ˆì´ë¸”ì—ì„œ ì§ì ‘ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                                        const labels = [];
                                        chart.xAxis[0].ticks && Object.values(chart.xAxis[0].ticks).forEach(tick => {
                                            if (tick.label && tick.label.textStr) {
                                                labels.push(tick.label.textStr);
                                            }
                                        });
                                        chartData.dates = labels;
                                    }
                                }
                                
                                // ì‹œë¦¬ì¦ˆ ë°ì´í„°
                                if (chart.series && chart.series.length > 0) {
                                    chart.series.forEach((series, index) => {
                                        if (series.data && series.data.length > 0) {
                                            const values = series.data.map(point => {
                                                if (point.y !== undefined) return point.y;
                                                if (point.options && point.options.y !== undefined) return point.options.y;
                                                return null;
                                            });
                                            
                                            // ì‹œë¦¬ì¦ˆ ì´ë¦„ìœ¼ë¡œ êµ¬ë¶„ (ì—†ìœ¼ë©´ ì¸ë±ìŠ¤ë¡œ)
                                            if (series.name) {
                                                if (series.name.includes('ì„¤ì •ì•¡') || series.name.includes('ì¢Œ')) {
                                                    chartData.setup_amounts = values;
                                                } else if (series.name.includes('ìˆ˜ìµë¥ ') || series.name.includes('ìš°')) {
                                                    chartData.returns = values;
                                                }
                                            } else {
                                                // ì´ë¦„ì´ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ì‹œë¦¬ì¦ˆë¥¼ ì„¤ì •ì•¡, ë‘ ë²ˆì§¸ë¥¼ ìˆ˜ìµë¥ ë¡œ ê°€ì •
                                                if (index === 0) {
                                                    chartData.setup_amounts = values;
                                                } else if (index === 1) {
                                                    chartData.returns = values;
                                                }
                                            }
                                        }
                                    });
                                }
                                
                                // Yì¶• ì •ë³´ë„ ì¶”ì¶œ (ê°’ ë²”ìœ„ íŒŒì•…ìš©)
                                if (chart.yAxis) {
                                    chart.yAxis.forEach((axis, index) => {
                                        console.log(`Y-axis ${index} range:`, axis.min, '-', axis.max);
                                    });
                                }
                                
                                break;
                            }
                        }
                    }
                    
                    // ë°©ë²• 2: data-highcharts-chart ì†ì„±ìœ¼ë¡œ ì°¾ê¸°
                    if (chartData.dates.length === 0) {
                        const chartDiv = document.querySelector('#lineAreaZone');
                        if (chartDiv) {
                            const chartIndex = chartDiv.getAttribute('data-highcharts-chart');
                            if (chartIndex && Highcharts.charts[chartIndex]) {
                                const chart = Highcharts.charts[chartIndex];
                                console.log('Found chart via data attribute');
                                
                                // ìœ„ì™€ ë™ì¼í•œ ë¡œì§ìœ¼ë¡œ ë°ì´í„° ì¶”ì¶œ
                                if (chart.xAxis && chart.xAxis[0] && chart.xAxis[0].categories) {
                                    chartData.dates = chart.xAxis[0].categories;
                                }
                                
                                if (chart.series) {
                                    chart.series.forEach((series, index) => {
                                        if (series.data) {
                                            const values = series.data.map(point => point.y);
                                            if (index === 0) chartData.setup_amounts = values;
                                            else if (index === 1) chartData.returns = values;
                                        }
                                    });
                                }
                            }
                        }
                    }
                    
                    // ë°©ë²• 3: SVG ìš”ì†Œì—ì„œ ì§ì ‘ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ì°¨ì„ ì±…)
                    if (chartData.dates.length === 0) {
                        const xLabels = document.querySelectorAll('.highcharts-xaxis-labels text');
                        xLabels.forEach(label => {
                            if (label.textContent) {
                                chartData.dates.push(label.textContent);
                            }
                        });
                    }
                    
                    console.log('Extracted data:', chartData);
                    return chartData;
                }
            ''')
            
            if chart_data and chart_data.get('dates'):
                print(f"ğŸ“Š JavaScript extraction successful!")
                print(f"   Dates: {chart_data['dates']}")
                print(f"   Setup amounts count: {len(chart_data.get('setup_amounts', []))}")
                print(f"   Returns count: {len(chart_data.get('returns', []))}")
                
                # ë°ì´í„° ê²€ì¦
                if chart_data.get('setup_amounts'):
                    print(f"   Setup amounts sample: {chart_data['setup_amounts'][:3]}...")
                if chart_data.get('returns'):
                    print(f"   Returns sample: {chart_data['returns'][:3]}...")
                    
                return chart_data
                
        except Exception as e:
            print(f"âŒ JavaScript extraction failed: {e}")
            import traceback
            traceback.print_exc()
        
        return None

    async def extract_chart_data(self, page, tab_name):
        """ì°¨íŠ¸ ë°ì´í„° ì¶”ì¶œ (JavaScriptì™€ OCR ë‘˜ ë‹¤ ìˆ˜í–‰í•˜ì—¬ ë¹„êµ)"""
        # 1. JavaScriptë¡œ ì§ì ‘ ì¶”ì¶œ ì‹œë„
        js_data = await self.extract_chart_data_via_javascript(page)
        
        # 2. ì´ë¯¸ì§€ OCR ë¶„ì„ë„ ìˆ˜í–‰ (ë¹„êµìš©)
        ocr_data = await self.extract_chart_data_with_ocr_analysis(page, tab_name)
        
        # ë‘ ë°©ë²• ëª¨ë‘ì˜ ê²°ê³¼ë¥¼ ë°˜í™˜
        return {
            'js_data': js_data,
            'ocr_data': ocr_data,
            'primary_data': js_data if js_data and js_data.get('dates') else ocr_data
        }
    
    async def extract_chart_data_with_ocr_analysis(self, page, tab_name):
        """ì°¨íŠ¸ ì´ë¯¸ì§€ OCR ë¶„ì„ (ë°±ì—… ë°©ë²•)"""
        chart_data = {
            'dates': [],
            'setup_amounts': [],
            'returns': []
        }
        
        try:
            # ì°¨íŠ¸ ì»¨í…Œì´ë„ˆ ì°¾ê¸°
            chart_container = await page.query_selector('#lineAreaZone')
            if not chart_container:
                print("âŒ Chart container #lineAreaZone not found")
                return chart_data
            
            # ì°¨íŠ¸ ì˜ì—­ ìŠ¤í¬ë¦°ìƒ·
            screenshot_dir = 'chart_analysis'
            if not os.path.exists(screenshot_dir):
                os.makedirs(screenshot_dir)
            
            chart_path = f'{screenshot_dir}/{tab_name}_chart.png'
            await chart_container.screenshot(path=chart_path)
            print(f"ğŸ“· Chart screenshot saved: {chart_path}")
            
            # ì—¬ê¸°ì— OCR ë¶„ì„ ë¡œì§ ì¶”ê°€ (í•„ìš”ì‹œ)
            # ...
            
        except Exception as e:
            print(f"âŒ Error in chart image analysis: {e}")
        
        return chart_data
    
    async def parse_top_funds(self, page):
        """Top í€ë“œ ë°ì´í„° íŒŒì‹±"""
        top_funds_data = []
        
        # ìˆ˜ìµë¥  TOP 5
        return_funds = await page.query_selector_all('#topFundZone td:nth-child(1) li')
        return_rates = await page.query_selector_all('#topFundZone td:nth-child(2) li')
        
        for i in range(len(return_funds)):
            fund_elem = return_funds[i]
            rate_elem = return_rates[i] if i < len(return_rates) else None
            
            rank = await fund_elem.query_selector('i')
            rank_text = await rank.inner_text() if rank else ''
            
            fund_link = await fund_elem.query_selector('a')
            if fund_link:
                fund_name = await fund_link.inner_text()
                fund_code = await fund_link.get_attribute('data-fund_cd')
                rate_text = await rate_elem.inner_text() if rate_elem else ''
                
                top_funds_data.append({
                    'rank': rank_text,
                    'fund_name': fund_name.strip(),
                    'fund_code': fund_code or '',
                    'value': rate_text.strip(),
                    'type': 'ìˆ˜ìµë¥ '
                })
        
        # ì„¤ì •ì•¡ì¦ê°€ TOP 5
        growth_funds = await page.query_selector_all('#topFundZone td:nth-child(3) li')
        growth_amounts = await page.query_selector_all('#topFundZone td:nth-child(4) li')
        
        for i in range(len(growth_funds)):
            fund_elem = growth_funds[i]
            amount_elem = growth_amounts[i] if i < len(growth_amounts) else None
            
            rank = await fund_elem.query_selector('i')
            rank_text = await rank.inner_text() if rank else ''
            
            fund_link = await fund_elem.query_selector('a')
            if fund_link:
                fund_name = await fund_link.inner_text()
                fund_code = await fund_link.get_attribute('data-fund_cd')
                amount_text = await amount_elem.inner_text() if amount_elem else ''
                
                top_funds_data.append({
                    'rank': rank_text,
                    'fund_name': fund_name.strip(),
                    'fund_code': fund_code or '',
                    'value': amount_text.strip(),
                    'type': 'ì„¤ì •ì•¡ì¦ê°€'
                })
        
        return top_funds_data
    
    async def parse_new_funds(self, page):
        """ì‹ ê·œ í€ë“œ ë°ì´í„° íŒŒì‹±"""
        new_funds_data = []
        
        # ì‹ ê·œ í€ë“œê°€ ì—†ëŠ”ì§€ í™•ì¸
        no_data = await page.query_selector('#newFundZone .nodata')
        if no_data:
            return new_funds_data
        
        # ì‹ ê·œ í€ë“œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        rows = await page.query_selector_all('#newFundZone tr')
        for row in rows:
            cols = await row.query_selector_all('td')
            if len(cols) >= 3:
                fund_name = await cols[0].inner_text()
                company = await cols[1].inner_text()
                setup_date = await cols[2].inner_text()
                
                new_funds_data.append({
                    'fund_name': fund_name.strip(),
                    'company': company.strip(),
                    'setup_date': setup_date.strip()
                })
        
        return new_funds_data
    
    async def fetch_tab_data(self, page, tab_value, tab_name):
        """íŠ¹ì • íƒ­ì˜ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        print(f"ğŸ” Fetching data for {tab_name}...")
        
        # íƒ­ í´ë¦­
        await page.click(f'button[value="{tab_value}"]')
        await page.wait_for_timeout(3000)  # ë°ì´í„° ë¡œë”© ëŒ€ê¸°
        
        # ê¸°ê°„ ì„ íƒ (ë“œë¡­ë‹¤ìš´ì—ì„œ ì„ íƒ)
        try:
            # ë¨¼ì € í˜„ì¬ ì„ íƒëœ ê¸°ê°„ í™•ì¸
            current_period = await page.inner_text('#selTerm option[selected]')
            print(f"ğŸ“… Current period: {current_period}")
            
            # ì›í•˜ëŠ” ê¸°ê°„ì´ ì´ë¯¸ ì„ íƒë˜ì–´ ìˆì§€ ì•Šì€ ê²½ìš°ì—ë§Œ ë³€ê²½
            if self.collection_period != '01':  # ê¸°ë³¸ê°’ì´ ì•„ë‹Œ ê²½ìš°
                print(f"ğŸ“… Changing period to: {self.period_text_map.get(self.collection_period)}")
                
                # select ìš”ì†Œë¥¼ ì§ì ‘ ì¡°ì‘
                await page.select_option('#selTerm', self.collection_period)
                
                # ì„ íƒ í›„ ì°¨íŠ¸ ë°ì´í„° ë¡œë”© ëŒ€ê¸°
                await page.wait_for_timeout(3000)
                
                # ë³€ê²½ í™•ì¸
                new_period = await page.inner_text('#selTerm option[selected]')
                print(f"âœ… Period changed to: {new_period}")
        except Exception as e:
            print(f"âš ï¸ Error changing period: {e}")
            # ì˜¤ë¥˜ê°€ ë°œìƒí•´ë„ ê³„ì† ì§„í–‰
        
        # ë°ì´í„° ì¶”ì¶œ
        data = {
            'tab_name': tab_name,
            'collection_period': self.collection_period,
            'period_text': self.period_text_map.get(self.collection_period, self.collection_period),
            'top_funds': await self.parse_top_funds(page),
            'new_funds': await self.parse_new_funds(page),
            'chart_data': await self.extract_chart_data(page, tab_name)
        }
        
        return data
    
    async def scrape_all_tabs(self):
        """ëª¨ë“  íƒ­ì˜ ë°ì´í„° ìˆ˜ì§‘"""
        all_data = {}
        
        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=True)
            page = await browser.new_page()
            
            try:
                # í˜ì´ì§€ ë¡œë“œ
                await page.goto(self.base_url, wait_until='networkidle')
                await page.wait_for_timeout(3000)
                
                # ê° íƒ­ ë°ì´í„° ìˆ˜ì§‘
                tabs = [
                    ('T0370', 'SRI'),
                    ('T0371', 'ESG_ì£¼ì‹'),
                    ('T0373', 'ESG_ì±„ê¶Œ')
                ]
                
                for tab_value, tab_name in tabs:
                    data = await self.fetch_tab_data(page, tab_value, tab_name)
                    all_data[tab_name] = data
                    await page.wait_for_timeout(1000)  # íƒ­ ê°„ ëŒ€ê¸°
                
            except Exception as e:
                print(f"âŒ Error during scraping: {e}")
                await self.send_telegram_message(f"âŒ ESG í€ë“œ ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                raise
            finally:
                await browser.close()
        
        return all_data
    
    def to_dataframes(self, all_data):
        """ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜ (í†µí•©ëœ í˜•íƒœ)"""
        dfs = {}
        collection_date = datetime.now().strftime('%Y-%m-%d')
        collection_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        # 1. TOP5 í€ë“œ ë°ì´í„° (ëª¨ë“  íƒ­ í†µí•©)
        all_top_funds = []
        for tab_name, tab_data in all_data.items():
            for fund in tab_data['top_funds']:
                fund['tab_type'] = tab_name
                fund['collection_date'] = collection_date
                fund['collection_time'] = collection_time
                all_top_funds.append(fund)
        
        if all_top_funds:
            dfs['top_funds'] = pd.DataFrame(all_top_funds)
            print(f"âœ… Created unified TOP5 dataframe with {len(all_top_funds)} rows")
        
        # 2. ì‹ ê·œ í€ë“œ ë°ì´í„° (ëª¨ë“  íƒ­ í†µí•©)
        all_new_funds = []
        for tab_name, tab_data in all_data.items():
            for fund in tab_data['new_funds']:
                fund['tab_type'] = tab_name
                fund['collection_date'] = collection_date
                fund['collection_time'] = collection_time
                all_new_funds.append(fund)
        
        if all_new_funds:
            dfs['new_funds'] = pd.DataFrame(all_new_funds)
            print(f"âœ… Created unified new funds dataframe with {len(all_new_funds)} rows")
        
        # 3. ì¼ë³„ ì°¨íŠ¸ ë°ì´í„° (ëª¨ë“  íƒ­ í†µí•©)
        all_chart_data = []
        for tab_name, tab_data in all_data.items():
            chart_data = tab_data.get('chart_data', {})
            if chart_data.get('dates'):
                dates = chart_data['dates']
                setup_amounts = chart_data.get('setup_amounts', [])
                returns = chart_data.get('returns', [])
                
                # ë°ì´í„° ê¸¸ì´ ë§ì¶”ê¸°
                min_length = min(
                    len(dates), 
                    len(setup_amounts) if setup_amounts else 0, 
                    len(returns) if returns else 0
                )
                
                for i in range(min_length):
                    all_chart_data.append({
                        'date': dates[i],
                        'setup_amount': setup_amounts[i] if i < len(setup_amounts) else None,
                        'return_rate': returns[i] if i < len(returns) else None,
                        'tab_type': tab_name,
                        'collection_time': collection_time
                    })
        
        if all_chart_data:
            dfs['daily_chart'] = pd.DataFrame(all_chart_data)
            print(f"âœ… Created unified chart dataframe with {len(all_chart_data)} rows")
        
        return dfs
    
    def save_to_sheets(self, dfs):
        """Google Sheetsì— ë°ì´í„° ì €ì¥ (í†µí•©ëœ ì‹œíŠ¸)"""
        # ì„œë¹„ìŠ¤ ê³„ì • ì¸ì¦
        scope = ['https://spreadsheets.google.com/feeds',
                 'https://www.googleapis.com/auth/drive']
        
        creds_json = os.environ.get('GOOGLE_SERVICE')
        if not creds_json:
            print("âŒ No Google Sheets credentials found")
            return []
        
        try:
            creds_dict = json.loads(creds_json)
            service_account_email = creds_dict.get('client_email', 'Unknown')
            print(f"ğŸ“§ Using service account: {service_account_email}")
            
            creds = Credentials.from_service_account_info(creds_dict, scopes=scope)
            client = gspread.authorize(creds)
            
            sheet_id = os.environ.get('KRFUND_SPREADSHEET_ID')
            if not sheet_id:
                print("âŒ No Google Sheet ID found")
                return []
                
            spreadsheet = client.open_by_key(sheet_id)
            
            # ì‹œíŠ¸ ì´ë¦„ ë§¤í•‘
            sheet_mapping = {
                'top_funds': 'ESG_TOP5í€ë“œ',
                'new_funds': 'ESG_ì‹ ê·œí€ë“œ',
                'daily_chart': 'ESG_ì¼ë³„ì°¨íŠ¸',
                'chart_comparison': 'ESG_ì°¨íŠ¸ë¹„êµê²€ì¦'
            }
            
            updated_sheets = []
            
            for df_key, df in dfs.items():
                sheet_name = sheet_mapping.get(df_key, df_key)
                
                try:
                    # ì‹œíŠ¸ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±
                    try:
                        worksheet = spreadsheet.worksheet(sheet_name)
                    except:
                        worksheet = spreadsheet.add_worksheet(title=sheet_name, rows=5000, cols=20)
                    
                    if df_key == 'daily_chart':
                        # ì¼ë³„ ì°¨íŠ¸ëŠ” íŠ¹ë³„í•œ ì²˜ë¦¬ (ìµœì‹  ë°ì´í„°ê°€ ìœ„ë¡œ)
                        existing_data = worksheet.get_all_records()
                        
                        if existing_data:
                            existing_df = pd.DataFrame(existing_data)
                            # ìƒˆ ë°ì´í„°ì™€ ê²°í•©
                            combined_df = pd.concat([df, existing_df], ignore_index=True)
                            # ì¤‘ë³µ ì œê±° (ë‚ ì§œì™€ íƒ­ìœ¼ë¡œ)
                            combined_df = combined_df.drop_duplicates(subset=['date', 'tab_type'], keep='first')
                            # ë‚ ì§œ ì—­ìˆœ ì •ë ¬ (ìµœì‹ ì´ ìœ„ë¡œ)
                            combined_df = combined_df.sort_values(by=['date', 'tab_type'], ascending=[False, True])
                        else:
                            combined_df = df
                            
                    elif df_key == 'chart_comparison':
                        # ë¹„êµ ê²€ì¦ ë°ì´í„°ëŠ” ë§¤ë²ˆ ìƒˆë¡œ ì“°ê¸°
                        combined_df = df
                        combined_df = combined_df.sort_values(by=['date', 'tab_type', 'method'], 
                                                            ascending=[False, True, True])
                        
                    else:
                        # TOP5ì™€ ì‹ ê·œí€ë“œëŠ” ê¸°ì¡´ ë¡œì§ ìœ ì§€
                        existing_data = worksheet.get_all_records()
                        
                        if existing_data:
                            existing_df = pd.DataFrame(existing_data)
                            # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•œ í‚¤ ì„¤ì •
                            if df_key == 'top_funds':
                                key_cols = ['collection_date', 'tab_type', 'type', 'rank']
                            elif df_key == 'new_funds':
                                key_cols = ['collection_date', 'tab_type', 'fund_name']
                            
                            # ì¤‘ë³µ ì œê±° í›„ ê²°í•©
                            combined_df = pd.concat([existing_df, df], ignore_index=True)
                            combined_df = combined_df.drop_duplicates(subset=key_cols, keep='last')
                            # ìµœì‹  ë°ì´í„°ê°€ ìœ„ë¡œ ì˜¤ë„ë¡ ì •ë ¬
                            combined_df = combined_df.sort_values(by=['collection_date', 'tab_type'], 
                                                                ascending=[False, True])
                        else:
                            combined_df = df
                    
                    # ë°ì´í„° ì“°ê¸°
                    worksheet.clear()
                    worksheet.update([combined_df.columns.values.tolist()] + combined_df.values.tolist())
                    
                    updated_sheets.append(sheet_name)
                    print(f"âœ… Successfully updated {sheet_name} with {len(combined_df)} rows")
                    
                except Exception as e:
                    print(f"âŒ Error updating {sheet_name}: {e}")
                    
            return updated_sheets
            
        except Exception as e:
            print(f"âŒ Error in save_to_sheets: {e}")
            return []
    
    def save_backup(self, dfs):
        """ë¡œì»¬ ë°±ì—… ì €ì¥"""
        backup_dir = 'data_backup'
        if not os.path.exists(backup_dir):
            os.makedirs(backup_dir)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        saved_files = []
        
        for key, df in dfs.items():
            filename = f'{backup_dir}/esg_fund_{key}_{timestamp}.csv'
            df.to_csv(filename, index=False, encoding='utf-8-sig')
            saved_files.append(filename)
            print(f"ğŸ’¾ Saved backup: {filename}")
        
        return saved_files
    
    def send_telegram_message(self, message):
        """Telegram ë©”ì‹œì§€ ì „ì†¡"""
        if not self.telegram_bot_token or not self.telegram_chat_id:
            print("âŒ Telegram credentials not found")
            return
        
        try:
            url = f"https://api.telegram.org/bot{self.telegram_bot_token}/sendMessage"
            data = {
                "chat_id": self.telegram_chat_id,
                "text": message,
                "parse_mode": "Markdown"
            }
            response = requests.post(url, data=data)
            response.raise_for_status()
        except Exception as e:
            print(f"âŒ Error sending Telegram message: {e}")
    
    async def run(self):
        """ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        start_time = time.time()
        print(f"ğŸš€ Starting ESG Fund data collection at {datetime.now()}")
        
        try:
            # 1. ëª¨ë“  íƒ­ ë°ì´í„° ìˆ˜ì§‘
            all_data = await self.scrape_all_tabs()
            
            # 2. DataFrame ë³€í™˜ (í†µí•©ëœ í˜•íƒœ)
            dfs = self.to_dataframes(all_data)
            
            # 3. ë°ì´í„° í†µê³„
            total_records = sum(len(df) for df in dfs.values())
            
            # 4. Google Sheets ì €ì¥
            updated_sheets = self.save_to_sheets(dfs)
            
            # 5. ë¡œì»¬ ë°±ì—…
            saved_files = self.save_backup(dfs)
            
            # 6. ì‹¤í–‰ ì‹œê°„ ê³„ì‚°
            execution_time = round(time.time() - start_time, 2)
            
            # 7. ìƒì„¸ í†µê³„
            stats = {}
            for key, df in dfs.items():
                if key == 'top_funds':
                    stats['TOP5 í€ë“œ'] = f"{len(df)}ê°œ (ìˆ˜ìµë¥ /ì„¤ì •ì•¡ì¦ê°€)"
                elif key == 'new_funds':
                    stats['ì‹ ê·œ í€ë“œ'] = f"{len(df)}ê°œ"
                elif key == 'daily_chart':
                    unique_dates = df['date'].nunique() if 'date' in df.columns else 0
                    stats['ì°¨íŠ¸ ë°ì´í„°'] = f"{unique_dates}ì¼ì¹˜"
            
            # 8. ì„±ê³µ ë©”ì‹œì§€ ì „ì†¡
            period_text = self.period_text_map.get(self.collection_period, self.collection_period)
            message = f"""âœ… *ESG í€ë“œ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ*

ğŸ“… ìˆ˜ì§‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ğŸ“Š ì´ ë ˆì½”ë“œ: {total_records}ê°œ
ğŸ“ ì—…ë°ì´íŠ¸ ì‹œíŠ¸: {len(updated_sheets)}ê°œ
â±ï¸ ì‹¤í–‰ ì‹œê°„: {execution_time}ì´ˆ
ğŸ“ˆ ìˆ˜ì§‘ ê¸°ê°„: {period_text}

*ìˆ˜ì§‘ í˜„í™©:*
{chr(10).join([f"â€¢ {k}: {v}" for k, v in stats.items()])}

*ìˆ˜ì§‘ ë²”ìœ„:*
â€¢ SRI í€ë“œ
â€¢ ESG ì£¼ì‹í˜• í€ë“œ
â€¢ ESG ì±„ê¶Œí˜• í€ë“œ"""
            
            self.send_telegram_message(message)
            print("âœ… Data collection completed successfully")
            
        except Exception as e:
            error_message = f"""âŒ *ESG í€ë“œ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨*

ğŸ“… ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ğŸš« ì˜¤ë¥˜: {str(e)}

ê´€ë¦¬ìì—ê²Œ í™•ì¸ì„ ìš”ì²­í•˜ì„¸ìš”."""
            
            self.send_telegram_message(error_message)
            print(f"âŒ Data collection failed: {e}")
            raise

if __name__ == "__main__":
    scraper = ESGFundScraper()
    asyncio.run(scraper.run())
